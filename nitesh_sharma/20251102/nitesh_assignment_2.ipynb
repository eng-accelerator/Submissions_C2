{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0596051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\env_v1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced RAG libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for advanced RAG\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Core LlamaIndex components\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# Vector store\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "\n",
    "# Embeddings and LLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "\n",
    "# Advanced RAG components (we'll use these in the assignments)\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "print(\"‚úÖ Advanced RAG libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda421c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OPENROUTER_API_KEY found - full advanced RAG functionality available\n",
      "‚úÖ Advanced RAG settings configured\n",
      "   - Chunk size: 512 (optimized for precision)\n",
      "   - Using local embeddings for cost efficiency\n",
      "   - OpenRouter LLM ready for response synthesis\n"
     ]
    }
   ],
   "source": [
    "# Configure Advanced RAG Settings (Using OpenRouter)\n",
    "def setup_advanced_rag_settings():\n",
    "    \"\"\"\n",
    "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
    "    Uses local embeddings and OpenRouter for LLM operations.\n",
    "    \"\"\"\n",
    "    import streamlit as st\n",
    "    # Check for OpenRouter API key\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\") or st.secrets.get(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ö†Ô∏è  OPENROUTER_API_KEY not found - LLM operations will be limited\")\n",
    "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
    "    else:\n",
    "        print(\"‚úÖ OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
    "        \n",
    "        # Configure OpenRouter LLM\n",
    "        Settings.llm = OpenRouter(\n",
    "            api_key=api_key,\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.1  # Lower temperature for more consistent responses\n",
    "        )\n",
    "    \n",
    "    # Configure local embeddings (no API key required)\n",
    "    Settings.embed_model = HuggingFaceEmbedding(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # Advanced RAG configuration\n",
    "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
    "    Settings.chunk_overlap = 50\n",
    "    \n",
    "    print(\"‚úÖ Advanced RAG settings configured\")\n",
    "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
    "    print(\"   - Using local embeddings for cost efficiency\")\n",
    "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
    "\n",
    "# Setup the configuration\n",
    "setup_advanced_rag_settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b81d9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Table documents doesn't exist yet. Please add some data to create it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Setting up basic index for advanced RAG...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\ai_agents.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\in_the_end.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\rags.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\env_v1\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Parsing nodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 73.56it/s]\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:11<00:00,  7.81it/s]\n",
      "2025-11-02 08:07:14,277 - INFO - Create new table documents adding data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Basic index created with 39 documents\n",
      "   Ready for advanced RAG techniques!\n",
      "üöÄ Ready to implement advanced RAG techniques!\n"
     ]
    }
   ],
   "source": [
    "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
    "def setup_basic_index(data_folder: str = \"../data\", force_rebuild: bool = False):\n",
    "    \"\"\"\n",
    "    Create a basic vector index that we'll enhance with advanced techniques.\n",
    "    This reuses the concepts from Assignment 1.\n",
    "    \"\"\"\n",
    "    # Create vector store\n",
    "    vector_store = LanceDBVectorStore(\n",
    "        uri=\"./advanced_rag_vectordb\",\n",
    "        table_name=\"documents\"\n",
    "    )\n",
    "    \n",
    "    # Load documents\n",
    "    if not Path(data_folder).exists():\n",
    "        print(f\"‚ùå Data folder not found: {data_folder}\")\n",
    "        return None\n",
    "        \n",
    "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
    "    documents = reader.load_data()\n",
    "    \n",
    "    # Create storage context and index\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, \n",
    "        storage_context=storage_context,\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Basic index created with {len(documents)} documents\")\n",
    "    print(\"   Ready for advanced RAG techniques!\")\n",
    "    return index\n",
    "\n",
    "# Create the basic index\n",
    "print(\"üìÅ Setting up basic index for advanced RAG...\")\n",
    "index = setup_basic_index()\n",
    "\n",
    "if index:\n",
    "    print(\"üöÄ Ready to implement advanced RAG techniques!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to create index - check data folder path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c111415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:20,978 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query engine with similarity filtering created\n",
      "\n",
      "üîç Testing query: 'What are the benefits of AI agents?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:21,535 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Response: AI agents offer several benefits, including the ability to tackle complex multi-step problems that require advanced problem-solving skills. They can be designed with well-defined system prompts, clear leadership, and task division, which enhance their effectiveness. Additionally, AI agents can incorporate dedicated phases for reasoning, planning, execution, and evaluation, as well as dynamic team structures and intelligent message filtering. These features make them more effective across various benchmarks and problem types. However, it's important to note that while promising, there are still challenges to address for their reliable application.\n",
      "   (Complete the function above to test the response)\n"
     ]
    }
   ],
   "source": [
    "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Create a query engine that filters results based on similarity scores.\n",
    "    \n",
    "    TODO: Complete this function to create a query engine with similarity postprocessing.\n",
    "    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n",
    "    \n",
    "    Args:\n",
    "        index: Vector index to query\n",
    "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
    "        top_k: Number of initial results to retrieve before filtering\n",
    "        \n",
    "    Returns:\n",
    "        Query engine with similarity filtering\n",
    "    \"\"\"\n",
    "    # TODO: Create similarity postprocessor with the cutoff threshold\n",
    "    similarity_processor = SimilarityPostprocessor(cutoff=similarity_cutoff)\n",
    "    \n",
    "    # TODO: Create query engine with similarity filtering\n",
    "    query_engine = index.as_query_engine(\n",
    "        retriever_kwargs={\"similarity_top_k\": top_k},\n",
    "        node_postprocessors=[similarity_processor]\n",
    "    )\n",
    "\n",
    "    return query_engine\n",
    "\n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create query engine with similarity cutoff {similarity_cutoff}\")\n",
    "    return None\n",
    "\n",
    "# Test the function\n",
    "if index:\n",
    "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
    "    \n",
    "    if filtered_engine:\n",
    "        print(\"‚úÖ Query engine with similarity filtering created\")\n",
    "        \n",
    "        # Test query\n",
    "        test_query = \"What are the benefits of AI agents?\"\n",
    "        print(f\"\\nüîç Testing query: '{test_query}'\")\n",
    "        \n",
    "        # Uncomment when implemented:\n",
    "        response = filtered_engine.query(test_query)\n",
    "        print(f\"üìù Response: {response}\")\n",
    "        print(\"   (Complete the function above to test the response)\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create filtered query engine\")\n",
    "else:\n",
    "    print(\"‚ùå No index available - run previous cells first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9881a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:33,718 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query engine with TreeSummarize created\n",
      "\n",
      "üîç Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:34,265 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù TreeSummarize Response:\n",
      "Different AI agent frameworks offer various advantages and disadvantages based on their design and application. \n",
      "\n",
      "Advantages:\n",
      "1. **Modularity and Composability**: Many frameworks, such as Agno and CrewAI, emphasize modularity and composability, allowing for flexible and rapid development. This makes it easier to integrate with existing cloud infrastructure and adapt to different use cases.\n",
      "2. **Scalability**: Frameworks that incorporate multi-agent scaling laws can efficiently manage the performance of systems as the number of agents increases, which is beneficial for handling complex tasks.\n",
      "3. **Advanced Problem-Solving**: Architectures that include well-defined system prompts, clear task division, and dynamic team structures are effective in tackling complex, multi-step problems.\n",
      "\n",
      "Disadvantages:\n",
      "1. **Complexity in Implementation**: The need for dedicated reasoning, planning, execution, and evaluation phases can increase the complexity of implementation and require significant expertise.\n",
      "2. **Real-World Applicability**: There are challenges in ensuring that these frameworks are applicable to real-world scenarios, particularly in terms of comprehensive benchmarks and mitigating biases.\n",
      "3. **Feedback Mechanisms**: While verbal reinforcement learning and feedback mechanisms can enhance learning, they may also introduce challenges in terms of consistency and reliability of the feedback provided.\n",
      "\n",
      "Overall, the\n",
      "   (Complete the function above to test comprehensive analysis)\n"
     ]
    }
   ],
   "source": [
    "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
    "    \n",
    "    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n",
    "    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n",
    "    \n",
    "    Args:\n",
    "        index: Vector index to query\n",
    "        top_k: Number of results to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        Query engine with TreeSummarize synthesis\n",
    "    \"\"\"\n",
    "    # TODO: Create TreeSummarize response synthesizer\n",
    "    tree_synthesizer = TreeSummarize()\n",
    "    \n",
    "    # TODO: Create query engine with the synthesizer\n",
    "    query_engine = index.as_query_engine(\n",
    "        response_synthesizer=tree_synthesizer,\n",
    "        retriever_kwargs={\"top_k\": top_k}\n",
    "    )\n",
    "    return query_engine\n",
    "    # return query_engine\n",
    "    \n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create query engine with TreeSummarize synthesis\")\n",
    "    return None\n",
    "\n",
    "# Test the function\n",
    "if index:\n",
    "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
    "    \n",
    "    if tree_engine:\n",
    "        print(\"‚úÖ Query engine with TreeSummarize created\")\n",
    "        \n",
    "        # Test with a complex analytical query\n",
    "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
    "        print(f\"\\nüîç Testing analytical query: '{analytical_query}'\")\n",
    "        \n",
    "        # Uncomment when implemented:\n",
    "        response = tree_engine.query(analytical_query)\n",
    "        print(f\"üìù TreeSummarize Response:\\n{response}\")\n",
    "        print(\"   (Complete the function above to test comprehensive analysis)\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create TreeSummarize query engine\")\n",
    "else:\n",
    "    print(\"‚ùå No index available - run previous cells first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31cd4b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:51,713 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Structured output program created\n",
      "\n",
      "üîç Testing structured query: 'Tell me about AI agents and their capabilities'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 08:59:52,408 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Structured Response:\n",
      "title='The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey' key_points=['The best agent architecture varies based on use case, incorporating techniques like system prompts, task division, and feedback.', 'Single and multi-agent patterns are effective in solving complex tasks requiring reasoning and tool execution.', 'Dynamic team structures and intelligent message filtering enhance agent performance.', 'Current AI-driven agents face limitations in benchmarks, real-world applicability, and language model biases.', 'Future research should focus on improving agent evaluation and reliability.'] applications=['AI-driven agents for complex problem-solving tasks', 'Dynamic team structures in AI systems', 'Enhanced reasoning and planning in AI applications'] summary='This survey paper explores advancements in AI agent architectures, highlighting their capabilities in reasoning, planning, and tool execution. It discusses the effectiveness of single and multi-agent patterns and identifies key techniques for improving agent performance. The paper also addresses current limitations and suggests areas for future research.'\n",
      "   (Complete the function above to get structured JSON output)\n",
      "\n",
      "üí° Expected output format:\n",
      "   - title: String\n",
      "   - key_points: List of strings\n",
      "   - applications: List of strings\n",
      "   - summary: String\n"
     ]
    }
   ],
   "source": [
    "# First, define the Pydantic models for structured outputs  \n",
    "class ResearchPaperInfo(BaseModel):\n",
    "    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n",
    "    title: str = Field(description=\"The main title or concept name\")\n",
    "    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n",
    "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
    "    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n",
    "\n",
    "# Import the missing component\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "\n",
    "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
    "    \"\"\"\n",
    "    Create a structured output program using Pydantic models.\n",
    "    \n",
    "    TODO: Complete this function to create a structured output program.\n",
    "    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n",
    "    \n",
    "    Args:\n",
    "        output_model: Pydantic model class for structured output\n",
    "        \n",
    "    Returns:\n",
    "        LLMTextCompletionProgram that returns structured data\n",
    "    \"\"\"\n",
    "    # TODO: Create output parser with the Pydantic model\n",
    "    output_parser = PydanticOutputParser(output_cls=output_model)\n",
    "    #output_parser = PydanticOutputParser()\n",
    "    \n",
    "    # TODO: Create the structured output program\n",
    "    program = LLMTextCompletionProgram.from_defaults(\n",
    "        output_parser=output_parser,\n",
    "        prompt_template_str=(\n",
    "            \"Extract the following information from the context:\\n\"\n",
    "            \"- title\\n\"\n",
    "            \"- key_points\\n\"\n",
    "            \"- applications\\n\"\n",
    "            \"- summary\\n\\n\"\n",
    "            \"Context:\\n{context}\\n\\n\"\n",
    "            \"Provide the output in JSON format.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return program\n",
    "\n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create structured output program with {output_model.__name__}\")\n",
    "    return None\n",
    "\n",
    "# Test the function\n",
    "if index:\n",
    "    structured_program = create_structured_output_program(ResearchPaperInfo)\n",
    "    \n",
    "    if structured_program:\n",
    "        print(\"‚úÖ Structured output program created\")\n",
    "        \n",
    "        # Test with retrieval and structured extraction\n",
    "        structure_query = \"Tell me about AI agents and their capabilities\"\n",
    "        print(f\"\\nüîç Testing structured query: '{structure_query}'\")\n",
    "        \n",
    "        # Get context for structured extraction (Uncomment when implemented)\n",
    "        retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
    "        nodes = retriever.retrieve(structure_query)\n",
    "        context = \"\\n\".join([node.text for node in nodes])\n",
    "        \n",
    "        # Uncomment when implemented:\n",
    "        response = structured_program(context=context, query=structure_query)\n",
    "        print(f\"üìä Structured Response:\\n{response}\")\n",
    "        print(\"   (Complete the function above to get structured JSON output)\")\n",
    "        \n",
    "        print(\"\\nüí° Expected output format:\")\n",
    "        print(\"   - title: String\")\n",
    "        print(\"   - key_points: List of strings\")\n",
    "        print(\"   - applications: List of strings\") \n",
    "        print(\"   - summary: String\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create structured output program\")\n",
    "else:\n",
    "    print(\"‚ùå No index available - run previous cells first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18ae040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 09:03:24,395 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced RAG pipeline created successfully!\n",
      "   üîß Similarity filtering: ‚úÖ\n",
      "   üå≥ TreeSummarize synthesis: ‚úÖ\n",
      "\n",
      "üîç Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 09:03:25,347 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Advanced RAG Response:\n",
      "The current state of AI agent technologies is characterized by advancements in reasoning, planning, and tool execution capabilities, enabling them to tackle complex, multi-step problems. Both single-agent and multi-agent architectures are being explored, with the choice of architecture depending on the specific use case. Effective agent systems often incorporate well-defined system prompts, clear leadership and task division, dedicated phases for reasoning, planning, execution, and evaluation, as well as dynamic team structures and feedback mechanisms.\n",
      "\n",
      "Despite these advancements, there are notable limitations that need addressing, such as the development of comprehensive benchmarks, ensuring real-world applicability, and mitigating biases inherent in language models. The future potential of AI agent technologies lies in overcoming these challenges, which will enable the creation of more reliable and effective autonomous agents. The progression from static language models to dynamic agents suggests a promising trajectory for AI applications, with ongoing research and development aimed at enhancing their capabilities and applicability.\n",
      "   (Complete the function above to test the full pipeline)\n",
      "\n",
      "üéØ This should provide:\n",
      "   - Filtered relevant results only\n",
      "   - Comprehensive analytical response\n",
      "   - Combined postprocessing and synthesis\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
    "    \n",
    "    TODO: Complete this function to create the ultimate advanced RAG query engine.\n",
    "    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n",
    "    \n",
    "    Args:\n",
    "        index: Vector index to query\n",
    "        similarity_cutoff: Minimum similarity score for filtering\n",
    "        top_k: Number of initial results to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        Advanced query engine with filtering and synthesis combined\n",
    "    \"\"\"\n",
    "    # TODO: Create similarity postprocessor\n",
    "    similarity_processor = SimilarityPostprocessor(cutoff=similarity_cutoff)\n",
    "    \n",
    "    # TODO: Create TreeSummarize for comprehensive responses\n",
    "    tree_synthesizer = TreeSummarize()\n",
    "    \n",
    "    # TODO: Create the comprehensive query engine combining both techniques\n",
    "    advanced_engine = index.as_query_engine(\n",
    "        retriever_kwargs={\"similarity_top_k\": top_k},\n",
    "        node_postprocessors=[similarity_processor],\n",
    "        response_synthesizer=tree_synthesizer\n",
    "    )\n",
    "\n",
    "    return advanced_engine\n",
    "\n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create advanced RAG pipeline with all techniques\")\n",
    "    return None\n",
    "\n",
    "# Test the comprehensive pipeline\n",
    "if index:\n",
    "    advanced_pipeline = create_advanced_rag_pipeline(index)\n",
    "    \n",
    "    if advanced_pipeline:\n",
    "        print(\"‚úÖ Advanced RAG pipeline created successfully!\")\n",
    "        print(\"   üîß Similarity filtering: ‚úÖ\")\n",
    "        print(\"   üå≥ TreeSummarize synthesis: ‚úÖ\")\n",
    "        \n",
    "        # Test with complex query\n",
    "        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n",
    "        print(f\"\\nüîç Testing complex query: '{complex_query}'\")\n",
    "        \n",
    "        # Uncomment when implemented:\n",
    "        response = advanced_pipeline.query(complex_query)\n",
    "        print(f\"üöÄ Advanced RAG Response:\\n{response}\")\n",
    "        print(\"   (Complete the function above to test the full pipeline)\")\n",
    "        \n",
    "        print(\"\\nüéØ This should provide:\")\n",
    "        print(\"   - Filtered relevant results only\")\n",
    "        print(\"   - Comprehensive analytical response\")\n",
    "        print(\"   - Combined postprocessing and synthesis\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create advanced RAG pipeline\")\n",
    "else:\n",
    "    print(\"‚ùå No index available - run previous cells first\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
