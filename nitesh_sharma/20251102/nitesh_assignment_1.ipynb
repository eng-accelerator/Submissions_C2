{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210779f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\env_v1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9e738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  OPENROUTER_API_KEY not found - that's OK for this assignment!\n",
      "   This assignment only uses local embeddings for vector operations.\n",
      "‚úÖ LlamaIndex configured with local embeddings\n",
      "   Using BAAI/bge-small-en-v1.5 for document embeddings\n"
     ]
    }
   ],
   "source": [
    "# Configure LlamaIndex Settings (Using OpenRouter - No OpenAI API Key needed)\n",
    "def setup_llamaindex_settings():\n",
    "    \"\"\"\n",
    "    Configure LlamaIndex with local embeddings and OpenRouter for LLM.\n",
    "    This assignment focuses on vector database operations, so we'll use local embeddings only.\n",
    "    \"\"\"\n",
    "    # Check for OpenRouter API key (for future use, not needed for this basic assignment)\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"‚ÑπÔ∏è  OPENROUTER_API_KEY not found - that's OK for this assignment!\")\n",
    "        print(\"   This assignment only uses local embeddings for vector operations.\")\n",
    "    \n",
    "    # Configure local embeddings (no API key required)\n",
    "    Settings.embed_model = HuggingFaceEmbedding(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ LlamaIndex configured with local embeddings\")\n",
    "    print(\"   Using BAAI/bge-small-en-v1.5 for document embeddings\")\n",
    "\n",
    "# Setup the configuration\n",
    "setup_llamaindex_settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3c274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:12<00:00, 11.2MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\ai_agents.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\in_the_end.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\rags.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\env_v1\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 39 documents\n"
     ]
    }
   ],
   "source": [
    "def load_documents_from_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    Load documents from a folder using SimpleDirectoryReader.\n",
    "    \n",
    "    TODO: Complete this function to load documents from the given folder path.\n",
    "    HINT: Use SimpleDirectoryReader with recursive parameter to load all files\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing documents\n",
    "        \n",
    "    Returns:\n",
    "        List of documents loaded from the folder\n",
    "    \"\"\"\n",
    "    # TODO: Create SimpleDirectoryReader instance\n",
    "    reader = SimpleDirectoryReader(folder_path, recursive=True)\n",
    "    \n",
    "    # TODO: Load and return documents\n",
    "    documents = reader.load_data()\n",
    "\n",
    "    # return documents\n",
    "    return documents\n",
    "\n",
    "# Test the function after you complete it\n",
    "test_folder = \"../data\"\n",
    "documents = load_documents_from_folder(test_folder)\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb61b262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 07:45:16,768 - WARNING - Table documents doesn't exist yet. Please add some data to create it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created: True\n"
     ]
    }
   ],
   "source": [
    "def create_vector_store(db_path: str = \"./vectordb\", table_name: str = \"documents\"):\n",
    "    \"\"\"\n",
    "    Create a LanceDB vector store for storing document embeddings.\n",
    "    \n",
    "    TODO: Complete this function to create and configure a LanceDB vector store.\n",
    "    HINT: Use LanceDBVectorStore with uri and table_name parameters\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path where the vector database will be stored\n",
    "        table_name (str): Name of the table in the vector database\n",
    "        \n",
    "    Returns:\n",
    "        LanceDBVectorStore: Configured vector store\n",
    "    \"\"\"\n",
    "    # TODO: Create the directory if it doesn't exist\n",
    "    Path(db_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # TODO: Create vector store\n",
    "    vector_store = LanceDBVectorStore(\n",
    "        uri=f\"./{db_path}/{table_name}.db\",\n",
    "        table_name=table_name,\n",
    "        mode=\"overwrite\"  # overwrite existing table\n",
    "    )\n",
    "    return vector_store\n",
    "    \n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create vector store at {db_path}\")\n",
    "    return None\n",
    "\n",
    "# Test the function after you complete it\n",
    "vector_store = create_vector_store(\"./assignment_vectordb\")\n",
    "print(f\"Vector store created: {vector_store is not None}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4aabec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 07:46:39,007 - INFO - Create new table documents adding data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector index created: True\n"
     ]
    }
   ],
   "source": [
    "def create_vector_index(documents: List, vector_store):\n",
    "    \"\"\"\n",
    "    Create a vector index from documents using the provided vector store.\n",
    "    \n",
    "    TODO: Complete this function to create a VectorStoreIndex from documents.\n",
    "    HINT: Create StorageContext with vector_store, then use VectorStoreIndex.from_documents()\n",
    "    \n",
    "    Args:\n",
    "        documents: List of documents to index\n",
    "        vector_store: LanceDB vector store to use for storage\n",
    "        \n",
    "    Returns:\n",
    "        VectorStoreIndex: The created vector index\n",
    "    \"\"\"\n",
    "    # TODO: Create storage context with vector store\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    # TODO: Create index from documents\n",
    "    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "    \n",
    "    return index\n",
    "\n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Create vector index from {len(documents)} documents\")\n",
    "    return None\n",
    "\n",
    "# Test the function after you complete it (will only work after previous functions are completed)\n",
    "if documents and vector_store:\n",
    "    index = create_vector_index(documents, vector_store)\n",
    "    print(f\"Vector index created: {index is not None}\")\n",
    "else:\n",
    "    print(\"Complete previous functions first to test this one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b292bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 07:47:37,186 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 results for query: 'What are AI agents?'\n",
      "Result 1: agent-personas or the user is not needed, multi-agent architectures tend to thrive more when collabo...\n",
      "Result 2: THE LANDSCAPE OF EMERGING AI AGENT ARCHITECTURES\n",
      "FOR REASONING , PLANNING , AND TOOL CALLING : A S U...\n"
     ]
    }
   ],
   "source": [
    "def search_documents(index, query: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Search for relevant documents using the vector index.\n",
    "    \n",
    "    TODO: Complete this function to perform semantic search on the index.\n",
    "    HINT: Use index.as_retriever() with similarity_top_k parameter, then retrieve(query)\n",
    "    \n",
    "    Args:\n",
    "        index: Vector index to search\n",
    "        query (str): Search query\n",
    "        top_k (int): Number of top results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of retrieved document nodes\n",
    "    \"\"\"\n",
    "    # TODO: Create retriever from index\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    \n",
    "    # TODO: Retrieve documents for the query\n",
    "    results = retriever.retrieve(query)\n",
    "    \n",
    "    return results\n",
    "\n",
    "    # PLACEHOLDER - Replace with actual implementation\n",
    "    print(f\"TODO: Search for '{query}' in index\")\n",
    "    return []\n",
    "\n",
    "# Test the function after you complete it (will only work after all previous functions are completed)\n",
    "if 'index' in locals() and index is not None:\n",
    "    test_query = \"What are AI agents?\"\n",
    "    results = search_documents(index, test_query, top_k=2)\n",
    "    print(f\"Found {len(results)} results for query: '{test_query}'\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"Result {i}: {result.text[:100] if hasattr(result, 'text') else 'No text'}...\")\n",
    "else:\n",
    "    print(\"Complete all previous functions first to test this one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842c3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Testing Complete Vector Database Pipeline\n",
      "==================================================\n",
      "\n",
      "üìÇ Step 1: Loading documents...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\ai_agents.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\in_the_end.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
      "Failed to load file c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\src\\20251102\\session_2\\assignments\\..\\data\\audio\\rags.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NSHAR\\OneDrive - paramanands limited\\AI_projects\\env_v1\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 39 documents\n",
      "\n",
      "üóÑÔ∏è Step 2: Creating vector store...\n",
      "   Vector store status: ‚úÖ Created\n",
      "\n",
      "üîó Step 3: Creating vector index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 07:48:24,923 - INFO - query_type :, vector\n",
      "2025-11-02 07:48:24,981 - INFO - query_type :, vector\n",
      "2025-11-02 07:48:25,021 - INFO - query_type :, vector\n",
      "2025-11-02 07:48:25,062 - INFO - query_type :, vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index status: ‚úÖ Created\n",
      "\n",
      "üîç Step 4: Testing search functionality...\n",
      "\n",
      "   üîé Query: 'What are AI agents?'\n",
      "      1. agent-personas or the user is not needed, multi-agent architectures tend to thrive more when collabo... (Score: 0.6250)\n",
      "\n",
      "   üîé Query: 'How to evaluate agent performance?'\n",
      "      1. steps, but the answers are limited to Yes/No responses [7]. As the industry continues to pivot towar... (Score: 0.6800)\n",
      "\n",
      "   üîé Query: 'Italian recipes and cooking'\n",
      "      1. # üçù Classic Spaghetti Carbonara Recipe\n",
      "\n",
      "## Ingredients\n",
      "- 400g spaghetti pasta\n",
      "- 4 large egg yolk... (Score: 0.6280)\n",
      "\n",
      "   üîé Query: 'Financial analysis and investment'\n",
      "      1. However, several important considerations need to be ad-\n",
      "dressed in future work:\n",
      "‚Ä¢ Scalability: Eval... (Score: 0.5623)\n",
      "\n",
      "==================================================\n",
      "üéØ Assignment Status:\n",
      "   Documents loaded: ‚úÖ\n",
      "   Vector store created: ‚úÖ\n",
      "   Index created: ‚úÖ\n",
      "   Search working: ‚úÖ\n",
      "\n",
      "üéâ Congratulations! You've successfully completed the assignment!\n",
      "   You've built a complete vector database with search functionality!\n"
     ]
    }
   ],
   "source": [
    "# Final test of the complete pipeline\n",
    "print(\"üöÄ Testing Complete Vector Database Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Re-run the complete pipeline to ensure everything works\n",
    "data_folder = \"../data\"\n",
    "vector_db_path = \"./assignment_vectordb\"\n",
    "\n",
    "# Step 1: Load documents\n",
    "print(\"\\nüìÇ Step 1: Loading documents...\")\n",
    "documents = load_documents_from_folder(data_folder)\n",
    "print(f\"   Loaded {len(documents)} documents\")\n",
    "\n",
    "# Step 2: Create vector store\n",
    "print(\"\\nüóÑÔ∏è Step 2: Creating vector store...\")\n",
    "vector_store = create_vector_store(vector_db_path)\n",
    "print(\"   Vector store status:\", \"‚úÖ Created\" if vector_store else \"‚ùå Failed\")\n",
    "\n",
    "# Step 3: Create vector index\n",
    "print(\"\\nüîó Step 3: Creating vector index...\")\n",
    "if documents and vector_store:\n",
    "    index = create_vector_index(documents, vector_store)\n",
    "    print(\"   Index status:\", \"‚úÖ Created\" if index else \"‚ùå Failed\")\n",
    "else:\n",
    "    index = None\n",
    "    print(\"   ‚ùå Cannot create index - missing documents or vector store\")\n",
    "\n",
    "# Step 4: Test multiple search queries\n",
    "print(\"\\nüîç Step 4: Testing search functionality...\")\n",
    "if index:\n",
    "    search_queries = [\n",
    "        \"What are AI agents?\",\n",
    "        \"How to evaluate agent performance?\", \n",
    "        \"Italian recipes and cooking\",\n",
    "        \"Financial analysis and investment\"\n",
    "    ]\n",
    "    \n",
    "    for query in search_queries:\n",
    "        print(f\"\\n   üîé Query: '{query}'\")\n",
    "        results = search_documents(index, query, top_k=2)\n",
    "        \n",
    "        if results:\n",
    "            for i, result in enumerate(results, 1):\n",
    "                text_preview = result.text[:100] if hasattr(result, 'text') else \"No text available\"\n",
    "                score = f\" (Score: {result.score:.4f})\" if hasattr(result, 'score') else \"\"\n",
    "                print(f\"      {i}. {text_preview}...{score}\")\n",
    "        else:\n",
    "            print(\"      No results found\")\n",
    "else:\n",
    "    print(\"   ‚ùå Cannot test search - index not created\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéØ Assignment Status:\")\n",
    "print(f\"   Documents loaded: {'‚úÖ' if documents else '‚ùå'}\")\n",
    "print(f\"   Vector store created: {'‚úÖ' if vector_store else '‚ùå'}\")\n",
    "print(f\"   Index created: {'‚úÖ' if index else '‚ùå'}\")\n",
    "print(f\"   Search working: {'‚úÖ' if index else '‚ùå'}\")\n",
    "\n",
    "if documents and vector_store and index:\n",
    "    print(\"\\nüéâ Congratulations! You've successfully completed the assignment!\")\n",
    "    print(\"   You've built a complete vector database with search functionality!\")\n",
    "else:\n",
    "    print(\"\\nüìù Please complete the TODO functions above to finish the assignment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
