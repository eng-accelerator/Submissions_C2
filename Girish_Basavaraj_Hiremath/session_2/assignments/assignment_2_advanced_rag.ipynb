{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 2: Advanced RAG Techniques\n",
        "## Day 6 Session 2 - Advanced RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Implement advanced RAG techniques including postprocessors, response synthesizers, and structured outputs.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand and implement node postprocessors for filtering and reranking\n",
        "- Learn different response synthesis strategies (TreeSummarize, Refine)\n",
        "- Create structured outputs using Pydantic models\n",
        "- Build advanced retrieval pipelines with multiple processing stages\n",
        "\n",
        "**DATASET:** Use the same data folder as Assignment 1 (`Day_6/session_2/data/`)\n",
        "\n",
        "**PREREQUISITES:** Complete Assignment 1 first\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the `03_advanced_rag_techniques.ipynb` notebook\n",
        "4. Each technique builds on the previous one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Advanced RAG libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for advanced RAG\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Load environment variables from .env file\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()  # Load .env file if it exists\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  python-dotenv not installed. Install with: pip install python-dotenv\")\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "print(\"‚úÖ Advanced RAG libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:09:39,604 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ OPENROUTER_API_KEY found - full advanced RAG functionality available\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:09:43,555 - INFO - 1 prompt is loaded, with the key: query\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Advanced RAG settings configured\n",
            "   - Chunk size: 512 (optimized for precision)\n",
            "   - Using local embeddings for cost efficiency\n",
            "   - OpenRouter LLM ready for response synthesis\n"
          ]
        }
      ],
      "source": [
        "# Configure Advanced RAG Settings (Using OpenRouter)\n",
        "def setup_advanced_rag_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
        "    Uses local embeddings and OpenRouter for LLM operations.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key (from .env file or environment)\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    \n",
        "    if not api_key:\n",
        "        print(\"‚ö†Ô∏è  OPENROUTER_API_KEY not found!\")\n",
        "        print(\"   Please create a .env file in the session_2 folder with:\")\n",
        "        print(\"   OPENROUTER_API_KEY=your_api_key_here\")\n",
        "        print(\"   OR set it as an environment variable\")\n",
        "        print(\"\\n   LLM operations will be limited\")\n",
        "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"‚úÖ OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
        "    \n",
        "    # Configure OpenRouter LLM\n",
        "    Settings.llm = OpenRouter(\n",
        "        api_key=api_key,\n",
        "        model=\"gpt-4o\",\n",
        "        temperature=0.1  # Lower temperature for more consistent responses\n",
        "    )\n",
        "    \n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    # Advanced RAG configuration\n",
        "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
        "    Settings.chunk_overlap = 50\n",
        "    \n",
        "    print(\"‚úÖ Advanced RAG settings configured\")\n",
        "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
        "    print(\"   - Using local embeddings for cost efficiency\")\n",
        "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_advanced_rag_settings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Key found!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "print(\"API Key found!\" if os.getenv(\"OPENROUTER_API_KEY\") else \"API Key NOT found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Setting up basic index for advanced RAG...\n",
            "Failed to load file c:\\Users\\gengi\\OneDrive\\Desktop\\ai-accelerator-C2\\Day_6\\session_2\\assignments\\..\\data\\audio\\ai_agents.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
            "Failed to load file c:\\Users\\gengi\\OneDrive\\Desktop\\ai-accelerator-C2\\Day_6\\session_2\\assignments\\..\\data\\audio\\in_the_end.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n",
            "Failed to load file c:\\Users\\gengi\\OneDrive\\Desktop\\ai-accelerator-C2\\Day_6\\session_2\\assignments\\..\\data\\audio\\rags.mp3 with error: [WinError 2] The system cannot find the file specified. Skipping...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Parsing nodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:00<00:00, 274.01it/s]\n",
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:26<00:00,  3.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Basic index created with 39 documents\n",
            "   Ready for advanced RAG techniques!\n",
            "üöÄ Ready to implement advanced RAG techniques!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
        "def setup_basic_index(data_folder: str = \"../data\", force_rebuild: bool = False):\n",
        "    \"\"\"\n",
        "    Create a basic vector index that we'll enhance with advanced techniques.\n",
        "    This reuses the concepts from Assignment 1.\n",
        "    \"\"\"\n",
        "    # Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "        uri=\"./advanced_rag_vectordb\",\n",
        "        table_name=\"documents\"\n",
        "    )\n",
        "    \n",
        "    # Load documents\n",
        "    if not Path(data_folder).exists():\n",
        "        print(f\"‚ùå Data folder not found: {data_folder}\")\n",
        "        return None\n",
        "        \n",
        "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "    documents = reader.load_data()\n",
        "    \n",
        "    # Create storage context and index\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents, \n",
        "        storage_context=storage_context,\n",
        "        show_progress=True\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Basic index created with {len(documents)} documents\")\n",
        "    print(\"   Ready for advanced RAG techniques!\")\n",
        "    return index\n",
        "\n",
        "# Create the basic index\n",
        "print(\"üìÅ Setting up basic index for advanced RAG...\")\n",
        "index = setup_basic_index()\n",
        "\n",
        "if index:\n",
        "    print(\"üöÄ Ready to implement advanced RAG techniques!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to create index - check data folder path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Node Postprocessors - Similarity Filtering\n",
        "\n",
        "**Concept:** Postprocessors refine retrieval results after the initial vector search. The `SimilarityPostprocessor` filters out chunks that fall below a relevance threshold.\n",
        "\n",
        "**Why it matters:** Raw vector search often returns some irrelevant results. Filtering improves precision and response quality.\n",
        "\n",
        "Complete the function below to create a query engine with similarity filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:06:35,010 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Query engine with similarity filtering created\n",
            "\n",
            "üîç Testing query: 'What are the benefits of AI agents?'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:06:39,716 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:06:42,470 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:06:44,703 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Response: AI agents offer several benefits, including the ability to tackle complex problems through reasoning, planning, and tool utilization. They can autonomously engage with external environments, make decisions, and assist humans in various tasks. By incorporating reasoning and planning, agents can adapt their strategies based on new information, ensuring effective decision-making in uncertain situations. Additionally, agents can use different tools to interact with external data sources, enhancing their problem-solving capabilities. Both single-agent and multi-agent systems excel at managing intricate tasks, with multi-agent systems providing advantages in scenarios that demand collaboration and parallel task execution.\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a query engine that filters results based on similarity scores.\n",
        "    \n",
        "    TODO: Complete this function to create a query engine with similarity postprocessing.\n",
        "    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
        "        top_k: Number of initial results to retrieve before filtering\n",
        "        \n",
        "    Returns:\n",
        "        Query engine with similarity filtering\n",
        "    \"\"\"\n",
        "    # Create similarity postprocessor with the cutoff threshold\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "    \n",
        "    # Create query engine with similarity filtering\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor]\n",
        "    )\n",
        "    \n",
        "    return query_engine\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
        "    \n",
        "    if filtered_engine:\n",
        "        print(\"‚úÖ Query engine with similarity filtering created\")\n",
        "        \n",
        "        # Test query\n",
        "        test_query = \"What are the benefits of AI agents?\"\n",
        "        print(f\"\\nüîç Testing query: '{test_query}'\")\n",
        "        \n",
        "        # Test the query\n",
        "        response = filtered_engine.query(test_query)\n",
        "        print(f\"üìù Response: {response}\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to create filtered query engine\")\n",
        "else:\n",
        "    print(\"‚ùå No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Response Synthesizers - TreeSummarize\n",
        "\n",
        "**Concept:** Response synthesizers control how retrieved information becomes final answers. `TreeSummarize` builds responses hierarchically, ideal for complex analytical questions.\n",
        "\n",
        "**Why it matters:** Different synthesis strategies work better for different query types. TreeSummarize excels at comprehensive analysis and long-form responses.\n",
        "\n",
        "Complete the function below to create a query engine with TreeSummarize response synthesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:11:22,888 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Query engine with TreeSummarize created\n",
            "\n",
            "üîç Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:11:24,584 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù TreeSummarize Response:\n",
            "Different AI agent frameworks offer various advantages and disadvantages based on their design and application.\n",
            "\n",
            "Advantages:\n",
            "1. **Rapid Development and Deployment**: Frameworks like Agno and CrewAI facilitate quick development and deployment of robust AI systems, particularly in sectors like finance.\n",
            "2. **Dynamic and Autonomous Capabilities**: Architectures that leverage dynamic teams and autonomous agents are effective across diverse benchmarks and problem types. They can adapt to changing needs by bringing agents in and out of the system as required.\n",
            "3. **Enhanced Performance**: Both single and multi-agent patterns show strong performance in complex tasks involving reasoning and tool execution. Multi-agent systems, in particular, benefit from having clear leaders, defined planning phases, and dynamic teams with specific skills.\n",
            "\n",
            "Disadvantages:\n",
            "1. **Evaluation Challenges**: There is a lack of standardized benchmarks for evaluating AI agents, making it difficult to compare different implementations. Many benchmarks are unique to specific research teams and involve complex, manually scored evaluations.\n",
            "2. **Real-World Applicability and Bias**: Current AI-driven agents face challenges in real-world applicability and in mitigating biases inherent in language models.\n",
            "3. **Complexity in Multi-Agent Systems**: While multi-agent systems can be highly effective, they require careful coordination and communication strategies to avoid unproductive interactions and\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
        "    \n",
        "    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n",
        "    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        top_k: Number of results to retrieve\n",
        "        \n",
        "    Returns:\n",
        "        Query engine with TreeSummarize synthesis\n",
        "    \"\"\"\n",
        "    # Create TreeSummarize response synthesizer\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "    \n",
        "    # Create query engine with the synthesizer\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "    \n",
        "    return query_engine\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
        "    \n",
        "    if tree_engine:\n",
        "        print(\"‚úÖ Query engine with TreeSummarize created\")\n",
        "        \n",
        "        # Test with a complex analytical query\n",
        "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
        "        print(f\"\\nüîç Testing analytical query: '{analytical_query}'\")\n",
        "        \n",
        "        # Test the query\n",
        "        response = tree_engine.query(analytical_query)\n",
        "        print(f\"üìù TreeSummarize Response:\\n{response}\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to create TreeSummarize query engine\")\n",
        "else:\n",
        "    print(\"‚ùå No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Structured Outputs with Pydantic Models\n",
        "\n",
        "**Concept:** Structured outputs ensure predictable, parseable responses using Pydantic models. This is essential for API endpoints and data pipelines.\n",
        "\n",
        "**Why it matters:** Instead of free-text responses, you get type-safe, validated data structures that applications can reliably process.\n",
        "\n",
        "Complete the function below to create a structured output system for extracting research paper information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:11:35,908 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Structured output program created\n",
            "\n",
            "üîç Testing structured query: 'Tell me about AI agents and their capabilities'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:11:37,199 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Structured Response:\n",
            "title='AI Agents and Their Capabilities' key_points=['AI-driven agents show promise but have limitations and areas for improvement.', 'Challenges include comprehensive benchmarks, real-world applicability, and mitigating harmful biases.', 'Dynamic teams of agents can be effective, with agents brought in based on need.', 'Single and multi-agent patterns perform well on complex tasks with reasoning and tool execution.', 'Agent architectures with clear leadership, planning phases, and dynamic teams improve performance.'] applications=['AI-driven agents can be used in dynamic team settings for task planning and execution.', 'Single agent patterns are effective for tasks requiring defined personas and iterative feedback.', 'Multi-agent systems can collaborate on complex goals with intelligent message filtering.'] summary='AI agents are evolving from static language models to dynamic, autonomous systems. While they show strong performance in various tasks, challenges remain in evaluation, reliability, and bias mitigation. Effective agent architectures often include dynamic teams and clear planning strategies.'\n",
            "\n",
            "üí° Expected output format:\n",
            "   - title: String\n",
            "   - key_points: List of strings\n",
            "   - applications: List of strings\n",
            "   - summary: String\n"
          ]
        }
      ],
      "source": [
        "# First, define the Pydantic models for structured outputs  \n",
        "class ResearchPaperInfo(BaseModel):\n",
        "    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n",
        "    title: str = Field(description=\"The main title or concept name\")\n",
        "    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n",
        "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
        "    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n",
        "\n",
        "# Import the missing component\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "\n",
        "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
        "    \"\"\"\n",
        "    Create a structured output program using Pydantic models.\n",
        "    \n",
        "    TODO: Complete this function to create a structured output program.\n",
        "    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n",
        "    \n",
        "    Args:\n",
        "        output_model: Pydantic model class for structured output\n",
        "        \n",
        "    Returns:\n",
        "        LLMTextCompletionProgram that returns structured data\n",
        "    \"\"\"\n",
        "    # Create output parser with the Pydantic model\n",
        "    output_parser = PydanticOutputParser(output_model)\n",
        "    \n",
        "    # Create the structured output program\n",
        "    program = LLMTextCompletionProgram.from_defaults(\n",
        "        output_parser=output_parser,\n",
        "        prompt_template_str=(\n",
        "            \"Extract structured information from the following context:\\n\"\n",
        "            \"{context}\\n\\n\"\n",
        "            \"Question: {query}\\n\\n\"\n",
        "            \"Provide the information in the specified JSON format.\"\n",
        "        ),\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return program\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    structured_program = create_structured_output_program(ResearchPaperInfo)\n",
        "    \n",
        "    if structured_program:\n",
        "        print(\"‚úÖ Structured output program created\")\n",
        "        \n",
        "        # Test with retrieval and structured extraction\n",
        "        structure_query = \"Tell me about AI agents and their capabilities\"\n",
        "        print(f\"\\nüîç Testing structured query: '{structure_query}'\")\n",
        "        \n",
        "        # Get context for structured extraction\n",
        "        retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
        "        nodes = retriever.retrieve(structure_query)\n",
        "        context = \"\\n\".join([node.text for node in nodes])\n",
        "        \n",
        "        # Get structured output\n",
        "        response = structured_program(context=context, query=structure_query)\n",
        "        print(f\"üìä Structured Response:\\n{response}\")\n",
        "        \n",
        "        print(\"\\nüí° Expected output format:\")\n",
        "        print(\"   - title: String\")\n",
        "        print(\"   - key_points: List of strings\")\n",
        "        print(\"   - applications: List of strings\") \n",
        "        print(\"   - summary: String\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to create structured output program\")\n",
        "else:\n",
        "    print(\"‚ùå No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Pipeline - Combining All Techniques\n",
        "\n",
        "**Concept:** Combine multiple advanced techniques into a single powerful query engine: similarity filtering + response synthesis + structured output.\n",
        "\n",
        "**Why it matters:** Production RAG systems often need multiple techniques working together for optimal results.\n",
        "\n",
        "Complete the function below to create a comprehensive advanced RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:19,878 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Advanced RAG pipeline created successfully!\n",
            "   üîß Similarity filtering: ‚úÖ\n",
            "   üå≥ TreeSummarize synthesis: ‚úÖ\n",
            "\n",
            "üîç Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:20,886 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Advanced RAG Response:\n",
            "The current state of AI agent technologies is promising, with advancements in their ability to achieve complex goals through enhanced reasoning, planning, and tool execution capabilities. These technologies are effective across various benchmarks and problem types, particularly when employing single or multi-agent architectures. Single-agent systems perform well with defined roles and iterative feedback, while multi-agent systems benefit from dynamic team structures and intelligent communication strategies.\n",
            "\n",
            "However, there are notable limitations that need addressing for future improvements. Challenges include the development of comprehensive benchmarks for evaluating agents, ensuring real-world applicability, and mitigating biases inherent in language models. Future potential lies in overcoming these challenges, which would enable more reliable and robust AI agents. Additionally, the integration of structured communication and information-sharing mechanisms, as seen in systems like MetaGPT, could further enhance the performance and efficiency of multi-agent architectures. Overall, the progression from static models to dynamic, autonomous agents offers significant opportunities for innovation in AI agent design and implementation.\n",
            "\n",
            "üéØ This should provide:\n",
            "   - Filtered relevant results only\n",
            "   - Comprehensive analytical response\n",
            "   - Combined postprocessing and synthesis\n"
          ]
        }
      ],
      "source": [
        "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
        "    \n",
        "    TODO: Complete this function to create the ultimate advanced RAG query engine.\n",
        "    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score for filtering\n",
        "        top_k: Number of initial results to retrieve\n",
        "        \n",
        "    Returns:\n",
        "        Advanced query engine with filtering and synthesis combined\n",
        "    \"\"\"\n",
        "    # Create similarity postprocessor\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "    \n",
        "    # Create TreeSummarize for comprehensive responses\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "    \n",
        "    # Create the comprehensive query engine combining both techniques\n",
        "    advanced_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor],\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "    \n",
        "    return advanced_engine\n",
        "\n",
        "# Test the comprehensive pipeline\n",
        "if index:\n",
        "    advanced_pipeline = create_advanced_rag_pipeline(index)\n",
        "    \n",
        "    if advanced_pipeline:\n",
        "        print(\"‚úÖ Advanced RAG pipeline created successfully!\")\n",
        "        print(\"   üîß Similarity filtering: ‚úÖ\")\n",
        "        print(\"   üå≥ TreeSummarize synthesis: ‚úÖ\")\n",
        "        \n",
        "        # Test with complex query\n",
        "        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n",
        "        print(f\"\\nüîç Testing complex query: '{complex_query}'\")\n",
        "        \n",
        "        # Test the pipeline\n",
        "        response = advanced_pipeline.query(complex_query)\n",
        "        print(f\"üöÄ Advanced RAG Response:\\n{response}\")\n",
        "        \n",
        "        print(\"\\nüéØ This should provide:\")\n",
        "        print(\"   - Filtered relevant results only\")\n",
        "        print(\"   - Comprehensive analytical response\")\n",
        "        print(\"   - Combined postprocessing and synthesis\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed to create advanced RAG pipeline\")\n",
        "else:\n",
        "    print(\"‚ùå No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Final Test - Compare Basic vs Advanced RAG\n",
        "\n",
        "Once you've completed all the functions above, run this cell to compare basic RAG with your advanced techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:46,537 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Advanced RAG Techniques Assignment - Final Test\n",
            "============================================================\n",
            "\n",
            "üìä Component Status:\n",
            "   ‚úÖ Basic Index\n",
            "   ‚úÖ Similarity Filter\n",
            "   ‚úÖ TreeSummarize\n",
            "   ‚úÖ Structured Output\n",
            "   ‚úÖ Advanced Pipeline\n",
            "\n",
            "üîç Creating basic query engine for comparison...\n",
            "\n",
            "============================================================\n",
            "üÜö COMPARISON: Basic vs Advanced RAG\n",
            "============================================================\n",
            "\n",
            "üìã Test Query 1: 'What are the key capabilities of AI agents?'\n",
            "--------------------------------------------------\n",
            "üîπ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:47,507 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:12:48,692 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: AI agents exhibit several key capabilities, including strong performance on complex tasks that involve reasoning and tool execution. They can operate effectively as single agents with defined personas...\n",
            "\n",
            "üî∏ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:49,357 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:12:50,626 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: AI agents are designed to extend the capabilities of language models to solve real-world challenges. Key capabilities include robust problem-solving skills, reasoning, planning, and the ability to call tools that interact with external environments. These capabilities enable agents to perform well on novel tasks by reasoning over multiple steps and accessing outside information. Additionally, effective agent architectures often involve dynamic teams with specific skills relevant to current tasks, intelligent message filtering, and opportunities for plan refinement as new information is learned.\n",
            "\n",
            "üìã Test Query 2: 'How do you evaluate agent performance metrics?'\n",
            "--------------------------------------------------\n",
            "üîπ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:51,652 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:12:53,427 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Evaluating agent performance metrics involves using both objective and subjective measures. Objective metrics include success rate, output similarity to human responses, and overall efficiency. These ...\n",
            "\n",
            "üî∏ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:54,140 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:12:57,513 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Evaluating agent performance metrics involves using both objective and subjective measures. Objective metrics include success rate, output similarity to human responses, and overall efficiency. These metrics provide a quantitative assessment of an agent's capabilities. Subjective measures, which are equally important, focus on aspects like the efficiency of tool use, reliability, and robustness of planning. These often require evaluation by human experts, which can be more costly and time-consuming. Additionally, benchmarks like AgentBench and SmartPlay are used to evaluate agents in various environments, providing insights into their ability to generalize and perform tasks involving reasoning, planning, and tool usage. Real-world benchmarks, such as WildBench, also play a role by using data from actual conversations to assess performance across a wide range of tasks.\n",
            "\n",
            "üìã Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n",
            "--------------------------------------------------\n",
            "üîπ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:12:58,531 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-11-02 14:12:59,779 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Multimodal AI systems offer several benefits, including the ability to process and integrate information from multiple sources, such as text, images, and audio, which can lead to more comprehensive un...\n",
            "\n",
            "üî∏ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-02 14:13:00,446 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Multimodal AI systems offer several benefits, including enhanced understanding and interaction capabilities by integrating multiple types of data such as text, images, and audio. This integration allows for more comprehensive analysis and decision-making, as the systems can draw on diverse data sources to improve accuracy and context-awareness. Additionally, multimodal systems can provide more natural and intuitive user interactions, as they can process and respond to inputs in various forms, similar to human communication.\n",
            "\n",
            "However, these systems also face challenges. One significant challenge is the complexity of effectively integrating and processing different data modalities, which often require distinct processing techniques and models. Ensuring seamless interaction between these modalities can be technically demanding. Another challenge is the increased computational resources required to handle and analyze the diverse data types, which can impact the system's efficiency and scalability. Furthermore, developing robust evaluation benchmarks for multimodal systems can be difficult, as it involves assessing performance across multiple data types and tasks.\n",
            "\n",
            "============================================================\n",
            "üéØ Assignment Status:\n",
            "   Completed: 5/5 components\n",
            "\n",
            "üéâ Congratulations! You've mastered Advanced RAG Techniques!\n",
            "   ‚úÖ Node postprocessors for result filtering\n",
            "   ‚úÖ Response synthesizers for better answers\n",
            "   ‚úÖ Structured outputs for reliable data\n",
            "   ‚úÖ Advanced pipelines combining all techniques\n",
            "\n",
            "üöÄ You're ready for production RAG systems!\n",
            "\n",
            "üí° Key learnings:\n",
            "   - Postprocessors improve result relevance and precision\n",
            "   - Different synthesizers work better for different query types\n",
            "   - Structured outputs enable reliable system integration\n",
            "   - Advanced techniques can be combined for production systems\n"
          ]
        }
      ],
      "source": [
        "# Final comparison: Basic vs Advanced RAG\n",
        "print(\"üöÄ Advanced RAG Techniques Assignment - Final Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test queries for comparison\n",
        "test_queries = [\n",
        "    \"What are the key capabilities of AI agents?\",\n",
        "    \"How do you evaluate agent performance metrics?\",\n",
        "    \"Explain the benefits and challenges of multimodal AI systems\"\n",
        "]\n",
        "\n",
        "# Check if all components were created\n",
        "components_status = {\n",
        "    \"Basic Index\": index is not None,\n",
        "    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n",
        "    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n",
        "    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n",
        "    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Component Status:\")\n",
        "for component, status in components_status.items():\n",
        "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
        "    print(f\"   {status_icon} {component}\")\n",
        "\n",
        "# Create basic query engine for comparison\n",
        "if index:\n",
        "    print(\"\\nüîç Creating basic query engine for comparison...\")\n",
        "    basic_engine = index.as_query_engine(similarity_top_k=5)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üÜö COMPARISON: Basic vs Advanced RAG\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nüìã Test Query {i}: '{query}'\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        # Basic RAG\n",
        "        print(\"üîπ Basic RAG:\")\n",
        "        if basic_engine:\n",
        "            basic_response = basic_engine.query(query)\n",
        "            print(f\"   Response: {str(basic_response)[:200]}...\")\n",
        "        \n",
        "        # Advanced RAG (if implemented)\n",
        "        print(\"\\nüî∏ Advanced RAG:\")\n",
        "        if components_status[\"Advanced Pipeline\"]:\n",
        "            advanced_response = advanced_pipeline.query(query)\n",
        "            print(f\"   Response: {advanced_response}\")\n",
        "        else:\n",
        "            print(\"   Complete the advanced pipeline function to test\")\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üéØ Assignment Status:\")\n",
        "completed_count = sum(components_status.values())\n",
        "total_count = len(components_status)\n",
        "\n",
        "print(f\"   Completed: {completed_count}/{total_count} components\")\n",
        "\n",
        "if completed_count == total_count:\n",
        "    print(\"\\nüéâ Congratulations! You've mastered Advanced RAG Techniques!\")\n",
        "    print(\"   ‚úÖ Node postprocessors for result filtering\")\n",
        "    print(\"   ‚úÖ Response synthesizers for better answers\")\n",
        "    print(\"   ‚úÖ Structured outputs for reliable data\")\n",
        "    print(\"   ‚úÖ Advanced pipelines combining all techniques\")\n",
        "    print(\"\\nüöÄ You're ready for production RAG systems!\")\n",
        "else:\n",
        "    missing = total_count - completed_count\n",
        "    print(f\"\\nüìù Complete {missing} more components to finish the assignment:\")\n",
        "    for component, status in components_status.items():\n",
        "        if not status:\n",
        "            print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\nüí° Key learnings:\")\n",
        "print(\"   - Postprocessors improve result relevance and precision\")\n",
        "print(\"   - Different synthesizers work better for different query types\")\n",
        "print(\"   - Structured outputs enable reliable system integration\")\n",
        "print(\"   - Advanced techniques can be combined for production systems\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
