# üöÄ Assignment 2: Advanced RAG Techniques - Implementation Guide

**Status**: Ready to start! ‚úÖ Assignment 1 Complete

This guide provides step-by-step help for completing Assignment 2's four main functions.

---

## üìã Quick Overview

**What You'll Build:**
1. ‚úÖ **Similarity Postprocessor** - Filter low-relevance results
2. ‚úÖ **TreeSummarize Engine** - Generate comprehensive responses  
3. ‚úÖ **Structured Outputs** - Create type-safe JSON responses
4. ‚úÖ **Advanced Pipeline** - Combine all techniques

**Estimated Time**: 60-90 minutes  
**Difficulty**: Intermediate

---

## ‚úÖ Prerequisites Check

Before starting, verify your setup:

```python
# Run this to verify API key and index
import os
api_key = os.getenv("OPENROUTER_API_KEY")
print("‚úÖ API Key found!" if api_key else "‚ö†Ô∏è API Key missing")

# The assignment should have created an index already
if 'index' in globals():
    print(f"‚úÖ Index ready: {index is not None}")
else:
    print("‚ùå Run the setup cells first")
```

---

## üîß Function 1: Similarity Postprocessor

**Goal**: Filter out low-relevance results

**Reference Pattern** (from tutorial):
```python
similarity_processor = SimilarityPostprocessor(similarity_cutoff=0.3)
query_engine = index.as_query_engine(
    similarity_top_k=top_k,
    node_postprocessors=[similarity_processor]
)
```

**Your Implementation**:
```python
def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):
    # Create similarity postprocessor
    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)
    
    # Create query engine with the postprocessor
    query_engine = index.as_query_engine(
        similarity_top_k=top_k,
        node_postprocessors=[similarity_processor]
    )
    
    return query_engine
```

**What This Does**:
- Filters out results below the similarity threshold
- Improves precision by removing noise
- Still retrieves `top_k` initially, then filters

**Test After Completion**:
```python
filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)
response = filtered_engine.query("What are the benefits of AI agents?")
print(response)
```

---

## üå≥ Function 2: TreeSummarize Engine

**Goal**: Generate comprehensive analytical responses

**Reference Pattern** (from tutorial):
```python
tree_synthesizer = TreeSummarize()
query_engine = index.as_query_engine(
    response_synthesizer=tree_synthesizer,
    similarity_top_k=8
)
```

**Your Implementation**:
```python
def create_query_engine_with_tree_summarize(index, top_k: int = 5):
    # Create TreeSummarize response synthesizer
    tree_synthesizer = TreeSummarize()
    
    # Create query engine with the synthesizer
    query_engine = index.as_query_engine(
        similarity_top_k=top_k,
        response_synthesizer=tree_synthesizer
    )
    
    return query_engine
```

**What This Does**:
- Builds responses hierarchically (groups related chunks)
- Better for complex analytical questions
- More comprehensive than simple summarization

**Test After Completion**:
```python
tree_engine = create_query_engine_with_tree_summarize(index)
response = tree_engine.query("Compare the advantages and disadvantages of different AI agent frameworks")
print(response)
```

---

## üìä Function 3: Structured Outputs

**Goal**: Create type-safe JSON responses using Pydantic

**Reference Pattern** (from tutorial):
```python
output_parser = PydanticOutputParser(RecipeInfo)
program = LLMTextCompletionProgram.from_defaults(
    output_parser=output_parser,
    prompt_template_str=(
        "Extract structured information from the following context:\n"
        "{context}\n\n"
        "Question: {query}\n\n"
        "Extract the information and return it in the specified format."
    )
)
```

**Your Implementation**:
```python
def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):
    # Create output parser with the Pydantic model
    output_parser = PydanticOutputParser(output_model)
    
    # Create the structured output program
    program = LLMTextCompletionProgram.from_defaults(
        output_parser=output_parser,
        prompt_template_str=(
            "Extract structured information from the following context:\n"
            "{context}\n\n"
            "Question: {query}\n\n"
            "Extract the information and return it in the specified format."
        )
    )
    
    return program
```

**What This Does**:
- Returns structured JSON matching your Pydantic model
- Type-safe with automatic validation
- Perfect for API endpoints

**Test After Completion**:
```python
structured_program = create_structured_output_program(ResearchPaperInfo)

# Get context first
retriever = VectorIndexRetriever(index=index, similarity_top_k=3)
nodes = retriever.retrieve("Tell me about AI agents")
context = "\n".join([node.text for node in nodes])

# Get structured output
response = structured_program(context=context, query="Tell me about AI agents")
print(response)
print(type(response))  # Should be ResearchPaperInfo instance
```

---

## üéØ Function 4: Advanced Pipeline

**Goal**: Combine similarity filtering + TreeSummarize for production-ready RAG

**Reference Pattern** (from tutorial):
```python
similarity_processor = SimilarityPostprocessor(similarity_cutoff=0.3)
tree_synthesizer = TreeSummarize()
query_engine = index.as_query_engine(
    similarity_top_k=10,
    node_postprocessors=[similarity_processor],
    response_synthesizer=tree_synthesizer
)
```

**Your Implementation**:
```python
def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):
    # Create similarity postprocessor
    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)
    
    # Create TreeSummarize for comprehensive responses
    tree_synthesizer = TreeSummarize()
    
    # Create the comprehensive query engine combining both techniques
    advanced_engine = index.as_query_engine(
        similarity_top_k=top_k,
        node_postprocessors=[similarity_processor],
        response_synthesizer=tree_synthesizer
    )
    
    return advanced_engine
```

**What This Does**:
- Filters results first (improves precision)
- Then synthesizes comprehensive response (improves quality)
- Best of both worlds!

**Test After Completion**:
```python
advanced_pipeline = create_advanced_rag_pipeline(index)
response = advanced_pipeline.query("Analyze the current state and future potential of AI agent technologies")
print(response)
```

---

## üîç Step-by-Step Workflow

### Step 1: Open Assignment 2 Notebook
```
assignments/assignment_2_advanced_rag.ipynb
```

### Step 2: Run Setup Cells
- Run the import cell (Cell 1) ‚úÖ
- Run the settings cell (Cell 2) ‚úÖ
- Run the index setup cell (Cell 3) ‚úÖ

**Expected**: Index created successfully with documents loaded

### Step 3: Complete Function 1 (Similarity Postprocessor)
1. Read the explanation (Cell 4)
2. Find the TODO function (Cell 5)
3. Implement using the pattern above
4. Run the test cell
5. Uncomment the test query to verify

### Step 4: Complete Function 2 (TreeSummarize)
1. Read the explanation (Cell 6)
2. Find the TODO function (Cell 7)
3. Implement using the pattern above
4. Run the test cell
5. Uncomment the test query to verify

### Step 5: Complete Function 3 (Structured Outputs)
1. Read the explanation (Cell 8)
2. Review the Pydantic model (Cell 9 - already defined)
3. Complete the TODO function
4. Run the test cell
5. Uncomment the retrieval and program calls

### Step 6: Complete Function 4 (Advanced Pipeline)
1. Read the explanation (Cell 10)
2. Find the TODO function (Cell 11)
3. Combine both techniques from Functions 1 & 2
4. Run the test cell
5. Uncomment the test query

### Step 7: Final Test (Cell 13)
- Run the final comparison cell
- Compare basic vs advanced RAG
- All components should show ‚úÖ

---

## üêõ Troubleshooting

### Issue: "OPENROUTER_API_KEY not found"
**Solution**: Set environment variable (already done in your QUICK_REFERENCE.md)

### Issue: "Index is None"
**Solution**: Run Cell 3 (setup_basic_index) first

### Issue: "TreeSummarize takes too long"
**Solution**: Normal! TreeSummarize processes hierarchically (3-8 seconds)

### Issue: "Pydantic validation errors"
**Solution**: Check that your prompt extracts all required fields (title, key_points, applications, summary)

### Issue: "No results after similarity filter"
**Solution**: Lower similarity_cutoff (try 0.2 instead of 0.3)

### Issue: "Import errors"
**Solution**: Verify all imports in Cell 1 ran successfully

---

## ‚úÖ Success Checklist

- [ ] All 4 functions completed without TODO comments
- [ ] Similarity filter removes low-relevance results
- [ ] TreeSummarize generates comprehensive responses
- [ ] Structured output returns valid Pydantic model
- [ ] Advanced pipeline combines both techniques
- [ ] Final test cell shows all components ‚úÖ
- [ ] Can compare basic vs advanced RAG responses

---

## üí° Key Concepts You'll Learn

1. **Postprocessors**: Improve retrieval precision by filtering results
2. **Response Synthesizers**: Control how retrieved info becomes answers
3. **Structured Outputs**: Enable reliable system integration
4. **Pipeline Design**: Combine techniques for production systems

---

## üéØ Expected Final Output

When you complete all functions, the final test should show:

```
üöÄ Advanced RAG Techniques Assignment - Final Test
============================================================

üìä Component Status:
   ‚úÖ Basic Index
   ‚úÖ Similarity Filter
   ‚úÖ TreeSummarize
   ‚úÖ Structured Output
   ‚úÖ Advanced Pipeline

üÜö COMPARISON: Basic vs Advanced RAG
...
üéâ Congratulations! You've mastered Advanced RAG Techniques!
```

---

## üöÄ Next Steps After Completion

1. Experiment with different similarity_cutoff values (0.2, 0.4, 0.5)
2. Try other synthesizers: `Refine()`, `CompactAndRefine()`
3. Create custom Pydantic models for different domains
4. Move to Assignment 3a: Basic Gradio Interface

---

**Ready to start? Open `assignment_2_advanced_rag.ipynb` and begin with Function 1! Good luck! üéâ**

