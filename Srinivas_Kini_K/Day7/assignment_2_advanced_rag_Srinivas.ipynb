{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR_HDKgzvR5Z"
      },
      "source": [
        "# Assignment 2: Advanced RAG Techniques\n",
        "## Day 6 Session 2 - Advanced RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Implement advanced RAG techniques including postprocessors, response synthesizers, and structured outputs.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand and implement node postprocessors for filtering and reranking\n",
        "- Learn different response synthesis strategies (TreeSummarize, Refine)\n",
        "- Create structured outputs using Pydantic models\n",
        "- Build advanced retrieval pipelines with multiple processing stages\n",
        "\n",
        "**DATASET:** Use the same data folder as Assignment 1 (`Day_6/session_2/data/`)\n",
        "\n",
        "**PREREQUISITES:** Complete Assignment 1 first\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the `03_advanced_rag_techniques.ipynb` notebook\n",
        "4. Each technique builds on the previous one\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path=\"/content/drive/MyDrive/Colab Notebooks\"\n",
        "requirements_path=os.path.join(project_path,\"requirements.txt\")\n",
        "!pip install -r \"$requirements_path\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_SR0qIMkv1ls",
        "outputId": "75ed505a-9b68-42f5-82b5-ae8550454c2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (4.13.5)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.28.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (2.185.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (5.49.1)\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (7.34.0)\n",
            "Collecting lancedb (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lancedb-0.25.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index-0.14.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-vector-stores-lancedb (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading llama_index_vector_stores_lancedb-0.4.1-py3-none-any.whl.metadata (460 bytes)\n",
            "Collecting llama-index-embeddings-huggingface (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14))\n",
            "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
            "Collecting llama-index-llms-huggingface-api (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 15))\n",
            "  Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-embeddings-openai (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 16))\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-llms-openrouter (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 19)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.109.1)\n",
            "Collecting openai-whisper (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22))\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (2.11.10)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (5.1.2)\n",
            "Collecting yt-dlp (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 25))\n",
            "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.8.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (1.71.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (0.31.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (4.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.6.4)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.14.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.49.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (4.9.0)\n",
            "Collecting deprecation (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11)) (18.1.0)\n",
            "Collecting lance-namespace>=0.0.16 (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lance_namespace-0.0.20-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.7 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_core-0.14.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_llms_openai-0.6.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pylance (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading pylance-0.38.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tantivy (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading tantivy-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama-index-llms-openrouter->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (2.8.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (3.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (4.57.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (1.16.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.0.3)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (3.13.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.9.1)\n",
            "Collecting lance-namespace-urllib3-client (from lance-namespace>=0.0.16->lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lance_namespace_urllib3_client-0.0.20-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.0)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_workflows-2.10.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (3.5)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (4.5.0)\n",
            "Collecting setuptools>=18.5 (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10))\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (8.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (2.0.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (0.7.1)\n",
            "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.2.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.11.1.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (0.6.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (7.4.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.1)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.2)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading lancedb-0.25.2-cp39-abi3-manylinux_2_28_x86_64.whl (38.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.14.7-py3-none-any.whl (7.4 kB)\n",
            "Downloading llama_index_vector_stores_lancedb-0.4.1-py3-none-any.whl (7.9 kB)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl (4.5 kB)\n",
            "Downloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lance_namespace-0.0.20-py3-none-any.whl (31 kB)\n",
            "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.7-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.6-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl (4.7 kB)\n",
            "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading pylance-0.38.3-cp39-abi3-manylinux_2_28_x86_64.whl (48.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tantivy-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.10.2-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading lance_namespace_urllib3_client-0.0.20-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=837f206f3eabe51e79408f21937cb10fe05a95657829cf250a7bd74ab25c19ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, yt-dlp, wrapt, tantivy, setuptools, pypdf, pylance, mypy-extensions, marshmallow, jedi, deprecation, colorama, aiosqlite, typing-inspect, griffe, deprecated, llama-index-instrumentation, llama-cloud, lance-namespace-urllib3-client, dataclasses-json, banks, openai-whisper, llama-index-workflows, lance-namespace, llama-index-core, lancedb, llama-index-vector-stores-lancedb, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface-api, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-openrouter, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 deprecation-2.1.0 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.14.0 jedi-0.19.2 lance-namespace-0.0.20 lance-namespace-urllib3-client-0.0.20 lancedb-0.25.2 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.7 llama-index-cli-0.5.3 llama-index-core-0.14.7 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-api-0.6.1 llama-index-llms-openai-0.6.6 llama-index-llms-openai-like-0.5.3 llama-index-llms-openrouter-0.4.2 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-vector-stores-lancedb-0.4.1 llama-index-workflows-2.10.2 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 openai-whisper-20250625 pylance-0.38.3 pypdf-6.1.3 setuptools-80.9.0 striprtf-0.0.26 tantivy-0.25.0 typing-inspect-0.9.0 wrapt-1.17.3 yt-dlp-2025.10.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "46f20080423c4703beb4d5c7287f4df1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧩 OpenRouter + LlamaIndex Setup & Verification Cell (for Google Colab)\n",
        "!pip install -q llama-index llama-index-llms-openrouter openai\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "from llama_index.core import Settings\n",
        "\n",
        "def setup_openrouter_llm():\n",
        "    \"\"\"\n",
        "    Verify and configure OpenRouter LLM for LlamaIndex inside Google Colab.\n",
        "    \"\"\"\n",
        "    print(\"🔐 Step 1: Enter your OpenRouter API key (starts with sk-or-v1-...)\")\n",
        "    api_key = getpass(\"API key: \").strip()\n",
        "\n",
        "    if not api_key.startswith(\"sk-or-\"):\n",
        "        print(\"❌ Invalid key format. Please use an OpenRouter key (sk-or-v1-...).\")\n",
        "        return\n",
        "\n",
        "    # Set environment variable for LlamaIndex + OpenAI client\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = api_key\n",
        "\n",
        "    # Initialize OpenAI client to test key validity\n",
        "    print(\"🔍 Step 2: Verifying your key with OpenRouter...\")\n",
        "    client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
        "    try:\n",
        "        models = client.models.list().data\n",
        "        print(f\"✅ Key verified! Found {len(models)} available models.\")\n",
        "        print(\"   Here are a few examples:\")\n",
        "        for m in [model.id for model in models[:5]]:\n",
        "            print(\"   •\", m)\n",
        "    except Exception as e:\n",
        "        print(\"❌ Failed to verify key:\", e)\n",
        "        return\n",
        "\n",
        "    # Configure LlamaIndex LLM\n",
        "    print(\"\\n⚙️ Step 3: Configuring LlamaIndex Settings...\")\n",
        "    Settings.llm = OpenRouter(\n",
        "        api_key=api_key,\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    # Test a simple call\n",
        "    try:\n",
        "        print(\"\\n💬 Step 4: Testing a simple completion...\")\n",
        "        response = Settings.llm.complete(\"Say hello from OpenRouter via LlamaIndex!\")\n",
        "        print(\"✅ Response:\", response)\n",
        "    except Exception as e:\n",
        "        print(\"❌ LLM test failed:\", e)\n",
        "        return\n",
        "\n",
        "    print(\"\\n🎯 Setup complete! Your LlamaIndex + OpenRouter configuration is ready.\")\n",
        "\n",
        "# 🚀 Run setup\n",
        "setup_openrouter_llm()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQpliZGJWTn1",
        "outputId": "683d561a-6a7c-447a-e34d-b6ebd72d5116"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔐 Step 1: Enter your OpenRouter API key (starts with sk-or-v1-...)\n",
            "API key: ··········\n",
            "🔍 Step 2: Verifying your key with OpenRouter...\n",
            "✅ Key verified! Found 343 available models.\n",
            "   Here are a few examples:\n",
            "   • amazon/nova-premier-v1\n",
            "   • openai/text-embedding-3-large\n",
            "   • perplexity/sonar-pro-search\n",
            "   • mistralai/voxtral-small-24b-2507\n",
            "   • openai/gpt-oss-safeguard-20b\n",
            "\n",
            "⚙️ Step 3: Configuring LlamaIndex Settings...\n",
            "\n",
            "💬 Step 4: Testing a simple completion...\n",
            "✅ Response: Hello from OpenRouter via LlamaIndex! How can I assist you today?\n",
            "\n",
            "🎯 Setup complete! Your LlamaIndex + OpenRouter configuration is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOOEKuMyvR5l",
        "outputId": "1ff25d17-0437-4413-b0ad-1ba0fbb90f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Advanced RAG libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for advanced RAG\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "print(\"✅ Advanced RAG libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Settings.llm.complete(\"Say hello from OpenRouter!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x40Jbo8iVLxi",
        "outputId": "f179da47-2dca-4430-8119-316aba346c6d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from OpenRouter! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnGdeBcUvR5o",
        "outputId": "362892c2-fde1-48a2-8272-1d7b58223467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OPENROUTER_API_KEY found - full advanced RAG functionality available\n",
            "✅ Advanced RAG settings configured\n",
            "   - Chunk size: 512 (optimized for precision)\n",
            "   - Using local embeddings for cost efficiency\n",
            "   - OpenRouter LLM ready for response synthesis\n"
          ]
        }
      ],
      "source": [
        "# Configure Advanced RAG Settings (Using OpenRouter)\n",
        "def setup_advanced_rag_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
        "    Uses local embeddings and OpenRouter for LLM operations.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    if not api_key:\n",
        "        print(\"⚠️  OPENROUTER_API_KEY not found - LLM operations will be limited\")\n",
        "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
        "    else:\n",
        "        print(\"✅ OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
        "\n",
        "        # Configure OpenRouter LLM\n",
        "        Settings.llm = OpenRouter(\n",
        "            api_key=api_key,\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.1,  # Lower temperature for more consistent responses\n",
        "            base_url=\"https://openrouter.ai/api/v1\"\n",
        "            )\n",
        "\n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # Advanced RAG configuration\n",
        "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
        "    Settings.chunk_overlap = 50\n",
        "\n",
        "    print(\"✅ Advanced RAG settings configured\")\n",
        "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
        "    print(\"   - Using local embeddings for cost efficiency\")\n",
        "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_advanced_rag_settings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "fa85d92d5d4a4bca87d0c9afd019788c",
            "b5b3b9ea200c48f09889040a77d23961",
            "06534dfd40564981a08f8218a3677bee",
            "ebe7a1d7b96b42f690fff88bbb4382d9",
            "ac7f0e30e2bf4ba8a34b2b2bb2ba49ef",
            "56649582055046f9ba277061c9962e08",
            "b2ffc6e7089d41b0af01bcaaca16d72e",
            "da02dd472d79402d8a1ab3d01bcbca32",
            "613fe50f71834b6db5302f9f9ff18f47",
            "724119ee647e4e068fe3171d2d15f7e3",
            "036be8cb223e4b41827fccf61576466b",
            "a4db4cbf11dd44ba9796f8c38007abe5",
            "a340e4ad86ae455d9881bb8e5dd8a99c",
            "4f2f1a589b52489f9f73ba361df333d4",
            "15f47418c96a4083ada15b2cccc5c13d",
            "6516ea595b9149f8bc87871067e8c01a",
            "b1f0d26a5afa4ac0bfbea684ed95b473",
            "7e423a96ba3e44908ff6ba1aa822b839",
            "70c816a436274a58817b0876ca0c8a11",
            "d41701d50fc04ab89e64551b65d42aa7",
            "30297b27a80a4243834d1bc7fb07a964",
            "308628783b6b4eec97940d848ffc64d8"
          ]
        },
        "id": "MfVL3DvKvR5p",
        "outputId": "8fa31637-5da6-402d-ce70-cd1eea9575e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Setting up basic index for advanced RAG...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/42 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa85d92d5d4a4bca87d0c9afd019788c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/90 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4db4cbf11dd44ba9796f8c38007abe5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Basic index created with 42 documents\n",
            "   Ready for advanced RAG techniques!\n",
            "🚀 Ready to implement advanced RAG techniques!\n"
          ]
        }
      ],
      "source": [
        "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
        "def setup_basic_index(data_folder: str = \"/content/drive/MyDrive/content_files/data\", force_rebuild: bool = False):\n",
        "    \"\"\"\n",
        "    Create a basic vector index that we'll enhance with advanced techniques.\n",
        "    This reuses the concepts from Assignment 1.\n",
        "    \"\"\"\n",
        "    # Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "        uri=\"./advanced_rag_vectordb\",\n",
        "        table_name=\"documents\"\n",
        "    )\n",
        "\n",
        "    # Load documents\n",
        "    if not Path(data_folder).exists():\n",
        "        print(f\"❌ Data folder not found: {data_folder}\")\n",
        "        return None\n",
        "\n",
        "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "    documents = reader.load_data()\n",
        "\n",
        "    # Create storage context and index\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents,\n",
        "        storage_context=storage_context,\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Basic index created with {len(documents)} documents\")\n",
        "    print(\"   Ready for advanced RAG techniques!\")\n",
        "    return index\n",
        "\n",
        "# Create the basic index\n",
        "print(\"📁 Setting up basic index for advanced RAG...\")\n",
        "index = setup_basic_index()\n",
        "\n",
        "if index:\n",
        "    print(\"🚀 Ready to implement advanced RAG techniques!\")\n",
        "else:\n",
        "    print(\"❌ Failed to create index - check data folder path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Om-qqfbvR5r"
      },
      "source": [
        "## 1. Node Postprocessors - Similarity Filtering\n",
        "\n",
        "**Concept:** Postprocessors refine retrieval results after the initial vector search. The `SimilarityPostprocessor` filters out chunks that fall below a relevance threshold.\n",
        "\n",
        "**Why it matters:** Raw vector search often returns some irrelevant results. Filtering improves precision and response quality.\n",
        "\n",
        "Complete the function below to create a query engine with similarity filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50B2lRRvR5s",
        "outputId": "39ed2623-ff03-4571-ee7e-f69e4148c363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Query engine with similarity filtering created\n",
            "\n",
            "🔍 Testing query: 'What are the benefits of AI agents?'\n",
            "   (Complete the function above to test the response)\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a query engine that filters results based on similarity scores.\n",
        "\n",
        "    TODO: Complete this function to create a query engine with similarity postprocessing.\n",
        "    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
        "        top_k: Number of initial results to retrieve before filtering\n",
        "\n",
        "    Returns:\n",
        "        Query engine with similarity filtering\n",
        "    \"\"\"\n",
        "    # TODO: Create similarity postprocessor with the cutoff threshold\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # TODO: Create query engine with similarity filtering\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor]\n",
        "    )\n",
        "\n",
        "    return query_engine\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create query engine with similarity cutoff {similarity_cutoff}\")\n",
        "    return None\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
        "\n",
        "    if filtered_engine:\n",
        "        print(\"✅ Query engine with similarity filtering created\")\n",
        "\n",
        "        # Test query\n",
        "        test_query = \"What are the benefits of AI agents?\"\n",
        "        print(f\"\\n🔍 Testing query: '{test_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = filtered_engine.query(test_query)\n",
        "        # print(f\"📝 Response: {response}\")\n",
        "        print(\"   (Complete the function above to test the response)\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create filtered query engine\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlKIzJS2vR5u"
      },
      "source": [
        "## 2. Response Synthesizers - TreeSummarize\n",
        "\n",
        "**Concept:** Response synthesizers control how retrieved information becomes final answers. `TreeSummarize` builds responses hierarchically, ideal for complex analytical questions.\n",
        "\n",
        "**Why it matters:** Different synthesis strategies work better for different query types. TreeSummarize excels at comprehensive analysis and long-form responses.\n",
        "\n",
        "Complete the function below to create a query engine with TreeSummarize response synthesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3OzyWF-vR5u",
        "outputId": "d54f10a0-d199-4527-bfd5-5a7d222180b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Query engine with TreeSummarize created\n",
            "\n",
            "🔍 Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n",
            "   (Complete the function above to test comprehensive analysis)\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
        "\n",
        "    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n",
        "    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        top_k: Number of results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Query engine with TreeSummarize synthesis\n",
        "    \"\"\"\n",
        "    # TODO: Create TreeSummarize response synthesizer\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    # TODO: Create query engine with the synthesizer\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "\n",
        "    return query_engine\n",
        "\n",
        "    # LACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create query engine with TreeSummarize synthesisP\")\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
        "\n",
        "    if tree_engine:\n",
        "        print(\"✅ Query engine with TreeSummarize created\")\n",
        "\n",
        "        # Test with a complex analytical query\n",
        "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
        "        print(f\"\\n🔍 Testing analytical query: '{analytical_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = tree_engine.query(analytical_query)\n",
        "        # print(f\"📝 TreeSummarize Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to test comprehensive analysis)\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create TreeSummarize query engine\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8FuhrKAvR5v"
      },
      "source": [
        "## 3. Structured Outputs with Pydantic Models\n",
        "\n",
        "**Concept:** Structured outputs ensure predictable, parseable responses using Pydantic models. This is essential for API endpoints and data pipelines.\n",
        "\n",
        "**Why it matters:** Instead of free-text responses, you get type-safe, validated data structures that applications can reliably process.\n",
        "\n",
        "Complete the function below to create a structured output system for extracting research paper information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv_F8w3HvR5w",
        "outputId": "dd23b038-92a5-41cd-d555-21e83093d046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Structured output program created\n",
            "\n",
            "🔍 Testing structured query: 'Tell me about AI agents and their capabilities'\n",
            "   (Complete the function above to get structured JSON output)\n",
            "\n",
            "💡 Expected output format:\n",
            "   - title: String\n",
            "   - key_points: List of strings\n",
            "   - applications: List of strings\n",
            "   - summary: String\n"
          ]
        }
      ],
      "source": [
        "# First, define the Pydantic models for structured outputs\n",
        "class ResearchPaperInfo(BaseModel):\n",
        "    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n",
        "    title: str = Field(description=\"The main title or concept name\")\n",
        "    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n",
        "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
        "    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n",
        "\n",
        "# Import the missing component\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "\n",
        "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
        "    \"\"\"\n",
        "    Create a structured output program using Pydantic models.\n",
        "\n",
        "    TODO: Complete this function to create a structured output program.\n",
        "    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n",
        "\n",
        "    Args:\n",
        "        output_model: Pydantic model class for structured output\n",
        "\n",
        "    Returns:\n",
        "        LLMTextCompletionProgram that returns structured data\n",
        "    \"\"\"\n",
        "    # TODO: Create output parser with the Pydantic model\n",
        "    output_parser = PydanticOutputParser(output_model)\n",
        "\n",
        "    # TODO: Create the structured output program\n",
        "    program = LLMTextCompletionProgram.from_defaults(\n",
        "        output_parser,\n",
        "        prompt_template_str=(\n",
        "            \"Extract structured investment information from the following context:\\n\"\n",
        "            \"{context}\\n\\n\"\n",
        "            \"Question: {query}\\n\\n\"\n",
        "            \"Provide the investment analysis in the specified JSON format.\"\n",
        "        ),\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    return program\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create structured output program with {output_model.__name__}\")\n",
        "    return None\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    structured_program = create_structured_output_program(ResearchPaperInfo)\n",
        "\n",
        "    if structured_program:\n",
        "        print(\"✅ Structured output program created\")\n",
        "\n",
        "        # Test with retrieval and structured extraction\n",
        "        structure_query = \"Tell me about AI agents and their capabilities\"\n",
        "        print(f\"\\n🔍 Testing structured query: '{structure_query}'\")\n",
        "\n",
        "        # Get context for structured extraction (Uncomment when implemented)\n",
        "        # retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
        "        # nodes = retriever.retrieve(structure_query)\n",
        "        # context = \"\\n\".join([node.text for node in nodes])\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = structured_program(context=context, query=structure_query)\n",
        "        # print(f\"📊 Structured Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to get structured JSON output)\")\n",
        "\n",
        "        print(\"\\n💡 Expected output format:\")\n",
        "        print(\"   - title: String\")\n",
        "        print(\"   - key_points: List of strings\")\n",
        "        print(\"   - applications: List of strings\")\n",
        "        print(\"   - summary: String\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create structured output program\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OliGXLxdvR5x"
      },
      "source": [
        "## 4. Advanced Pipeline - Combining All Techniques\n",
        "\n",
        "**Concept:** Combine multiple advanced techniques into a single powerful query engine: similarity filtering + response synthesis + structured output.\n",
        "\n",
        "**Why it matters:** Production RAG systems often need multiple techniques working together for optimal results.\n",
        "\n",
        "Complete the function below to create a comprehensive advanced RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hMHlwsKvR5x",
        "outputId": "8bcb6e27-c666-414b-a8af-f71eede1be22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TODO: Create advanced RAG pipeline with all techniques\n",
            "✅ Advanced RAG pipeline created successfully!\n",
            "   🔧 Similarity filtering: ✅\n",
            "   🌳 TreeSummarize synthesis: ✅\n",
            "\n",
            "🔍 Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n",
            "   (Complete the function above to test the full pipeline)\n",
            "\n",
            "🎯 This should provide:\n",
            "   - Filtered relevant results only\n",
            "   - Comprehensive analytical response\n",
            "   - Combined postprocessing and synthesis\n"
          ]
        }
      ],
      "source": [
        "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
        "\n",
        "    TODO: Complete this function to create the ultimate advanced RAG query engine.\n",
        "    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score for filtering\n",
        "        top_k: Number of initial results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Advanced query engine with filtering and synthesis combined\n",
        "    \"\"\"\n",
        "    # TODO: Create similarity postprocessor\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # TODO: Create TreeSummarize for comprehensive responses\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    # TODO: Create the comprehensive query engine combining both techniques\n",
        "    advanced_engine = RetrieverQueryEngine(\n",
        "        retriever=retriever,\n",
        "        response_synthesizer=tree_synthesizer,\n",
        "        node_postprocessors=[similarity_processor],\n",
        "    )\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create advanced RAG pipeline with all techniques\")\n",
        "\n",
        "    return advanced_engine\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Test the comprehensive pipeline\n",
        "if index:\n",
        "    advanced_pipeline = create_advanced_rag_pipeline(index)\n",
        "\n",
        "    if advanced_pipeline:\n",
        "        print(\"✅ Advanced RAG pipeline created successfully!\")\n",
        "        print(\"   🔧 Similarity filtering: ✅\")\n",
        "        print(\"   🌳 TreeSummarize synthesis: ✅\")\n",
        "\n",
        "        # Test with complex query\n",
        "        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n",
        "        print(f\"\\n🔍 Testing complex query: '{complex_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = advanced_pipeline.query(complex_query)\n",
        "        # print(f\"🚀 Advanced RAG Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to test the full pipeline)\")\n",
        "\n",
        "        print(\"\\n🎯 This should provide:\")\n",
        "        print(\"   - Filtered relevant results only\")\n",
        "        print(\"   - Comprehensive analytical response\")\n",
        "        print(\"   - Combined postprocessing and synthesis\")\n",
        "    else:\n",
        "        print(\"❌ Failed to create advanced RAG pipeline\")\n",
        "else:\n",
        "    print(\"❌ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kya0MjbgvR5y"
      },
      "source": [
        "## 5. Final Test - Compare Basic vs Advanced RAG\n",
        "\n",
        "Once you've completed all the functions above, run this cell to compare basic RAG with your advanced techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXKkuCguvR5y",
        "outputId": "b417ec36-e326-4c7b-cd6e-8dfbe0eae3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Advanced RAG Techniques Assignment - Final Test\n",
            "============================================================\n",
            "\n",
            "📊 Component Status:\n",
            "   ✅ Basic Index\n",
            "   ✅ Similarity Filter\n",
            "   ✅ TreeSummarize\n",
            "   ✅ Structured Output\n",
            "   ✅ Advanced Pipeline\n",
            "\n",
            "🔍 Creating basic query engine for comparison...\n",
            "\n",
            "============================================================\n",
            "🆚 COMPARISON: Basic vs Advanced RAG\n",
            "============================================================\n",
            "\n",
            "📋 Test Query 1: 'What are the key capabilities of AI agents?'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   Response: AI agents exhibit strong performance in complex tasks involving reasoning and tool execution. They thrive when provided with a defined persona, a set of tools, opportunities for human feedback, and th...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   Response: AI agents exhibit strong performance in complex tasks that involve reasoning and tool execution. They are particularly effective when they have a defined persona, access to specific tools, opportunities for human feedback, and the ability to work iteratively towards their goals. In collaborative settings, agent teams benefit from having clear leaders, defined planning phases, intelligent message filtering, and the ability to dynamically adjust team composition based on the skills required for specific sub-tasks. These capabilities enhance their effectiveness compared to single-agent architectures or less organized multi-agent systems.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "📋 Test Query 2: 'How do you evaluate agent performance metrics?'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   Response: Agent performance metrics can be evaluated using both objective and subjective measures. Objective metrics include success rate, output similarity to human responses, and overall efficiency, which pro...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   Response: Agent performance metrics can be evaluated using both objective and subjective measures. Objective metrics include success rate, output similarity to human responses, and overall efficiency, which can be assessed through benchmarks like AgentBench and SmartPlay. These benchmarks provide a structured way to evaluate agents in various environments, such as web browsing and video games.\n",
            "\n",
            "However, subjective measures are also crucial for a comprehensive evaluation. These include the efficiency of tool use, reliability, and robustness of planning, which often require human expert evaluation. This type of assessment can be more challenging and resource-intensive compared to objective metrics. Additionally, the diversity of benchmarks used for agent evaluation can complicate comparisons across different agent implementations, as many research teams create their own unique benchmarks, which may not be standardized.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "📋 Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n",
            "--------------------------------------------------\n",
            "🔹 Basic RAG:\n",
            "   Response: The benefits of multimodal AI systems include the ability to leverage diverse types of information, such as text, images, and audio, which can enhance understanding and decision-making. These systems ...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "🔸 Advanced RAG:\n",
            "   Response: The exploration of multi-agent architectures highlights several benefits and challenges associated with these systems. \n",
            "\n",
            "Benefits include the intelligent division of labor, where tasks can be distributed among agents based on their specific skills, leading to more efficient goal execution. Additionally, the collaborative nature of these architectures allows for diverse feedback from various agent personas, enhancing the overall decision-making process.\n",
            "\n",
            "However, challenges arise from the complexity of these systems. Multi-agent architectures often require significant computational resources and time to complete tasks due to the intricate algorithms and reflection steps involved. Furthermore, many existing frameworks have not been rigorously tested in more complex scenarios, which may limit their effectiveness in real-world applications that demand advanced reasoning and tool utilization.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "============================================================\n",
            "🎯 Assignment Status:\n",
            "   Completed: 5/5 components\n",
            "\n",
            "🎉 Congratulations! You've mastered Advanced RAG Techniques!\n",
            "   ✅ Node postprocessors for result filtering\n",
            "   ✅ Response synthesizers for better answers\n",
            "   ✅ Structured outputs for reliable data\n",
            "   ✅ Advanced pipelines combining all techniques\n",
            "\n",
            "🚀 You're ready for production RAG systems!\n",
            "\n",
            "💡 Key learnings:\n",
            "   - Postprocessors improve result relevance and precision\n",
            "   - Different synthesizers work better for different query types\n",
            "   - Structured outputs enable reliable system integration\n",
            "   - Advanced techniques can be combined for production systems\n"
          ]
        }
      ],
      "source": [
        "# Final comparison: Basic vs Advanced RAG\n",
        "print(\"🚀 Advanced RAG Techniques Assignment - Final Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test queries for comparison\n",
        "test_queries = [\n",
        "    \"What are the key capabilities of AI agents?\",\n",
        "    \"How do you evaluate agent performance metrics?\",\n",
        "    \"Explain the benefits and challenges of multimodal AI systems\"\n",
        "]\n",
        "\n",
        "# Check if all components were created\n",
        "components_status = {\n",
        "    \"Basic Index\": index is not None,\n",
        "    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n",
        "    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n",
        "    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n",
        "    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n",
        "}\n",
        "\n",
        "print(\"\\n📊 Component Status:\")\n",
        "for component, status in components_status.items():\n",
        "    status_icon = \"✅\" if status else \"❌\"\n",
        "    print(f\"   {status_icon} {component}\")\n",
        "\n",
        "# Create basic query engine for comparison\n",
        "if index:\n",
        "    print(\"\\n🔍 Creating basic query engine for comparison...\")\n",
        "    basic_engine = index.as_query_engine(similarity_top_k=5)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"🆚 COMPARISON: Basic vs Advanced RAG\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\n📋 Test Query {i}: '{query}'\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Basic RAG\n",
        "        print(\"🔹 Basic RAG:\")\n",
        "        if basic_engine:\n",
        "            # Uncomment when testing:\n",
        "            basic_response = basic_engine.query(query)\n",
        "            print(f\"   Response: {str(basic_response)[:200]}...\")\n",
        "            print(\"   (Standard vector search + simple response)\")\n",
        "\n",
        "        # Advanced RAG (if implemented)\n",
        "        print(\"\\n🔸 Advanced RAG:\")\n",
        "        if components_status[\"Advanced Pipeline\"]:\n",
        "            # Uncomment when testing:\n",
        "            advanced_response = advanced_pipeline.query(query)\n",
        "            print(f\"   Response: {advanced_response}\")\n",
        "            print(\"   (Filtered + TreeSummarize + Structured output)\")\n",
        "        else:\n",
        "            print(\"   Complete the advanced pipeline function to test\")\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🎯 Assignment Status:\")\n",
        "completed_count = sum(components_status.values())\n",
        "total_count = len(components_status)\n",
        "\n",
        "print(f\"   Completed: {completed_count}/{total_count} components\")\n",
        "\n",
        "if completed_count == total_count:\n",
        "    print(\"\\n🎉 Congratulations! You've mastered Advanced RAG Techniques!\")\n",
        "    print(\"   ✅ Node postprocessors for result filtering\")\n",
        "    print(\"   ✅ Response synthesizers for better answers\")\n",
        "    print(\"   ✅ Structured outputs for reliable data\")\n",
        "    print(\"   ✅ Advanced pipelines combining all techniques\")\n",
        "    print(\"\\n🚀 You're ready for production RAG systems!\")\n",
        "else:\n",
        "    missing = total_count - completed_count\n",
        "    print(f\"\\n📝 Complete {missing} more components to finish the assignment:\")\n",
        "    for component, status in components_status.items():\n",
        "        if not status:\n",
        "            print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\n💡 Key learnings:\")\n",
        "print(\"   - Postprocessors improve result relevance and precision\")\n",
        "print(\"   - Different synthesizers work better for different query types\")\n",
        "print(\"   - Structured outputs enable reliable system integration\")\n",
        "print(\"   - Advanced techniques can be combined for production systems\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa85d92d5d4a4bca87d0c9afd019788c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5b3b9ea200c48f09889040a77d23961",
              "IPY_MODEL_06534dfd40564981a08f8218a3677bee",
              "IPY_MODEL_ebe7a1d7b96b42f690fff88bbb4382d9"
            ],
            "layout": "IPY_MODEL_ac7f0e30e2bf4ba8a34b2b2bb2ba49ef"
          }
        },
        "b5b3b9ea200c48f09889040a77d23961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56649582055046f9ba277061c9962e08",
            "placeholder": "​",
            "style": "IPY_MODEL_b2ffc6e7089d41b0af01bcaaca16d72e",
            "value": "Parsing nodes: 100%"
          }
        },
        "06534dfd40564981a08f8218a3677bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da02dd472d79402d8a1ab3d01bcbca32",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_613fe50f71834b6db5302f9f9ff18f47",
            "value": 42
          }
        },
        "ebe7a1d7b96b42f690fff88bbb4382d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_724119ee647e4e068fe3171d2d15f7e3",
            "placeholder": "​",
            "style": "IPY_MODEL_036be8cb223e4b41827fccf61576466b",
            "value": " 42/42 [00:00&lt;00:00, 465.61it/s]"
          }
        },
        "ac7f0e30e2bf4ba8a34b2b2bb2ba49ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56649582055046f9ba277061c9962e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ffc6e7089d41b0af01bcaaca16d72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da02dd472d79402d8a1ab3d01bcbca32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613fe50f71834b6db5302f9f9ff18f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "724119ee647e4e068fe3171d2d15f7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036be8cb223e4b41827fccf61576466b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4db4cbf11dd44ba9796f8c38007abe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a340e4ad86ae455d9881bb8e5dd8a99c",
              "IPY_MODEL_4f2f1a589b52489f9f73ba361df333d4",
              "IPY_MODEL_15f47418c96a4083ada15b2cccc5c13d"
            ],
            "layout": "IPY_MODEL_6516ea595b9149f8bc87871067e8c01a"
          }
        },
        "a340e4ad86ae455d9881bb8e5dd8a99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f0d26a5afa4ac0bfbea684ed95b473",
            "placeholder": "​",
            "style": "IPY_MODEL_7e423a96ba3e44908ff6ba1aa822b839",
            "value": "Generating embeddings: 100%"
          }
        },
        "4f2f1a589b52489f9f73ba361df333d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c816a436274a58817b0876ca0c8a11",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d41701d50fc04ab89e64551b65d42aa7",
            "value": 90
          }
        },
        "15f47418c96a4083ada15b2cccc5c13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30297b27a80a4243834d1bc7fb07a964",
            "placeholder": "​",
            "style": "IPY_MODEL_308628783b6b4eec97940d848ffc64d8",
            "value": " 90/90 [00:00&lt;00:00, 100.88it/s]"
          }
        },
        "6516ea595b9149f8bc87871067e8c01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f0d26a5afa4ac0bfbea684ed95b473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e423a96ba3e44908ff6ba1aa822b839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c816a436274a58817b0876ca0c8a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d41701d50fc04ab89e64551b65d42aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30297b27a80a4243834d1bc7fb07a964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308628783b6b4eec97940d848ffc64d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}