{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRnLLowdCg5R"
      },
      "source": [
        "# Assignment 3b: Advanced Gradio RAG Frontend\n",
        "## Day 6 Session 2 - Building Configurable RAG Applications\n",
        "\n",
        "In this assignment, you'll extend your basic RAG interface with advanced configuration options to create a professional, feature-rich RAG application.\n",
        "\n",
        "**New Features to Add:**\n",
        "- Model selection dropdown (gpt-4o, gpt-4o-mini)\n",
        "- Temperature slider (0 to 1 with 0.1 intervals)\n",
        "- Chunk size configuration\n",
        "- Chunk overlap configuration  \n",
        "- Similarity top-k slider\n",
        "- Node postprocessor multiselect\n",
        "- Similarity cutoff slider\n",
        "- Response synthesizer multiselect\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Advanced Gradio components and interactions\n",
        "- Dynamic RAG configuration\n",
        "- Professional UI design patterns\n",
        "- Parameter validation and handling\n",
        "- Building production-ready AI applications\n",
        "\n",
        "**Prerequisites:**\n",
        "- Completed Assignment 3a (Basic Gradio RAG)\n",
        "- Understanding of RAG parameters and their effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-f6y6hSCg5V"
      },
      "source": [
        "## ðŸ“š Part 1: Setup and Imports\n",
        "\n",
        "Import all necessary libraries including advanced RAG components for configuration options.\n",
        "\n",
        "**Note:** This assignment uses OpenRouter for LLM access (not OpenAI). Make sure you have your `OPENROUTER_API_KEY` environment variable set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "project_path=\"/content/drive/MyDrive/Colab Notebooks\"\n",
        "requirements_path=os.path.join(project_path,\"requirements.txt\")\n",
        "!pip install -r \"$requirements_path\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hVRXrv0VClh4",
        "outputId": "fcb7501e-83a4-4f2a-f49e-eab5b7243331"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (4.13.5)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.28.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (2.185.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (5.49.1)\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (0.36.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (7.34.0)\n",
            "Collecting lancedb (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lancedb-0.25.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index-0.14.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-vector-stores-lancedb (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading llama_index_vector_stores_lancedb-0.4.1-py3-none-any.whl.metadata (460 bytes)\n",
            "Collecting llama-index-embeddings-huggingface (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14))\n",
            "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
            "Collecting llama-index-llms-huggingface-api (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 15))\n",
            "  Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-embeddings-openai (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 16))\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-llms-openrouter (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 19)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.109.1)\n",
            "Collecting openai-whisper (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22))\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (2.11.10)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (5.1.2)\n",
            "Collecting yt-dlp (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 25))\n",
            "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.8.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (1.71.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (0.31.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (4.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.6.4)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.14.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.49.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (4.9.0)\n",
            "Collecting deprecation (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11)) (18.1.0)\n",
            "Collecting lance-namespace>=0.0.16 (from lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lance_namespace-0.0.20-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.7 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_core-0.14.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_llms_openai-0.6.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pylance (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading pylance-0.38.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tantivy (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 13))\n",
            "  Downloading tantivy-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama-index-llms-openrouter->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 18)) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (2.8.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (3.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (4.57.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (1.16.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.4.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.0.3)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (3.13.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 9)) (5.9.1)\n",
            "Collecting lance-namespace-urllib3-client (from lance-namespace>=0.0.16->lancedb->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 11))\n",
            "  Downloading lance_namespace_urllib3_client-0.0.20-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.0)\n",
            "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_workflows-2.10.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (3.5)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (4.5.0)\n",
            "Collecting setuptools>=18.5 (from ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10))\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (8.5.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (2.0.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (0.7.1)\n",
            "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 10)) (0.2.14)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.13.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.11.1.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (0.6.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (7.4.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 24)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 14)) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 26)) (1.3.1)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 22)) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12)) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 6)) (0.1.2)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/Colab Notebooks/requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading lancedb-0.25.2-cp39-abi3-manylinux_2_28_x86_64.whl (38.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.14.7-py3-none-any.whl (7.4 kB)\n",
            "Downloading llama_index_vector_stores_lancedb-0.4.1-py3-none-any.whl (7.9 kB)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading llama_index_llms_huggingface_api-0.6.1-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_llms_openrouter-0.4.2-py3-none-any.whl (4.5 kB)\n",
            "Downloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lance_namespace-0.0.20-py3-none-any.whl (31 kB)\n",
            "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.7-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.6-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl (4.7 kB)\n",
            "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Downloading pylance-0.38.3-cp39-abi3-manylinux_2_28_x86_64.whl (48.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tantivy-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.10.2-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading lance_namespace_urllib3_client-0.0.20-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=751ecfe3baf4b0089bde136033b7499153ddcee8da79650fc7d2b6a4f21e87fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, yt-dlp, wrapt, tantivy, setuptools, pypdf, pylance, mypy-extensions, marshmallow, jedi, deprecation, colorama, aiosqlite, typing-inspect, griffe, deprecated, llama-index-instrumentation, llama-cloud, lance-namespace-urllib3-client, dataclasses-json, banks, openai-whisper, llama-index-workflows, lance-namespace, llama-index-core, lancedb, llama-index-vector-stores-lancedb, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface-api, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-openrouter, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 deprecation-2.1.0 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.14.0 jedi-0.19.2 lance-namespace-0.0.20 lance-namespace-urllib3-client-0.0.20 lancedb-0.25.2 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.7 llama-index-cli-0.5.3 llama-index-core-0.14.7 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-api-0.6.1 llama-index-llms-openai-0.6.6 llama-index-llms-openai-like-0.5.3 llama-index-llms-openrouter-0.4.2 llama-index-readers-file-0.5.4 llama-index-readers-llama-parse-0.5.1 llama-index-vector-stores-lancedb-0.4.1 llama-index-workflows-2.10.2 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 openai-whisper-20250625 pylance-0.38.3 pypdf-6.1.3 setuptools-80.9.0 striprtf-0.0.26 tantivy-0.25.0 typing-inspect-0.9.0 wrapt-1.17.3 yt-dlp-2025.10.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "b1edcd9d36ee4669b10b84a83d8603ce"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4ad61QCg5W",
        "outputId": "9a14f490-0594-45c2-b5f6-3ef7cd23dad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import gradio as gr\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "# LlamaIndex core components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§© OpenRouter + LlamaIndex Setup & Verification Cell (for Google Colab)\n",
        "!pip install -q llama-index llama-index-llms-openrouter openai\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "from llama_index.core import Settings\n",
        "\n",
        "def setup_openrouter_llm():\n",
        "    \"\"\"\n",
        "    Verify and configure OpenRouter LLM for LlamaIndex inside Google Colab.\n",
        "    \"\"\"\n",
        "    print(\"ðŸ” Step 1: Enter your OpenRouter API key (starts with sk-or-v1-...)\")\n",
        "    api_key = getpass(\"API key: \").strip()\n",
        "\n",
        "    if not api_key.startswith(\"sk-or-\"):\n",
        "        print(\"âŒ Invalid key format. Please use an OpenRouter key (sk-or-v1-...).\")\n",
        "        return\n",
        "\n",
        "    # Set environment variable for LlamaIndex + OpenAI client\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = api_key\n",
        "\n",
        "    # Initialize OpenAI client to test key validity\n",
        "    print(\"ðŸ” Step 2: Verifying your key with OpenRouter...\")\n",
        "    client = OpenAI(api_key=api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
        "    try:\n",
        "        models = client.models.list().data\n",
        "        print(f\"âœ… Key verified! Found {len(models)} available models.\")\n",
        "        print(\"   Here are a few examples:\")\n",
        "        for m in [model.id for model in models[:5]]:\n",
        "            print(\"   â€¢\", m)\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Failed to verify key:\", e)\n",
        "        return\n",
        "\n",
        "    # Configure LlamaIndex LLM\n",
        "    print(\"\\nâš™ï¸ Step 3: Configuring LlamaIndex Settings...\")\n",
        "    Settings.llm = OpenRouter(\n",
        "        api_key=api_key,\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "    # Test a simple call\n",
        "    try:\n",
        "        print(\"\\nðŸ’¬ Step 4: Testing a simple completion...\")\n",
        "        response = Settings.llm.complete(\"Say hello from OpenRouter via LlamaIndex!\")\n",
        "        print(\"âœ… Response:\", response)\n",
        "    except Exception as e:\n",
        "        print(\"âŒ LLM test failed:\", e)\n",
        "        return\n",
        "\n",
        "    print(\"\\nðŸŽ¯ Setup complete! Your LlamaIndex + OpenRouter configuration is ready.\")\n",
        "\n",
        "# ðŸš€ Run setup\n",
        "setup_openrouter_llm()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDEETDOvCpeR",
        "outputId": "7b5f7e52-cc23-417d-aa3b-25997e721c33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Step 1: Enter your OpenRouter API key (starts with sk-or-v1-...)\n",
            "API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "ðŸ” Step 2: Verifying your key with OpenRouter...\n",
            "âœ… Key verified! Found 343 available models.\n",
            "   Here are a few examples:\n",
            "   â€¢ amazon/nova-premier-v1\n",
            "   â€¢ openai/text-embedding-3-large\n",
            "   â€¢ perplexity/sonar-pro-search\n",
            "   â€¢ mistralai/voxtral-small-24b-2507\n",
            "   â€¢ openai/gpt-oss-safeguard-20b\n",
            "\n",
            "âš™ï¸ Step 3: Configuring LlamaIndex Settings...\n",
            "\n",
            "ðŸ’¬ Step 4: Testing a simple completion...\n",
            "âœ… Response: Hello from OpenRouter via LlamaIndex! How can I assist you today?\n",
            "\n",
            "ðŸŽ¯ Setup complete! Your LlamaIndex + OpenRouter configuration is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOQF94c-Cg5X"
      },
      "source": [
        "## ðŸ¤– Part 2: Advanced RAG Backend Class\n",
        "\n",
        "Create an advanced RAG backend that supports dynamic configuration of all parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_8jeoDCg5Y",
        "outputId": "55ff3c73-6d63-411e-fb5b-5a8193ea35ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Advanced RAG Backend initialized and ready!\n"
          ]
        }
      ],
      "source": [
        "class AdvancedRAGBackend:\n",
        "    \"\"\"Advanced RAG backend with configurable parameters.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.index = None\n",
        "        self.available_models = [\"gpt-4o\", \"gpt-4o-mini\"]\n",
        "        self.available_postprocessors = [\"SimilarityPostprocessor\"]\n",
        "        self.available_synthesizers = [\"TreeSummarize\", \"Refine\", \"CompactAndRefine\", \"Default\"]\n",
        "        self.update_settings()\n",
        "\n",
        "    def update_settings(self, model: str = \"gpt-4o-mini\", temperature: float = 0.1, chunk_size: int = 512, chunk_overlap: int = 50):\n",
        "        \"\"\"Update LlamaIndex settings based on user configuration.\"\"\"\n",
        "        # Set up the LLM using OpenRouter\n",
        "        api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "        if api_key:\n",
        "            Settings.llm = OpenRouter(\n",
        "                api_key=api_key,\n",
        "                model=model,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "        # Set up the embedding model (keep this constant)\n",
        "        Settings.embed_model = HuggingFaceEmbedding(\n",
        "            model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Set chunking parameters from function parameters\n",
        "        Settings.chunk_size = chunk_size\n",
        "        Settings.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def initialize_database(self, data_folder=\"/content/drive/MyDrive/content_files/data\"):\n",
        "        \"\"\"Initialize the vector database with documents.\"\"\"\n",
        "        # Check if data folder exists\n",
        "        if not Path(data_folder).exists():\n",
        "            return f\"âŒ Data folder '{data_folder}' not found!\"\n",
        "\n",
        "        try:\n",
        "            # Create vector store\n",
        "            vector_store = LanceDBVectorStore(\n",
        "                uri=\"./advanced_rag_vectordb\",\n",
        "                table_name=\"documents\"\n",
        "            )\n",
        "\n",
        "            # Load documents\n",
        "            reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "            documents = reader.load_data()\n",
        "\n",
        "            # Create storage context and index\n",
        "            storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "            self.index = VectorStoreIndex.from_documents(\n",
        "                documents,\n",
        "                storage_context=storage_context,\n",
        "                show_progress=True\n",
        "            )\n",
        "\n",
        "            return f\"âœ… Database initialized successfully with {len(documents)} documents!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error initializing database: {str(e)}\"\n",
        "\n",
        "    def get_postprocessor(self, postprocessor_name: str, similarity_cutoff: float):\n",
        "        \"\"\"Get the selected postprocessor.\"\"\"\n",
        "        if postprocessor_name == \"SimilarityPostprocessor\":\n",
        "            return SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "        elif postprocessor_name == \"None\":\n",
        "            return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_synthesizer(self, synthesizer_name: str):\n",
        "        \"\"\"Get the selected response synthesizer.\"\"\"\n",
        "        if synthesizer_name == \"TreeSummarize\":\n",
        "            return TreeSummarize()\n",
        "        elif synthesizer_name == \"Refine\":\n",
        "            return Refine()\n",
        "        elif synthesizer_name == \"CompactAndRefine\":\n",
        "            return CompactAndRefine()\n",
        "        elif synthesizer_name == \"Default\":\n",
        "            return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def advanced_query(self, question: str, model: str, temperature: float,\n",
        "                      chunk_size: int, chunk_overlap: int, similarity_top_k: int,\n",
        "                      postprocessor_names: List[str], similarity_cutoff: float,\n",
        "                      synthesizer_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"Query the RAG system with advanced configuration.\"\"\"\n",
        "\n",
        "        # Check if index exists\n",
        "        if self.index is None:\n",
        "            return {\"response\": \"âŒ Please initialize the database first!\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "        # Check if question is empty\n",
        "        if not question or not question.strip():\n",
        "            return {\"response\": \"âš ï¸ Please enter a question first!\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "        try:\n",
        "            # Update settings with new parameters\n",
        "            self.update_settings(model, temperature, chunk_size, chunk_overlap)\n",
        "\n",
        "            # Get postprocessors\n",
        "            postprocessors = []\n",
        "            for name in postprocessor_names:\n",
        "                processor = self.get_postprocessor(name, similarity_cutoff)\n",
        "                if processor is not None:\n",
        "                    postprocessors.append(processor)\n",
        "\n",
        "            # Get synthesizer\n",
        "            synthesizer = self.get_synthesizer(synthesizer_name)\n",
        "\n",
        "            # Create query engine with all parameters\n",
        "            query_engine_kwargs = {\"similarity_top_k\": similarity_top_k}\n",
        "            if postprocessors:\n",
        "                query_engine_kwargs[\"node_postprocessors\"] = postprocessors\n",
        "            if synthesizer is not None:\n",
        "                query_engine_kwargs[\"response_synthesizer\"] = synthesizer\n",
        "\n",
        "            query_engine = self.index.as_query_engine(**query_engine_kwargs)\n",
        "\n",
        "            # Query and get response\n",
        "            response = query_engine.query(question)\n",
        "\n",
        "            # Extract source information if available\n",
        "            sources = []\n",
        "            if hasattr(response, 'source_nodes'):\n",
        "                for node in response.source_nodes:\n",
        "                    sources.append({\n",
        "                        \"text\": node.text[:200] + \"...\",\n",
        "                        \"score\": getattr(node, 'score', 0.0),\n",
        "                        \"source\": getattr(node.node, 'metadata', {}).get('file_name', 'Unknown')\n",
        "                    })\n",
        "\n",
        "            return {\n",
        "                \"response\": str(response),\n",
        "                \"sources\": sources,\n",
        "                \"config\": {\n",
        "                    \"model\": model,\n",
        "                    \"temperature\": temperature,\n",
        "                    \"chunk_size\": chunk_size,\n",
        "                    \"chunk_overlap\": chunk_overlap,\n",
        "                    \"similarity_top_k\": similarity_top_k,\n",
        "                    \"postprocessors\": postprocessor_names,\n",
        "                    \"similarity_cutoff\": similarity_cutoff,\n",
        "                    \"synthesizer\": synthesizer_name\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"response\": f\"âŒ Error processing query: {str(e)}\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "# Initialize the backend\n",
        "rag_backend = AdvancedRAGBackend()\n",
        "print(\"ðŸš€ Advanced RAG Backend initialized and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3T577tCg5Y"
      },
      "source": [
        "## ðŸŽ¨ Part 3: Advanced Gradio Interface\n",
        "\n",
        "Create a sophisticated Gradio interface with all the configuration options specified:\n",
        "1. Database initialization button\n",
        "2. Search query input and button  \n",
        "3. Model selection dropdown\n",
        "4. Temperature slider\n",
        "5. Chunk size and overlap inputs\n",
        "6. Similarity top-k slider\n",
        "7. Node postprocessor multiselect\n",
        "8. Similarity cutoff slider\n",
        "9. Response synthesizer multiselect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG7Fe-M9Cg5Z",
        "outputId": "4cab8779-c0ad-4b46-f3de-47ff82848b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Advanced RAG interface created successfully!\n"
          ]
        }
      ],
      "source": [
        "def create_advanced_rag_interface():\n",
        "    \"\"\"Create advanced RAG interface with full configuration options.\"\"\"\n",
        "\n",
        "    def initialize_db():\n",
        "        \"\"\"Handle database initialization.\"\"\"\n",
        "        return rag_backend.initialize_database()\n",
        "\n",
        "    def handle_advanced_query(question, model, temperature, chunk_size, chunk_overlap,\n",
        "                             similarity_top_k, postprocessors, similarity_cutoff, synthesizer):\n",
        "        \"\"\"Handle advanced RAG queries with all configuration options.\"\"\"\n",
        "        result = rag_backend.advanced_query(\n",
        "            question, model, temperature, chunk_size, chunk_overlap,\n",
        "            similarity_top_k, postprocessors, similarity_cutoff, synthesizer\n",
        "        )\n",
        "\n",
        "        # Format configuration for display\n",
        "        config_text = f\"\"\"**Current Configuration:**\n",
        "- Model: {result['config'].get('model', 'N/A')}\n",
        "- Temperature: {result['config'].get('temperature', 'N/A')}\n",
        "- Chunk Size: {result['config'].get('chunk_size', 'N/A')}\n",
        "- Chunk Overlap: {result['config'].get('chunk_overlap', 'N/A')}\n",
        "- Similarity Top-K: {result['config'].get('similarity_top_k', 'N/A')}\n",
        "- Postprocessors: {', '.join(result['config'].get('postprocessors', []))}\n",
        "- Similarity Cutoff: {result['config'].get('similarity_cutoff', 'N/A')}\n",
        "- Synthesizer: {result['config'].get('synthesizer', 'N/A')}\"\"\"\n",
        "\n",
        "        return result[\"response\"], config_text\n",
        "\n",
        "    # TODO: Create the advanced interface structure\n",
        "    # Hint: This interface needs more complex layout with configuration controls\n",
        "\n",
        "    with gr.Blocks(title=\"Advanced RAG Assistant\") as interface:\n",
        "        # TODO: Add title and description\n",
        "        # Hint: Use gr.Markdown() for formatted text\n",
        "\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            # ðŸ§  Advanced RAG Assistant\n",
        "            Configure, initialize, and query your Retrieval-Augmented Generation system with full control.\n",
        "            \"\"\",\n",
        "        )\n",
        "\n",
        "        # Your title and description here:\n",
        "\n",
        "\n",
        "        # TODO: Add database initialization section\n",
        "        # Hint: Use gr.Button() for initialization and gr.Textbox() for status\n",
        "        # init_btn = ?\n",
        "        # status_output = ?\n",
        "        # -------------------------------\n",
        "        # Database Initialization Section\n",
        "        # -------------------------------\n",
        "        with gr.Accordion(\"ðŸ“‚ Database Initialization\", open=False):\n",
        "            gr.Markdown(\"Initialize or rebuild your document database before running queries.\")\n",
        "            init_btn = gr.Button(\"ðŸš€ Initialize Database\", variant=\"primary\")\n",
        "            status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "            init_btn.click(initialize_db, outputs=[status_output])\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Create main layout with columns\n",
        "        # Hint: Configuration controls on left, query/response on right makes sense\n",
        "        # Use gr.Row() and gr.Column() to organize this\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "\n",
        "                gr.Markdown(\"### âš™ï¸ RAG Configuration\")\n",
        "\n",
        "                # TODO: Model selection\n",
        "                # Hint: Use gr.Dropdown() with choices=[\"gpt-4o\", \"gpt-4o-mini\"]\n",
        "                # model_dropdown = ?\n",
        "                model_dropdown = gr.Dropdown(\n",
        "                    label=\"Model\",\n",
        "                    choices=rag_backend.available_models,\n",
        "                    value=\"gpt-4o-mini\"\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "                # TODO: Temperature control\n",
        "                # Hint: Use gr.Slider() with minimum=0.0, maximum=1.0, step=0.1, value=0.1\n",
        "                # temperature_slider = ?\n",
        "                temperature_slider = gr.Slider(\n",
        "                    label=\"Temperature\",\n",
        "                    minimum=0.0,\n",
        "                    maximum=1.0,\n",
        "                    step=0.1,\n",
        "                    value=0.1\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Chunking parameters\n",
        "                # Hint: Use gr.Number() for numeric inputs with default values\n",
        "                # chunk_size_input = ?  (default 512)\n",
        "\n",
        "                # chunk_overlap_input = ?  (default 50)\n",
        "                gr.Markdown(\"#### ðŸ“¦ Chunking Parameters\")\n",
        "                chunk_size_input = gr.Number(\n",
        "                    label=\"Chunk Size\", value=512, precision=0\n",
        "                )\n",
        "                chunk_overlap_input = gr.Number(\n",
        "                    label=\"Chunk Overlap\", value=50, precision=0\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Retrieval parameters\n",
        "                # Hint: Use gr.Slider() with minimum=1, maximum=20, step=1, value=5\n",
        "                # similarity_topk_slider = ?\n",
        "                gr.Markdown(\"#### ðŸ” Retrieval Parameters\")\n",
        "                similarity_topk_slider = gr.Slider(\n",
        "                    label=\"Similarity Top-K\",\n",
        "                    minimum=1,\n",
        "                    maximum=20,\n",
        "                    step=1,\n",
        "                    value=5\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Postprocessor selection\n",
        "                # Hint: Use gr.CheckboxGroup() with choices=[\"SimilarityPostprocessor\"]\n",
        "                # postprocessor_checkbox = ?\n",
        "                postprocessor_checkbox = gr.CheckboxGroup(\n",
        "                    label=\"Node Postprocessors\",\n",
        "                    choices=rag_backend.available_postprocessors,\n",
        "                    value=[\"SimilarityPostprocessor\"]\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Similarity filtering\n",
        "                # Hint: Use gr.Slider() with minimum=0.0, maximum=1.0, step=0.1, value=0.3\n",
        "                # similarity_cutoff_slider = ?\n",
        "                similarity_cutoff_slider = gr.Slider(\n",
        "                    label=\"Similarity Cutoff\",\n",
        "                    minimum=0.0,\n",
        "                    maximum=1.0,\n",
        "                    step=0.05,\n",
        "                    value=0.3\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Response synthesizer\n",
        "                # Hint: Use gr.Dropdown() with choices=[\"TreeSummarize\", \"Refine\", \"CompactAndRefine\", \"Default\"]\n",
        "                # synthesizer_dropdown = ?\n",
        "                synthesizer_dropdown = gr.Dropdown(\n",
        "                    label=\"Response Synthesizer\",\n",
        "                    choices=rag_backend.available_synthesizers,\n",
        "                    value=\"Default\"\n",
        "                )\n",
        "\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### ðŸ’¬ Query Interface\")\n",
        "\n",
        "                # TODO: Query input\n",
        "                # Hint: Use gr.Textbox() with label=\"Ask a question\", placeholder text, lines=3\n",
        "                # query_input = ?\n",
        "                query_input = gr.Textbox(\n",
        "                    label=\"Ask a Question\",\n",
        "                    placeholder=\"Example: Summarize the main findings in the dataset...\",\n",
        "                    lines=3\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Submit button\n",
        "                # Hint: Use gr.Button() with variant=\"primary\"\n",
        "                # submit_btn = ?\n",
        "                submit_btn = gr.Button(\"ðŸ” Run Query\", variant=\"primary\")\n",
        "\n",
        "\n",
        "                # TODO: Response output\n",
        "                # Hint: Use gr.Textbox() with lines=12, interactive=False\n",
        "                # response_output = ?\n",
        "                response_output = gr.Textbox(\n",
        "                    label=\"Response\",\n",
        "                    lines=12,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "\n",
        "                # TODO: Configuration display\n",
        "                # Hint: Use gr.Textbox() with lines=8, interactive=False\n",
        "                # config_display = ?\n",
        "                config_display = gr.Markdown(\n",
        "                    label=\"Configuration\",\n",
        "                    value=\"\",\n",
        "                )\n",
        "\n",
        "\n",
        "        # Uncomment to Connect functions to components\n",
        "        init_btn.click(initialize_db, outputs=[status_output])\n",
        "\n",
        "        submit_btn.click(\n",
        "                    handle_advanced_query,\n",
        "                    inputs=[\n",
        "                        query_input, model_dropdown, temperature_slider,\n",
        "                        chunk_size_input, chunk_overlap_input,\n",
        "                        similarity_topk_slider, postprocessor_checkbox,\n",
        "                        similarity_cutoff_slider, synthesizer_dropdown\n",
        "                    ],\n",
        "                    outputs=[response_output, config_display]\n",
        "                )\n",
        "\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create the interface\n",
        "advanced_interface = create_advanced_rag_interface()\n",
        "print(\"âœ… Advanced RAG interface created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjQvTNP1Cg5Z"
      },
      "source": [
        "## ðŸš€ Part 4: Launch Your Advanced Application\n",
        "\n",
        "Launch your advanced Gradio application and test all the configuration options!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vLEsFEpwCg5a",
        "outputId": "d4571e05-3752-4fcc-ba81-3b694a116721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ Launching your Advanced RAG Assistant...\n",
            "ðŸ”— Your application will open in a new browser tab!\n",
            "\n",
            "âš ï¸  Make sure your OPENROUTER_API_KEY environment variable is set!\n",
            "\n",
            "ðŸ“‹ Testing Instructions:\n",
            "1. Click 'Initialize Vector Database' button first\n",
            "2. Wait for success message\n",
            "3. Configure your RAG parameters:\n",
            "   - Choose model (gpt-4o, gpt-4o-mini)\n",
            "   - Adjust temperature (0.0 = deterministic, 1.0 = creative)\n",
            "   - Set chunk size and overlap\n",
            "   - Choose similarity top-k\n",
            "   - Select postprocessors and synthesizer\n",
            "4. Enter a question and click 'Ask Question'\n",
            "5. Review both the response and configuration used\n",
            "\n",
            "ðŸ§ª Experiments to try:\n",
            "- Compare different models with the same question\n",
            "- Test temperature effects (0.1 vs 0.9)\n",
            "- Try different chunk sizes (256 vs 1024)\n",
            "- Compare synthesizers (TreeSummarize vs Refine)\n",
            "- Adjust similarity cutoff to filter results\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://027a0d1c7a74e36a2c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://027a0d1c7a74e36a2c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"ðŸŽ‰ Launching your Advanced RAG Assistant...\")\n",
        "print(\"ðŸ”— Your application will open in a new browser tab!\")\n",
        "print(\"\")\n",
        "print(\"âš ï¸  Make sure your OPENROUTER_API_KEY environment variable is set!\")\n",
        "print(\"\")\n",
        "print(\"ðŸ“‹ Testing Instructions:\")\n",
        "print(\"1. Click 'Initialize Vector Database' button first\")\n",
        "print(\"2. Wait for success message\")\n",
        "print(\"3. Configure your RAG parameters:\")\n",
        "print(\"   - Choose model (gpt-4o, gpt-4o-mini)\")\n",
        "print(\"   - Adjust temperature (0.0 = deterministic, 1.0 = creative)\")\n",
        "print(\"   - Set chunk size and overlap\")\n",
        "print(\"   - Choose similarity top-k\")\n",
        "print(\"   - Select postprocessors and synthesizer\")\n",
        "print(\"4. Enter a question and click 'Ask Question'\")\n",
        "print(\"5. Review both the response and configuration used\")\n",
        "print(\"\")\n",
        "print(\"ðŸ§ª Experiments to try:\")\n",
        "print(\"- Compare different models with the same question\")\n",
        "print(\"- Test temperature effects (0.1 vs 0.9)\")\n",
        "print(\"- Try different chunk sizes (256 vs 1024)\")\n",
        "print(\"- Compare synthesizers (TreeSummarize vs Refine)\")\n",
        "print(\"- Adjust similarity cutoff to filter results\")\n",
        "\n",
        "# Your code here:\n",
        "advanced_interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xmml4MgCg5a"
      },
      "source": [
        "## ðŸ’¡ Understanding the Configuration Options\n",
        "\n",
        "### Model Selection\n",
        "- **gpt-4o**: Latest and most capable model, best quality responses\n",
        "- **gpt-4o-mini**: Faster and cheaper while maintaining good quality\n",
        "\n",
        "### Temperature (0.0 - 1.0)\n",
        "- **0.0-0.3**: Deterministic, factual responses\n",
        "- **0.4-0.7**: Balanced creativity and accuracy\n",
        "- **0.8-1.0**: More creative and varied responses\n",
        "\n",
        "### Chunk Size & Overlap\n",
        "- **Chunk Size**: How much text to process at once (256-1024 typical)\n",
        "- **Chunk Overlap**: Overlap between chunks to maintain context (10-100 typical)\n",
        "\n",
        "### Similarity Top-K (1-20)\n",
        "- **Lower values (3-5)**: More focused, faster responses\n",
        "- **Higher values (8-15)**: More comprehensive, detailed responses\n",
        "\n",
        "### Node Postprocessors\n",
        "- **SimilarityPostprocessor**: Filters out low-relevance documents\n",
        "\n",
        "### Similarity Cutoff (0.0-1.0)\n",
        "- **0.1-0.3**: More permissive, includes potentially relevant docs\n",
        "- **0.5-0.8**: More strict, only highly relevant docs\n",
        "\n",
        "### Response Synthesizers\n",
        "- **TreeSummarize**: Hierarchical summarization, good for complex topics\n",
        "- **Refine**: Iterative refinement, builds detailed responses\n",
        "- **CompactAndRefine**: Efficient version of Refine\n",
        "- **Default**: Standard synthesis approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri_XptcaCg5b"
      },
      "source": [
        "## âœ… Assignment Completion Checklist\n",
        "\n",
        "Before submitting, ensure you have:\n",
        "\n",
        "- [ ] Set up your OPENROUTER_API_KEY environment variable\n",
        "- [ ] Imported all necessary libraries including advanced RAG components\n",
        "- [ ] Created AdvancedRAGBackend class with configurable parameters\n",
        "- [ ] Implemented all required methods:\n",
        "  - [ ] `update_settings()` - Updates LLM and chunking parameters\n",
        "  - [ ] `initialize_database()` - Sets up vector database\n",
        "  - [ ] `get_postprocessor()` - Returns selected postprocessor\n",
        "  - [ ] `get_synthesizer()` - Returns selected synthesizer\n",
        "  - [ ] `advanced_query()` - Handles queries with all configuration options\n",
        "- [ ] Created advanced Gradio interface with all required components:\n",
        "  - [ ] Initialize database button\n",
        "  - [ ] Model selection dropdown (gpt-4o, gpt-4o-mini)\n",
        "  - [ ] Temperature slider (0 to 1, step 0.1)\n",
        "  - [ ] Chunk size input (default 512)\n",
        "  - [ ] Chunk overlap input (default 50)\n",
        "  - [ ] Similarity top-k slider (1 to 20, default 5)\n",
        "  - [ ] Node postprocessor multiselect\n",
        "  - [ ] Similarity cutoff slider (0.0 to 1.0, step 0.1, default 0.3)\n",
        "  - [ ] Response synthesizer dropdown\n",
        "  - [ ] Query input and submit button\n",
        "  - [ ] Response output\n",
        "  - [ ] Configuration display\n",
        "- [ ] Connected all components to backend functions\n",
        "- [ ] Successfully launched the application\n",
        "- [ ] Tested different parameter combinations\n",
        "- [ ] Verified all configuration options work correctly\n",
        "\n",
        "## ðŸŽŠ Congratulations!\n",
        "\n",
        "You've successfully built a professional, production-ready RAG application! You now have:\n",
        "\n",
        "- **Advanced Parameter Control**: Full control over all RAG system parameters\n",
        "- **Professional UI**: Clean, organized interface with proper layout\n",
        "- **Real-time Configuration**: Ability to experiment with different settings\n",
        "- **Production Patterns**: Understanding of how to build scalable AI applications\n",
        "\n",
        "## ðŸš€ Next Steps & Extensions\n",
        "\n",
        "**Potential Enhancements:**\n",
        "1. **Authentication**: Add user login and session management\n",
        "2. **Document Upload**: Allow users to upload their own documents\n",
        "3. **Chat History**: Implement conversation memory\n",
        "4. **Performance Monitoring**: Add response time and quality metrics\n",
        "5. **A/B Testing**: Compare different configurations side-by-side\n",
        "6. **Export Features**: Download responses and configurations\n",
        "7. **Advanced Visualizations**: Show document similarity scores and retrieval paths\n",
        "\n",
        "**Deployment Options:**\n",
        "- **Local**: Run on your machine for development\n",
        "- **Gradio Cloud**: Deploy with `interface.launch(share=True)`\n",
        "- **Hugging Face Spaces**: Deploy to Hugging Face for public access\n",
        "- **Docker**: Containerize for scalable deployment\n",
        "- **Cloud Platforms**: Deploy to AWS, GCP, or Azure\n",
        "\n",
        "You're now ready to build sophisticated AI-powered applications!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}