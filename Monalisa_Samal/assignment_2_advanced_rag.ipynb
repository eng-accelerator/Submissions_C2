{"cells":[{"cell_type":"markdown","metadata":{"id":"81YKC_3kYchN"},"source":["# Assignment 2: Advanced RAG Techniques\n","## Day 6 Session 2 - Advanced RAG Fundamentals\n","\n","**OBJECTIVE:** Implement advanced RAG techniques including postprocessors, response synthesizers, and structured outputs.\n","\n","**LEARNING GOALS:**\n","- Understand and implement node postprocessors for filtering and reranking\n","- Learn different response synthesis strategies (TreeSummarize, Refine)\n","- Create structured outputs using Pydantic models\n","- Build advanced retrieval pipelines with multiple processing stages\n","\n","**DATASET:** Use the same data folder as Assignment 1 (`Day_6/session_2/data/`)\n","\n","**PREREQUISITES:** Complete Assignment 1 first\n","\n","**INSTRUCTIONS:**\n","1. Complete each function by replacing the TODO comments with actual implementation\n","2. Run each cell after completing the function to test it\n","3. The answers can be found in the `03_advanced_rag_techniques.ipynb` notebook\n","4. Each technique builds on the previous one\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZrAeu6IY2T_","executionInfo":{"status":"ok","timestamp":1762089683825,"user_tz":-330,"elapsed":1950,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"83f2ce92-9423-4551-a26e-5bb3b961b29d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# If it's in a specific folder (e.g., \"Projects/MyProject/\")\n","!pip install -r '/content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d1faFFvY9wc","executionInfo":{"status":"ok","timestamp":1762089695753,"user_tz":-330,"elapsed":9079,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"2247e8bb-33dc-47be-8118-1d5ea02707b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 1)) (4.13.5)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (2.28.0)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 3)) (2.185.0)\n","Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 4)) (2.38.0)\n","Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (5.49.1)\n","Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 7)) (1.13.3)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 8)) (0.36.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (6.17.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (7.34.0)\n","Requirement already satisfied: lancedb in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 11)) (0.25.2)\n","Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.14.7)\n","Requirement already satisfied: llama-index-vector-stores-lancedb in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 13)) (0.4.1)\n","Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (0.6.1)\n","Requirement already satisfied: llama-index-llms-huggingface-api in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 15)) (0.6.1)\n","Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 16)) (0.5.1)\n","Requirement already satisfied: llama-index-llms-openrouter in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 17)) (0.4.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 18)) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 19)) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 20)) (2.2.2)\n","Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 21)) (1.109.1)\n","Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (20250625)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 23)) (2.11.10)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (5.1.2)\n","Requirement already satisfied: yt-dlp in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 25)) (2025.10.22)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (3.8.7)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 1)) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 1)) (4.15.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (1.71.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (5.29.5)\n","Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (1.26.1)\n","Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (2.32.4)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 3)) (0.31.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 3)) (4.2.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 4)) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 4)) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 4)) (4.9.1)\n","Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (24.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (4.11.0)\n","Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.120.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.6.4)\n","Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.1.2)\n","Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (3.0.3)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (3.11.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (25.0)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (11.3.0)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (6.0.3)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.14.2)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.1.7)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.49.1)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.13.3)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.20.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.38.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 7)) (2025.3.0)\n","Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 7)) (15.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 8)) (3.20.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 8)) (4.67.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 8)) (1.2.0)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (1.8.15)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (7.4.9)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (0.2.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (1.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (5.9.5)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (26.2.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (6.5.1)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (5.7.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (80.9.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (3.0.52)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (4.9.0)\n","Requirement already satisfied: deprecation in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 11)) (18.1.0)\n","Requirement already satisfied: lance-namespace>=0.0.16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 11)) (0.0.20)\n","Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.5.3)\n","Requirement already satisfied: llama-index-core<0.15.0,>=0.14.7 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.14.7)\n","Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.9.4)\n","Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.6.6)\n","Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.5.4)\n","Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: pylance in /usr/local/lib/python3.12/dist-packages (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 13)) (0.38.3)\n","Requirement already satisfied: tantivy in /usr/local/lib/python3.12/dist-packages (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 13)) (0.25.0)\n","Requirement already satisfied: llama-index-llms-openai-like<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openrouter->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 17)) (0.5.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 18)) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 18)) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 18)) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 20)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 20)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 20)) (2025.2)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 21)) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 21)) (0.11.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 21)) (1.3.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (10.8.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (0.60.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (0.12.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (2.8.0+cu126)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (3.4.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 23)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 23)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 23)) (0.4.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (4.57.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (1.16.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.0.13)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (3.0.10)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (0.4.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (3.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (3.11)\n","Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.0.3)\n","Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 3)) (3.2.5)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.16.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (3.13.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.8.5)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (0.4)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 9)) (5.9.1)\n","Requirement already satisfied: lance-namespace-urllib3-client in /usr/local/lib/python3.12/dist-packages (from lance-namespace>=0.0.16->lancedb->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 11)) (0.0.20)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.3.0)\n","Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.21.0)\n","Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (2.2.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.2.18)\n","Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.0.8)\n","Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.2.0)\n","Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (2.10.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (3.5)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (4.5.0)\n","Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (2.0.44)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (8.5.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.17.3)\n","Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.1.35)\n","Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.7.1)\n","Requirement already satisfied: pypdf<7,>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (6.1.3)\n","Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.0.26)\n","Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.6.54)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 10)) (0.2.14)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 4)) (0.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 20)) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 2)) (2.5.0)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (0.1.5)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (1.13.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (1.11.1.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (0.6.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (7.4.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (0.43.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 24)) (3.6.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 14)) (1.22.0)\n","Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.14.0)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 26)) (1.3.1)\n","Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.4.2)\n","Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.6.54)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (4.0.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (3.2.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 22)) (1.3.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.1.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (3.26.1)\n","Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (1.2.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 6)) (0.1.2)\n","Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.7->llama-index->-r /content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/requirements.txt (line 12)) (0.4.6)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlT1dnXjYchO","executionInfo":{"status":"ok","timestamp":1762089698115,"user_tz":-330,"elapsed":10,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"740c93db-ab39-4f37-edeb-93b9c8580141"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Advanced RAG libraries imported successfully!\n"]}],"source":["# Import required libraries for advanced RAG\n","import os\n","from pathlib import Path\n","from typing import Dict, List, Optional, Any\n","from pydantic import BaseModel, Field\n","\n","# Core LlamaIndex components\n","from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n","from llama_index.core.query_engine import RetrieverQueryEngine\n","from llama_index.core.retrievers import VectorIndexRetriever\n","\n","# Vector store\n","from llama_index.vector_stores.lancedb import LanceDBVectorStore\n","\n","# Embeddings and LLM\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.llms.openrouter import OpenRouter\n","\n","# Advanced RAG components (we'll use these in the assignments)\n","from llama_index.core.postprocessor import SimilarityPostprocessor\n","from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n","from llama_index.core.output_parsers import PydanticOutputParser\n","\n","print(\"âœ… Advanced RAG libraries imported successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_3uIzeMYchP","executionInfo":{"status":"ok","timestamp":1762089706600,"user_tz":-330,"elapsed":3209,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"42778bab-2cb4-44d2-a7c8-0d03aa468ae9"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… OpenRouter API key found in Colab secrets\n","âœ… Advanced RAG settings configured\n","   - Chunk size: 512 (optimized for precision)\n","   - Using local embeddings for cost efficiency\n","   - OpenRouter LLM ready for response synthesis\n"]}],"source":["# Configure Advanced RAG Settings (Using OpenRouter)\n","def setup_advanced_rag_settings():\n","    \"\"\"\n","    Configure LlamaIndex with optimized settings for advanced RAG.\n","    Uses local embeddings and OpenRouter for LLM operations.\n","    \"\"\"\n","    # Check for OpenRouter API key\n","\n","    from google.colab import userdata\n","\n","    try:\n","        api_key = userdata.get('OPEN_ROUTER')  #  your named your secret\n","        print(\"âœ… OpenRouter API key found in Colab secrets\")\n","    except Exception:\n","        print(\"â„¹ï¸  OPENROUTER_API_KEY not found - that's OK for this assignment!\")\n","        print(\"   This assignment only uses local embeddings for vector operations.\")\n","\n","\n","        # Configure OpenRouter LLM\n","        Settings.llm = OpenRouter(\n","            api_key=api_key,\n","            model=\"gpt-4o\",\n","            temperature=0.1  # Lower temperature for more consistent responses\n","        )\n","\n","    # Configure local embeddings (no API key required)\n","    Settings.embed_model = HuggingFaceEmbedding(\n","        model_name=\"BAAI/bge-small-en-v1.5\",\n","        trust_remote_code=True\n","    )\n","\n","    # Advanced RAG configuration\n","    Settings.chunk_size = 512  # Smaller chunks for better precision\n","    Settings.chunk_overlap = 50\n","\n","    print(\"âœ… Advanced RAG settings configured\")\n","    print(\"   - Chunk size: 512 (optimized for precision)\")\n","    print(\"   - Using local embeddings for cost efficiency\")\n","    print(\"   - OpenRouter LLM ready for response synthesis\")\n","\n","# Setup the configuration\n","setup_advanced_rag_settings()\n"]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","# Get the token from Colab secrets\n","hf_token = userdata.get('HF_TOKEN')\n","\n","# Set as environment variable (optional)\n","os.environ['HF_TOKEN'] = hf_token\n","\n","# Use with Hugging Face libraries\n","from huggingface_hub import login\n","login(token=hf_token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7mg0QC3nmgs","executionInfo":{"status":"ok","timestamp":1762089712808,"user_tz":-330,"elapsed":899,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"4fc230c4-a763-4c1a-b640-85f2e1e67f42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["a9d4ddd2138e497f9050b59d4a579687","28265196138e4fc2b71a6f28b6c9ae0c","a341f62d1b374c63b71f478afe421377","1a852a69c3274338bd6634fb0c16a457","d1a87baee2b34ff39294a9957609ae33","0b6a9975c3a84f048b3b34e678c1a3d8","70441a90759e419fbc118642ee3afeb8","e80346f88fa049f9bc4690b520faeadf","2607a80a19ef469a852a574dde7deec9","752bdeb9460947cdb9731e87828b93c7","a9a4ffd40f97484fa39374570f6fd006","18aba1e55c084b45a59d723c920649db","a8395d6fb02e49cb8062308a40db32b8","4d2373e1731b46f6960ae50e48ea2d33","cc18d8a0b8904643a0cd1f13b7ba8bd3","e051a3be3c35478cbd343dbacdd48acf","a011adb7c30245deb082532acfd038cb","4208e397a3a7458aa5b16c91bc7b5ac8","f1c05ad90ee74a1fbb77d618ff193971","656d18ae543a463ea98145be9cc6771e","6141e0010d114134ba65680c86be8720","c86f10069df241d3adfcf0f884a61389"]},"id":"IseBtxKeYchP","executionInfo":{"status":"ok","timestamp":1762089804808,"user_tz":-330,"elapsed":87443,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"467cb814-9deb-4ca1-a7ea-1d41a4dd38f0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"display_data","data":{"text/plain":["Parsing nodes:   0%|          | 0/42 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d4ddd2138e497f9050b59d4a579687"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating embeddings:   0%|          | 0/93 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18aba1e55c084b45a59d723c920649db"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… Basic index created with 42 documents\n","   Ready for advanced RAG techniques!\n","ðŸ“ Setting up basic index for advanced RAG...\n","ðŸš€ Ready to implement advanced RAG techniques!\n"]}],"source":["# Setup: Create index from Assignment 1 (reuse the basic functionality)\n","def setup_basic_index(data_folder: str = \"/content/drive/MyDrive/ai-accelerator-C2-main/Day_6/session_2/data\", force_rebuild: bool = False):\n","    \"\"\"\n","    Create a basic vector index that we'll enhance with advanced techniques.\n","    This reuses the concepts from Assignment 1.\n","    \"\"\"\n","    # Create vector store\n","    vector_store = LanceDBVectorStore(\n","        uri=\"./advanced_rag_vectordb\",\n","        table_name=\"documents\"\n","    )\n","\n","    # Load documents\n","    if not Path(data_folder).exists():\n","        print(f\"âŒ Data folder not found: {data_folder}\")\n","        return None\n","\n","    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n","    documents = reader.load_data()\n","\n","    # Create storage context and index\n","    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n","    index = VectorStoreIndex.from_documents(\n","        documents,\n","        storage_context=storage_context,\n","        show_progress=True\n","    )\n","\n","    print(f\"âœ… Basic index created with {len(documents)} documents\")\n","    print(\"   Ready for advanced RAG techniques!\")\n","\n","    # Create the basic index\n","    print(\"ðŸ“ Setting up basic index for advanced RAG...\")\n","\n","\n","    return index\n","\n","# Create the basic index\n","index = setup_basic_index()\n","if index:\n","    print(\"ðŸš€ Ready to implement advanced RAG techniques!\")\n","else:\n","    print(\"âŒ Failed to create index - check data folder path\")\n"]},{"cell_type":"markdown","metadata":{"id":"FS0WPW2sYchP"},"source":["## 1. Node Postprocessors - Similarity Filtering\n","\n","**Concept:** Postprocessors refine retrieval results after the initial vector search. The `SimilarityPostprocessor` filters out chunks that fall below a relevance threshold.\n","\n","**Why it matters:** Raw vector search often returns some irrelevant results. Filtering improves precision and response quality.\n","\n","Complete the function below to create a query engine with similarity filtering.\n"]},{"cell_type":"code","source":["# First install the huggingface integration\n","!pip install llama-index-llms-huggingface"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qUVNJbhLlnW-","executionInfo":{"status":"ok","timestamp":1762089836938,"user_tz":-330,"elapsed":5165,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"3a1c34da-7a79-4e29-dd6f-d0d3b10668f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: llama-index-llms-huggingface in /usr/local/lib/python3.12/dist-packages (0.6.1)\n","Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-huggingface) (0.14.7)\n","Requirement already satisfied: torch<3,>=2.1.2 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-huggingface) (2.8.0+cu126)\n","Requirement already satisfied: transformers<5,>=4.37.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (4.57.1)\n","Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.13.1)\n","Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.21.0)\n","Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.2.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.6.7)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.2.18)\n","Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.0.8)\n","Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.2.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2025.3.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.28.1)\n","Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.10.2)\n","Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.5)\n","Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.2)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (11.3.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.5.0)\n","Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.11.10)\n","Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (6.0.3)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.32.4)\n","Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (80.9.0)\n","Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.0.44)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (8.5.0)\n","Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.12.0)\n","Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.67.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.15.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.9.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.20.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.1.2->llama-index-llms-huggingface) (3.4.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (0.36.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (25.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (0.6.2)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.11.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.22.0)\n","Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.37.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.2.0)\n","Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.5.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.2.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.1.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (3.26.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.1.2->llama-index-llms-huggingface) (3.0.3)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (1.3.1)\n","Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-huggingface) (0.4.6)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NXdeLi2NYchP","executionInfo":{"status":"ok","timestamp":1762091882924,"user_tz":-330,"elapsed":2769,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"18aab0d1-d8e5-46de-853f-f1b47f858471"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… OpenAI API key loaded from Colab secrets\n","âœ… OpenAI LLM configured successfully\n","âœ… Query engine with similarity cutoff 0.3 created\n","âœ… Query engine with similarity filtering created\n","\n","ðŸ” Testing query: 'What are the benefits of AI agents?'\n","ðŸ“ Response: The benefits of AI agents include their enhanced reasoning, planning, and tool execution capabilities, which enable them to achieve complex goals efficiently. Additionally, AI agents can communicate effectively, adapt to different scenarios, and work collaboratively in both single-agent and multi-agent architectures.\n"]}],"source":["import os\n","from google.colab import userdata\n","from llama_index.llms.openai import OpenAI\n","from llama_index.core import Settings\n","from llama_index.core.postprocessor import SimilarityPostprocessor\n","\n","# Get OpenAI API key from Colab secrets\n","try:\n","    openai_api_key = userdata.get('OPENAI_API')  # Your secret name\n","    os.environ[\"OPENAI_API_KEY\"] = openai_api_key  # What OpenAI expects\n","    print(\"âœ… OpenAI API key loaded from Colab secrets\")\n","except Exception as e:\n","    print(f\"âŒ Error loading OpenAI API key from secrets: {e}\")\n","    print(\"ðŸ’¡ Make sure you have added 'OPENAI_API' to your Colab secrets\")\n","    print(\"   Go to the key icon (ðŸ”‘) in the left sidebar and add your key\")\n","\n","# Use OpenAI which handles long contexts much better\n","Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", max_tokens=256)\n","print(\"âœ… OpenAI LLM configured successfully\")\n","\n","def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 5):\n","    \"\"\"\n","    Create a query engine that filters results based on similarity scores.\n","\n","    TODO: Complete this function to create a query engine with similarity postprocessing.\n","    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n","\n","    Args:\n","        index: Vector index to query\n","        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n","        top_k: Number of initial results to retrieve before filtering\n","\n","    Returns:\n","        Query engine with similarity filtering\n","    \"\"\"\n","    try:\n","        # TODO: Create similarity postprocessor with the cutoff threshold\n","        similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n","\n","        # TODO: Create query engine with similarity filtering\n","        query_engine = index.as_query_engine(\n","            similarity_top_k=top_k,\n","            node_postprocessors=[similarity_processor]\n","        )\n","\n","        print(f\"âœ… Query engine with similarity cutoff {similarity_cutoff} created\")\n","        return query_engine\n","\n","    except Exception as e:\n","        print(f\"âŒ Error creating query engine: {e}\")\n","        return None\n","\n","# Test the function with error handling\n","if 'index' in locals() and index:\n","    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3, top_k=3)\n","\n","    if filtered_engine:\n","        print(\"âœ… Query engine with similarity filtering created\")\n","\n","        # Test query\n","        test_query = \"What are the benefits of AI agents?\"\n","        print(f\"\\nðŸ” Testing query: '{test_query}'\")\n","\n","        try:\n","            response = filtered_engine.query(test_query)\n","            print(f\"ðŸ“ Response: {response}\")\n","        except Exception as e:\n","            print(f\"âŒ Error during query: {e}\")\n","            print(\"ðŸ’¡ Try using a different model or check your data preprocessing\")\n","    else:\n","        print(\"âŒ Failed to create filtered query engine\")\n","else:\n","    print(\"âŒ No index available - run previous cells first\")"]},{"cell_type":"markdown","metadata":{"id":"X8qGszd0YchP"},"source":["## 2. Response Synthesizers - TreeSummarize\n","\n","**Concept:** Response synthesizers control how retrieved information becomes final answers. `TreeSummarize` builds responses hierarchically, ideal for complex analytical questions.\n","\n","**Why it matters:** Different synthesis strategies work better for different query types. TreeSummarize excels at comprehensive analysis and long-form responses.\n","\n","Complete the function below to create a query engine with TreeSummarize response synthesis.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"th0Kz2rMYchP","executionInfo":{"status":"ok","timestamp":1762092383190,"user_tz":-330,"elapsed":4006,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"b704bba9-0419-421a-d682-018420b6046e"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Create query engine with TreeSummarize synthesis\n","âœ… Query engine with TreeSummarize created\n","\n","ðŸ” Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n","ðŸ“ TreeSummarize Response:\n","Advantages and disadvantages of different AI agent frameworks can be compared based on factors such as complexity, learning curve, best use case, performance considerations, and suitability for different tasks. Frameworks like LangChain offer a moderate complexity level and are suitable for general LLM applications, while AutoGPT is known for its high complexity and steep learning curve, making it ideal for autonomous tasks. CrewAI, on the other hand, has a medium complexity level with an easy learning curve, making it suitable for team collaboration. LlamaIndex stands out with low complexity and ease of use, making it a good fit for document Q&A tasks. Performance considerations show that single agents typically have lower latency compared to multi-agent systems, but the latter are often more accurate for complex tasks. However, more agents in a system can lead to higher API costs. In terms of reliability, simpler frameworks are generally more stable. When choosing the right framework, beginners may find LlamaIndex or simple LangChain suitable, while those tackling complex tasks may benefit from using AutoGPT or multi-agent systems.\n"]}],"source":["def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n","    \"\"\"\n","    Create a query engine that uses TreeSummarize for comprehensive responses.\n","\n","    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n","    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n","\n","    Args:\n","        index: Vector index to query\n","        top_k: Number of results to retrieve\n","\n","    Returns:\n","        Query engine with TreeSummarize synthesis\n","    \"\"\"\n","    # TODO: Create TreeSummarize response synthesizer\n","    tree_synthesizer =TreeSummarize()\n","\n","    # TODO: Create query engine with the synthesizer\n","    query_engine = index.as_query_engine(\n","        response_synthesizer=tree_synthesizer,\n","        similarity_top_k=top_k\n","    )\n","\n","\n","\n","    # PLACEHOLDER - Replace with actual implementation\n","    print(f\"âœ… Create query engine with TreeSummarize synthesis\")\n","\n","    return query_engine\n","\n","\n","# Test the function\n","if index:\n","    tree_engine = create_query_engine_with_tree_summarize(index)\n","\n","    if tree_engine:\n","        print(\"âœ… Query engine with TreeSummarize created\")\n","\n","        # Test with a complex analytical query\n","        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n","        print(f\"\\nðŸ” Testing analytical query: '{analytical_query}'\")\n","\n","        try:\n","            response = tree_engine.query(analytical_query)\n","            print(f\"ðŸ“ TreeSummarize Response:\\n{response}\")\n","        except Exception as e:\n","            print(f\"âŒ Error during query: {e}\")\n","        # Uncomment when implemented:\n","\n","\n","\n","    else:\n","        print(\"âŒ Failed to create TreeSummarize query engine\")\n","else:\n","    print(\"âŒ No index available - run previous cells first\")\n"]},{"cell_type":"markdown","metadata":{"id":"abAfqxgnYchQ"},"source":["## 3. Structured Outputs with Pydantic Models\n","\n","**Concept:** Structured outputs ensure predictable, parseable responses using Pydantic models. This is essential for API endpoints and data pipelines.\n","\n","**Why it matters:** Instead of free-text responses, you get type-safe, validated data structures that applications can reliably process.\n","\n","Complete the function below to create a structured output system for extracting research paper information.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0AwVrGwYchQ","executionInfo":{"status":"ok","timestamp":1762095388759,"user_tz":-330,"elapsed":1762,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"eb3b067d-9dcb-407b-da11-60369ca3032f"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ…: Create structured output program with ResearchPaperInfo\n","âœ… Structured output program created\n","\n","ðŸ” Testing structured query: 'Tell me about AI agents and their capabilities'\n","ðŸ“Š Structured Response:\n","title='AI Agents and Their Capabilities' key_points=['Architectures leveraging advanced techniques are more effective across various benchmarks and problem types', 'Current AI-driven agents show promise but have notable limitations and areas for improvement', 'Challenges around agent benchmarks, real-world applicability, and mitigating harmful biases need to be addressed for reliable agents'] applications=[] summary='The survey explores the progression from static language models to dynamic, autonomous agents, providing a comprehensive understanding of the current AI agent landscape and insights for developers.'\n"]}],"source":["# First, define the Pydantic models for structured outputs\n","class ResearchPaperInfo(BaseModel):\n","    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n","    title: str = Field(description=\"The main title or concept name\")\n","    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n","    applications: List[str] = Field(description=\"Practical applications or use cases\")\n","    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n","\n","# Import the missing component\n","from llama_index.core.program import LLMTextCompletionProgram\n","\n","def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n","    \"\"\"\n","    Create a structured output program using Pydantic models.\n","\n","    TODO: Complete this function to create a structured output program.\n","    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n","\n","    Args:\n","        output_model: Pydantic model class for structured output\n","\n","    Returns:\n","        LLMTextCompletionProgram that returns structured data\n","    \"\"\"\n","    # TODO: Create output parser with the Pydantic model\n","    output_parser = PydanticOutputParser(output_model)\n","\n","    # TODO: Create the structured output program\n","    program = LLMTextCompletionProgram.from_defaults(\n","        output_parser=output_parser,\n","        prompt_template_str=(\n","            \"Extract structured information from the following context:\\n\"\n","            \"{context}\\n\\n\"\n","            \"Question: {query}\\n\\n\"\n","            \"Provide the information in the specified JSON format.\"\n","        )\n","    )\n","\n","    print(f\"âœ…: Create structured output program with {output_model.__name__}\")\n","\n","    return program\n","\n","\n","\n","# Test the function\n","if index:\n","    structured_program = create_structured_output_program(ResearchPaperInfo)\n","\n","    if structured_program:\n","        print(\"âœ… Structured output program created\")\n","\n","        # Test with retrieval and structured extraction\n","        structure_query = \"Tell me about AI agents and their capabilities\"\n","        print(f\"\\nðŸ” Testing structured query: '{structure_query}'\")\n","\n","        # Get context for structured extraction (Uncomment when implemented)\n","        retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n","        nodes = retriever.retrieve(structure_query)\n","        context = \"\\n\".join([node.text for node in nodes])\n","\n","\n","        response = structured_program(context=context, query=structure_query)\n","        print(f\"ðŸ“Š Structured Response:\\n{response}\")\n","\n","    else:\n","        print(\"âŒ Failed to create structured output program\")\n","else:\n","    print(\"âŒ No index available - run previous cells first\")\n"]},{"cell_type":"markdown","metadata":{"id":"cuS2ueNtYchQ"},"source":["## 4. Advanced Pipeline - Combining All Techniques\n","\n","**Concept:** Combine multiple advanced techniques into a single powerful query engine: similarity filtering + response synthesis + structured output.\n","\n","**Why it matters:** Production RAG systems often need multiple techniques working together for optimal results.\n","\n","Complete the function below to create a comprehensive advanced RAG pipeline.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsKSzjscYchQ","executionInfo":{"status":"ok","timestamp":1762095552846,"user_tz":-330,"elapsed":2667,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"f16ed629-552a-47e5-8e66-8f0cde752139"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… : Create advanced RAG pipeline with all techniques\n","âœ… Advanced RAG pipeline created successfully!\n","   ðŸ”§ Similarity filtering: âœ…\n","   ðŸŒ³ TreeSummarize synthesis: âœ…\n","\n","ðŸ” Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n","ðŸš€ Advanced RAG Response:\n","The current state of AI agent technologies shows promising advancements in achieving complex goals that require enhanced reasoning, planning, and tool execution capabilities. Architectures leveraging these techniques have demonstrated effectiveness across various benchmarks and problem types. However, there are notable limitations that need to be addressed for future improvement. Challenges such as comprehensive agent benchmarks, real-world applicability, and mitigating harmful biases in language models are areas that require attention in the near term to enable the development of reliable agents. By transitioning from static language models to more dynamic, autonomous agents, the AI agent landscape is evolving towards more robust and capable systems. This progression aims to provide a holistic understanding of existing AI agent architectures and offers valuable insights for those involved in building or customizing agent systems.\n","   (Complete the function above to test the full pipeline)\n","\n","ðŸŽ¯ This should provide:\n","   - Filtered relevant results only\n","   - Comprehensive analytical response\n","   - Combined postprocessing and synthesis\n"]}],"source":["def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 5):\n","    \"\"\"\n","    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n","\n","    TODO: Complete this function to create the ultimate advanced RAG query engine.\n","    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n","\n","    Args:\n","        index: Vector index to query\n","        similarity_cutoff: Minimum similarity score for filtering\n","        top_k: Number of initial results to retrieve\n","\n","    Returns:\n","        Advanced query engine with filtering and synthesis combined\n","    \"\"\"\n","    # TODO: Create similarity postprocessor\n","    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n","\n","    # TODO: Create TreeSummarize for comprehensive responses\n","    tree_synthesizer = TreeSummarize()\n","\n","    # TODO: Create the comprehensive query engine combining both techniques\n","    advanced_engine = index.as_query_engine(\n","        response_synthesizer=tree_synthesizer,\n","        node_postprocessors=[similarity_processor],\n","        similarity_top_k=top_k\n","    )\n","\n","    print(f\"âœ… : Create advanced RAG pipeline with all techniques\")\n","\n","    return advanced_engine\n","\n","    # PLACEHOLDER - Replace with actual implementation\n","\n","    #return None\n","\n","# Test the comprehensive pipeline\n","if index:\n","    advanced_pipeline = create_advanced_rag_pipeline(index)\n","\n","    if advanced_pipeline:\n","        print(\"âœ… Advanced RAG pipeline created successfully!\")\n","        print(\"   ðŸ”§ Similarity filtering: âœ…\")\n","        print(\"   ðŸŒ³ TreeSummarize synthesis: âœ…\")\n","\n","        # Test with complex query\n","        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n","        print(f\"\\nðŸ” Testing complex query: '{complex_query}'\")\n","\n","        # Uncomment when implemented:\n","        response = advanced_pipeline.query(complex_query)\n","        print(f\"ðŸš€ Advanced RAG Response:\\n{response}\")\n","        print(\"   (Complete the function above to test the full pipeline)\")\n","\n","        print(\"\\nðŸŽ¯ This should provide:\")\n","        print(\"   - Filtered relevant results only\")\n","        print(\"   - Comprehensive analytical response\")\n","        print(\"   - Combined postprocessing and synthesis\")\n","    else:\n","        print(\"âŒ Failed to create advanced RAG pipeline\")\n","else:\n","    print(\"âŒ No index available - run previous cells first\")\n"]},{"cell_type":"markdown","metadata":{"id":"YpIQsi_bYchQ"},"source":["## 5. Final Test - Compare Basic vs Advanced RAG\n","\n","Once you've completed all the functions above, run this cell to compare basic RAG with your advanced techniques.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOm-hv1cYchQ","executionInfo":{"status":"ok","timestamp":1762095884735,"user_tz":-330,"elapsed":10556,"user":{"displayName":"Monalisa Samal","userId":"00386399154790621171"}},"outputId":"34e01e76-4134-4dcc-eba2-bb69ebb67a82"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸš€ Advanced RAG Techniques Assignment - Final Test\n","============================================================\n","\n","ðŸ“Š Component Status:\n","   âœ… Basic Index\n","   âœ… Similarity Filter\n","   âœ… TreeSummarize\n","   âœ… Structured Output\n","   âœ… Advanced Pipeline\n","\n","ðŸ” Creating basic query engine for comparison...\n","\n","============================================================\n","ðŸ†š COMPARISON: Basic vs Advanced RAG\n","============================================================\n","\n","ðŸ“‹ Test Query 1: 'What are the key capabilities of AI agents?'\n","--------------------------------------------------\n","ðŸ”¹ Basic RAG:\n","   Response: The key capabilities of AI agents include strong performance on complex tasks involving reasoning and tool execution, the ability to work iteratively towards goals, opportunities for human feedback, c...\n","\n","ðŸ”¸ Advanced RAG:\n","   Response: The key capabilities of AI agents include strong performance on complex tasks involving reasoning and tool execution, the ability to work iteratively towards goals, opportunities for human feedback, clear leadership, defined planning phases with opportunities for plan refinement, intelligent message filtering, and dynamic teams with agents possessing specific skills relevant to the current sub-task. These capabilities contribute to increased performance compared to architectures lacking these elements.\n","\n","ðŸ“‹ Test Query 2: 'How do you evaluate agent performance metrics?'\n","--------------------------------------------------\n","ðŸ”¹ Basic RAG:\n","   Response: By considering objective evaluation metrics like success rate, output similarity to human responses, and overall efficiency, as well as more nuanced or subjective measures such as efficiency of tool u...\n","\n","ðŸ”¸ Advanced RAG:\n","   Response: Evaluate agent performance metrics by considering objective evaluation metrics like success rate, output similarity to human responses, and overall efficiency. It is also important to take into account more nuanced or subjective measures of performance such as efficiency of tool use, reliability, and robustness of planning. Additionally, real-world applicability should be assessed by evaluating performance on tasks that cover a wide breadth of topics and are sourced from real conversations or issues, rather than just logic puzzles or video games.\n","\n","ðŸ“‹ Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n","--------------------------------------------------\n","ðŸ”¹ Basic RAG:\n","   Response: Multimodal AI systems offer the advantage of combining multiple modes of input, such as text, images, and speech, to enhance understanding and improve performance on various tasks. By leveraging diffe...\n","\n","ðŸ”¸ Advanced RAG:\n","   Response: Multimodal AI systems offer the advantage of combining different modalities such as text, images, and speech to enhance understanding and performance in various tasks. By leveraging multiple modalities, these systems can provide more comprehensive and nuanced insights, leading to improved accuracy and effectiveness in tasks that require multimodal input. However, challenges may arise in multimodal AI systems related to data integration, model complexity, and computational resources. Coordinating information from different modalities, ensuring alignment between them, and managing the increased complexity of multimodal models can be demanding tasks. Additionally, training and deploying multimodal AI systems may require more computational resources compared to unimodal systems, potentially leading to longer processing times and higher resource consumption.\n","\n","============================================================\n","ðŸŽ¯ Assignment Status:\n","   Completed: 5/5 components\n","\n","ðŸŽ‰ Congratulations! You've mastered Advanced RAG Techniques!\n","   âœ… Node postprocessors for result filtering\n","   âœ… Response synthesizers for better answers\n","   âœ… Structured outputs for reliable data\n","   âœ… Advanced pipelines combining all techniques\n","\n","ðŸš€ You're ready for production RAG systems!\n","\n","ðŸ’¡ Key learnings:\n","   - Postprocessors improve result relevance and precision\n","   - Different synthesizers work better for different query types\n","   - Structured outputs enable reliable system integration\n","   - Advanced techniques can be combined for production systems\n"]}],"source":["# Final comparison: Basic vs Advanced RAG\n","print(\"ðŸš€ Advanced RAG Techniques Assignment - Final Test\")\n","print(\"=\" * 60)\n","\n","# Test queries for comparison\n","test_queries = [\n","    \"What are the key capabilities of AI agents?\",\n","    \"How do you evaluate agent performance metrics?\",\n","    \"Explain the benefits and challenges of multimodal AI systems\"\n","]\n","\n","# Check if all components were created\n","components_status = {\n","    \"Basic Index\": index is not None,\n","    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n","    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n","    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n","    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n","}\n","\n","print(\"\\nðŸ“Š Component Status:\")\n","for component, status in components_status.items():\n","    status_icon = \"âœ…\" if status else \"âŒ\"\n","    print(f\"   {status_icon} {component}\")\n","\n","# Create basic query engine for comparison\n","if index:\n","    print(\"\\nðŸ” Creating basic query engine for comparison...\")\n","    basic_engine = index.as_query_engine(similarity_top_k=5)\n","\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"ðŸ†š COMPARISON: Basic vs Advanced RAG\")\n","    print(\"=\" * 60)\n","\n","    for i, query in enumerate(test_queries, 1):\n","        print(f\"\\nðŸ“‹ Test Query {i}: '{query}'\")\n","        print(\"-\" * 50)\n","\n","        # Basic RAG\n","        print(\"ðŸ”¹ Basic RAG:\")\n","        if basic_engine:\n","            # Uncomment when testing:\n","            basic_response = basic_engine.query(query)\n","            print(f\"   Response: {str(basic_response)[:200]}...\")\n","            #print(\"   (Standard vector search + simple response)\")\n","\n","        # Advanced RAG (if implemented)\n","        print(\"\\nðŸ”¸ Advanced RAG:\")\n","        if components_status[\"Advanced Pipeline\"]:\n","            # Uncomment when testing:\n","            advanced_response = advanced_pipeline.query(query)\n","            print(f\"   Response: {advanced_response}\")\n","            #print(\"   (Filtered + TreeSummarize + Structured output)\")\n","        else:\n","            print(\"   Complete the advanced pipeline function to test\")\n","\n","# Final status\n","print(\"\\n\" + \"=\" * 60)\n","print(\"ðŸŽ¯ Assignment Status:\")\n","completed_count = sum(components_status.values())\n","total_count = len(components_status)\n","\n","print(f\"   Completed: {completed_count}/{total_count} components\")\n","\n","if completed_count == total_count:\n","    print(\"\\nðŸŽ‰ Congratulations! You've mastered Advanced RAG Techniques!\")\n","    print(\"   âœ… Node postprocessors for result filtering\")\n","    print(\"   âœ… Response synthesizers for better answers\")\n","    print(\"   âœ… Structured outputs for reliable data\")\n","    print(\"   âœ… Advanced pipelines combining all techniques\")\n","    print(\"\\nðŸš€ You're ready for production RAG systems!\")\n","else:\n","    missing = total_count - completed_count\n","    print(f\"\\nðŸ“ Complete {missing} more components to finish the assignment:\")\n","    for component, status in components_status.items():\n","        if not status:\n","            print(f\"   - {component}\")\n","\n","print(\"\\nðŸ’¡ Key learnings:\")\n","print(\"   - Postprocessors improve result relevance and precision\")\n","print(\"   - Different synthesizers work better for different query types\")\n","print(\"   - Structured outputs enable reliable system integration\")\n","print(\"   - Advanced techniques can be combined for production systems\")\n"]}],"metadata":{"kernelspec":{"display_name":"accelerator","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"a9d4ddd2138e497f9050b59d4a579687":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28265196138e4fc2b71a6f28b6c9ae0c","IPY_MODEL_a341f62d1b374c63b71f478afe421377","IPY_MODEL_1a852a69c3274338bd6634fb0c16a457"],"layout":"IPY_MODEL_d1a87baee2b34ff39294a9957609ae33"}},"28265196138e4fc2b71a6f28b6c9ae0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b6a9975c3a84f048b3b34e678c1a3d8","placeholder":"â€‹","style":"IPY_MODEL_70441a90759e419fbc118642ee3afeb8","value":"Parsingâ€‡nodes:â€‡100%"}},"a341f62d1b374c63b71f478afe421377":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e80346f88fa049f9bc4690b520faeadf","max":42,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2607a80a19ef469a852a574dde7deec9","value":42}},"1a852a69c3274338bd6634fb0c16a457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_752bdeb9460947cdb9731e87828b93c7","placeholder":"â€‹","style":"IPY_MODEL_a9a4ffd40f97484fa39374570f6fd006","value":"â€‡42/42â€‡[00:00&lt;00:00,â€‡215.18it/s]"}},"d1a87baee2b34ff39294a9957609ae33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b6a9975c3a84f048b3b34e678c1a3d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70441a90759e419fbc118642ee3afeb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e80346f88fa049f9bc4690b520faeadf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2607a80a19ef469a852a574dde7deec9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"752bdeb9460947cdb9731e87828b93c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a4ffd40f97484fa39374570f6fd006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18aba1e55c084b45a59d723c920649db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8395d6fb02e49cb8062308a40db32b8","IPY_MODEL_4d2373e1731b46f6960ae50e48ea2d33","IPY_MODEL_cc18d8a0b8904643a0cd1f13b7ba8bd3"],"layout":"IPY_MODEL_e051a3be3c35478cbd343dbacdd48acf"}},"a8395d6fb02e49cb8062308a40db32b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a011adb7c30245deb082532acfd038cb","placeholder":"â€‹","style":"IPY_MODEL_4208e397a3a7458aa5b16c91bc7b5ac8","value":"Generatingâ€‡embeddings:â€‡100%"}},"4d2373e1731b46f6960ae50e48ea2d33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1c05ad90ee74a1fbb77d618ff193971","max":93,"min":0,"orientation":"horizontal","style":"IPY_MODEL_656d18ae543a463ea98145be9cc6771e","value":93}},"cc18d8a0b8904643a0cd1f13b7ba8bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6141e0010d114134ba65680c86be8720","placeholder":"â€‹","style":"IPY_MODEL_c86f10069df241d3adfcf0f884a61389","value":"â€‡93/93â€‡[00:53&lt;00:00,â€‡â€‡1.82it/s]"}},"e051a3be3c35478cbd343dbacdd48acf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a011adb7c30245deb082532acfd038cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4208e397a3a7458aa5b16c91bc7b5ac8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1c05ad90ee74a1fbb77d618ff193971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"656d18ae543a463ea98145be9cc6771e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6141e0010d114134ba65680c86be8720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c86f10069df241d3adfcf0f884a61389":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}