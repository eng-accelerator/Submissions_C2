{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Vector Database Creation and Retrieval\n",
    "## Day 6 Session 2 - RAG Fundamentals\n",
    "\n",
    "**OBJECTIVE:** Create a vector database from a folder of documents and implement basic retrieval functionality.\n",
    "\n",
    "**LEARNING GOALS:**\n",
    "- Understand document loading with SimpleDirectoryReader\n",
    "- Learn vector store setup with LanceDB\n",
    "- Implement vector index creation\n",
    "- Perform semantic search and retrieval\n",
    "\n",
    "**DATASET:** Use the data folder in `Day_6/session_2/data/` which contains multiple file types\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1. Complete each function by replacing the TODO comments with actual implementation\n",
    "2. Run each cell after completing the function to test it\n",
    "3. The answers can be found in the existing notebooks in the `llamaindex_rag/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Setup: Configure Your API Key (Optional)\n",
    "\n",
    "**IMPORTANT:** This assignment primarily uses **local embeddings** (no API key required).\n",
    "\n",
    "However, if you want to use OpenAI or OpenRouter for LLM operations later:\n",
    "\n",
    "### Option 1: OpenAI API Key\n",
    "Get your API key from: https://platform.openai.com/api-keys\n",
    "\n",
    "### Option 2: OpenRouter API Key (Recommended - cheaper!)\n",
    "Get your API key from: https://openrouter.ai/keys\n",
    "\n",
    "### How to Enter Your API Key:\n",
    "Run the cell below and enter your API key when prompted. It will be securely stored for this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Configuration (Optional - for future LLM operations)\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Check if API key is already set in environment\n",
    "if not os.getenv(\"OPENROUTER_API_KEY\") and not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"\\nüîë API Key Setup (Optional)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"This assignment uses LOCAL embeddings (no API key required).\")\n",
    "    print(\"\\nHowever, you can optionally configure an API key for future LLM operations:\")\n",
    "    print(\"  1. OpenAI API Key - https://platform.openai.com/api-keys\")\n",
    "    print(\"  2. OpenRouter API Key - https://openrouter.ai/keys (cheaper option)\")\n",
    "    print(\"\\nPress Enter to skip, or paste your API key below:\")\n",
    "    \n",
    "    api_key = getpass(\"API Key (or press Enter to skip): \").strip()\n",
    "    \n",
    "    if api_key:\n",
    "        # Detect which type of key it is\n",
    "        if api_key.startswith(\"sk-or-\"):\n",
    "            os.environ[\"OPENROUTER_API_KEY\"] = api_key\n",
    "            print(\"‚úÖ OpenRouter API key configured!\")\n",
    "        elif api_key.startswith(\"sk-\"):\n",
    "            os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "            print(\"‚úÖ OpenAI API key configured!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Warning: API key format not recognized. Setting as OPENROUTER_API_KEY.\")\n",
    "            os.environ[\"OPENROUTER_API_KEY\"] = api_key\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  Skipping API key setup - using local embeddings only (perfect for this assignment!)\")\n",
    "else:\n",
    "    print(\"‚úÖ API key already configured in environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö Step 1: Import Required Libraries\n",
    "\n",
    "**What this does:**\n",
    "- Imports LlamaIndex components for document loading, vector storage, and indexing\n",
    "- Imports LanceDB for local vector database storage\n",
    "- Imports HuggingFace embeddings for converting text to numerical vectors\n",
    "\n",
    "**Key Libraries:**\n",
    "- `SimpleDirectoryReader`: Loads documents from folders\n",
    "- `VectorStoreIndex`: Creates searchable index from documents\n",
    "- `LanceDBVectorStore`: Local vector database (fast, no API needed)\n",
    "- `HuggingFaceEmbedding`: Free, local text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è Step 2: Configure LlamaIndex Settings\n",
    "\n",
    "**What this does:**\n",
    "- Configures LlamaIndex to use **local embeddings** (no API calls, completely free!)\n",
    "- Uses the BAAI/bge-small-en-v1.5 model for converting text to 384-dimensional vectors\n",
    "- This model runs on your computer, so no internet connection or API key needed\n",
    "\n",
    "**Why local embeddings?**\n",
    "- ‚úÖ Completely free (no API costs)\n",
    "- ‚úÖ Fast (runs on your machine)\n",
    "- ‚úÖ Private (your documents never leave your computer)\n",
    "- ‚úÖ Good quality for learning and many applications\n",
    "\n",
    "**Model Details:**\n",
    "- BAAI/bge-small-en-v1.5: 384-dimensional embeddings, ~133MB model size\n",
    "- First run will download the model (one-time, ~1-2 minutes)\n",
    "- Subsequent runs use cached model (instant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LlamaIndex Settings (Using local embeddings - No API key needed)\n",
    "def setup_llamaindex_settings():\n",
    "    \"\"\"\n",
    "    Configure LlamaIndex with local embeddings.\n",
    "    This assignment focuses on vector database operations using free, local models.\n",
    "    \"\"\"\n",
    "    # Check for API keys (optional, for future use)\n",
    "    has_openrouter = bool(os.getenv(\"OPENROUTER_API_KEY\"))\n",
    "    has_openai = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "    \n",
    "    if not has_openrouter and not has_openai:\n",
    "        print(\"‚ÑπÔ∏è  No API key configured - that's OK for this assignment!\")\n",
    "        print(\"   This assignment only uses local embeddings for vector operations.\")\n",
    "    else:\n",
    "        print(\"‚úÖ API key found (for optional future LLM operations)\")\n",
    "    \n",
    "    # Configure local embeddings (no API key required)\n",
    "    print(\"\\nüîÑ Loading local embedding model...\")\n",
    "    Settings.embed_model = HuggingFaceEmbedding(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ LlamaIndex configured with local embeddings\")\n",
    "    print(\"   Using BAAI/bge-small-en-v1.5 for document embeddings (384 dimensions)\")\n",
    "    print(\"   First run may take 1-2 minutes to download model (~133MB)\")\n",
    "\n",
    "# Setup the configuration\n",
    "setup_llamaindex_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÇ Function 1: Load Documents from Folder\n",
    "\n",
    "**Your Task:** Complete the `load_documents_from_folder()` function below.\n",
    "\n",
    "**What this function does:**\n",
    "- Takes a folder path as input\n",
    "- Uses `SimpleDirectoryReader` to automatically detect and load various file types\n",
    "- Supports: PDFs, text files, Word docs, HTML, CSVs, and more\n",
    "- Returns a list of Document objects that can be indexed\n",
    "\n",
    "**Key Concept - Document Loading:**\n",
    "Document ingestion is the first step in any RAG system. We need to load various file types (PDFs, text, HTML, etc.) into memory before we can create embeddings and search them.\n",
    "\n",
    "**Parameters:**\n",
    "- `input_dir`: Path to the folder containing documents\n",
    "- `recursive=True`: Also load files from subdirectories\n",
    "\n",
    "**TODO:** Replace the `pass` statement with your implementation using `SimpleDirectoryReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_folder(folder_path: str):\n",
    "    \"\"\"\n",
    "    Load documents from a folder using SimpleDirectoryReader.\n",
    "    \n",
    "    TODO: Complete this function to load documents from the given folder path.\n",
    "    HINT: Use SimpleDirectoryReader with recursive parameter to load all files\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing documents\n",
    "        \n",
    "    Returns:\n",
    "        List of documents loaded from the folder\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    # Create SimpleDirectoryReader instance with recursive loading\n",
    "    # Load and return documents\n",
    "    pass\n",
    "\n",
    "# Test the function after you complete it\n",
    "test_folder = \"data\"\n",
    "documents = load_documents_from_folder(test_folder)\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìñ Understanding Vector Stores and Embeddings\n",
    "\n",
    "Before we create the vector store, let's understand some key concepts:\n",
    "\n",
    "### üèóÔ∏è 1. What is an \"Instance\"?\n",
    "\n",
    "**Instance** = A working copy of an object\n",
    "\n",
    "Think of it like:\n",
    "- **Class** (LanceDBVectorStore) = Blueprint for a house\n",
    "- **Instance** (vector_store) = An actual house built from that blueprint\n",
    "\n",
    "```python\n",
    "vector_store = LanceDBVectorStore(...)  # Creating an instance\n",
    "```\n",
    "\n",
    "Now `vector_store` is a working object you can use:\n",
    "- `vector_store.add()` - Add documents\n",
    "- `vector_store.query()` - Search documents\n",
    "\n",
    "---\n",
    "\n",
    "### üóÇÔ∏è 2. Where is the Database Created?\n",
    "\n",
    "When you specify `db_path = \"./vectordb\"`, it means:\n",
    "- `./` = Current working directory (where Jupyter is running)\n",
    "- Since you're in `D:\\Claude\\Bootcamp\\Day- 6\\`, the database will be created at:\n",
    "  - `D:\\Claude\\Bootcamp\\Day- 6\\vectordb\\`\n",
    "\n",
    "After running, you'll see a new folder with files like:\n",
    "- `documents.lance` (the actual database)\n",
    "- Index files\n",
    "\n",
    "---\n",
    "\n",
    "### üß† 3. What are Document Embeddings? (MOST IMPORTANT!)\n",
    "\n",
    "**Embeddings** = Converting text to numbers that capture meaning\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Original Documents (text):\n",
    "- Doc 1: \"Python is a programming language\"\n",
    "- Doc 2: \"JavaScript is used for web development\"\n",
    "- Doc 3: \"I love cooking pasta\"\n",
    "\n",
    "Document Embeddings (numbers):\n",
    "- Doc 1: `[0.8, 0.9, 0.1, 0.05, ...]` (384 numbers)\n",
    "- Doc 2: `[0.75, 0.85, 0.15, 0.1, ...]` (384 numbers)\n",
    "- Doc 3: `[0.1, 0.05, 0.9, 0.95, ...]` (384 numbers)\n",
    "\n",
    "**Why numbers?**\n",
    "- Computers can't understand \"Python\" or \"programming\"\n",
    "- BUT computers CAN measure distance between numbers!\n",
    "- Similar meanings ‚Üí Similar numbers\n",
    "\n",
    "---\n",
    "\n",
    "### üìä 4. Storing Documents vs Storing Embeddings\n",
    "\n",
    "**Traditional Search (Keyword Matching):**\n",
    "```\n",
    "Database stores: \"Python is a programming language\"\n",
    "Search: \"coding languages\"\n",
    "Result: ‚ùå NO MATCH (\"coding\" ‚â† \"programming\")\n",
    "```\n",
    "\n",
    "**Vector Search (Semantic/Meaning-Based):**\n",
    "```\n",
    "Database stores: [0.8, 0.9, 0.1, ...] ‚Üê Python doc embedding\n",
    "Your query: \"coding languages\" ‚Üí [0.78, 0.88, 0.12, ...]\n",
    "Computer calculates: Distance = 0.05 (VERY CLOSE!)\n",
    "Result: ‚úÖ Returns Python doc (understands \"coding\" ‚âà \"programming\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ The Magic of Embeddings:\n",
    "\n",
    "Embeddings understand **MEANING**, not just words:\n",
    "\n",
    "| Your Search | Traditional DB | Embedding DB |\n",
    "|-------------|----------------|-------------|\n",
    "| \"king\" | ‚ùå No match for \"queen\" | ‚úÖ Finds \"queen\" (similar concept) |\n",
    "| \"happy\" | ‚ùå No match for \"joyful\" | ‚úÖ Finds \"joyful\" (same sentiment) |\n",
    "| \"Python tutorial\" | ‚ùå No match for \"learn programming\" | ‚úÖ Finds \"learn programming\" (same intent) |\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Why RAG Uses Embeddings:\n",
    "\n",
    "When you ask: **\"How do AI agents work?\"**\n",
    "\n",
    "RAG system:\n",
    "1. Converts your question to embedding: `[0.6, 0.7, 0.3, ...]`\n",
    "2. Compares to ALL document embeddings in database\n",
    "3. Finds documents with similar embeddings (similar meaning)\n",
    "4. Returns: \"AI_Agent_Frameworks.pdf\" (even if it never says \"how do they work\")\n",
    "\n",
    "**That's the \"Retrieval\" in Retrieval-Augmented Generation!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üóÑÔ∏è Function 2: Create Vector Store\n",
    "\n",
    "**Your Task:** Complete the `create_vector_store()` function below.\n",
    "\n",
    "**What this function does:**\n",
    "- Creates a local LanceDB vector database\n",
    "- LanceDB stores document embeddings (numerical vectors) on your disk\n",
    "- No API calls needed - everything runs locally\n",
    "\n",
    "**Key Concept - Vector Store:**\n",
    "A vector store is a specialized database optimized for storing and searching high-dimensional vectors (embeddings). Unlike traditional databases that search by exact matches, vector databases find similar vectors using distance calculations.\n",
    "\n",
    "**Parameters:**\n",
    "- `uri`: Path where the database files will be stored\n",
    "- `table_name`: Name of the table to store document vectors (like a table in SQL)\n",
    "\n",
    "**Why LanceDB?**\n",
    "- ‚úÖ Works completely offline (no API calls)\n",
    "- ‚úÖ Fast similarity search\n",
    "- ‚úÖ Lightweight (~few MB for typical document collections)\n",
    "- ‚úÖ Perfect for learning and small-to-medium projects\n",
    "\n",
    "**TODO:** Complete the function by creating a `LanceDBVectorStore` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(db_path: str = \"./vectordb\", table_name: str = \"documents\"):\n",
    "    \"\"\"\n",
    "    Create a LanceDB vector store for storing document embeddings.\n",
    "    \n",
    "    TODO: Complete this function to create a LanceDB vector store.\n",
    "    HINT: Create the directory first, then instantiate LanceDBVectorStore with uri and table_name\n",
    "    \n",
    "    Args:\n",
    "        db_path (str): Path where the vector database will be stored\n",
    "        table_name (str): Name of the table in the vector database\n",
    "        \n",
    "    Returns:\n",
    "        LanceDBVectorStore: Configured vector store\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    # Create the directory if it doesn't exist (use Path from pathlib)\n",
    "    # Create and return LanceDBVectorStore instance\n",
    "    pass\n",
    "\n",
    "# Test the function after you complete it\n",
    "vector_store = create_vector_store(\"./assignment_vectordb\")\n",
    "print(f\"Vector store created: {vector_store is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîó Function 3: Create Vector Index\n",
    "\n",
    "**Your Task:** Complete the `create_vector_index()` function below.\n",
    "\n",
    "**What this function does:**\n",
    "- Takes your loaded documents and the vector store\n",
    "- Creates embeddings for ALL documents (converts text to 384-dimensional vectors)\n",
    "- Stores these embeddings in the vector database\n",
    "- Returns an index that can be used for searching\n",
    "\n",
    "**Key Concept - Vector Index:**\n",
    "The vector index is the searchable structure that connects your original documents with their embeddings. When you search, the index:\n",
    "1. Converts your query to an embedding\n",
    "2. Finds the closest document embeddings in the vector store\n",
    "3. Returns the original document text\n",
    "\n",
    "**What happens during index creation:**\n",
    "1. For each document ‚Üí Generate embedding using BAAI/bge-small-en-v1.5\n",
    "2. Store embedding in LanceDB vector store\n",
    "3. Create searchable index structure\n",
    "\n",
    "**Time taken:**\n",
    "- ~1-2 seconds per document (first time)\n",
    "- For 39 documents ‚âà 30-60 seconds\n",
    "- Subsequent runs faster (embeddings cached)\n",
    "\n",
    "**TODO:** Complete the function by:\n",
    "1. Creating a StorageContext with the vector store\n",
    "2. Creating a VectorStoreIndex from documents using that storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(documents: List, vector_store):\n",
    "    \"\"\"\n",
    "    Create a vector index from documents using the provided vector store.\n",
    "    \n",
    "    TODO: Complete this function to create a searchable vector index.\n",
    "    HINT: Create StorageContext first, then use VectorStoreIndex.from_documents()\n",
    "    \n",
    "    Args:\n",
    "        documents: List of documents to index\n",
    "        vector_store: LanceDB vector store to use for storage\n",
    "        \n",
    "    Returns:\n",
    "        VectorStoreIndex: The created vector index\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    # Create storage context with vector store\n",
    "    # Create index from documents\n",
    "    # This will: 1) Generate embeddings for all documents\n",
    "    #           2) Store embeddings in the vector store\n",
    "    pass\n",
    "\n",
    "# Test the function after you complete it\n",
    "if documents and vector_store:\n",
    "    index = create_vector_index(documents, vector_store)\n",
    "    print(f\"Vector index created: {index is not None}\")\n",
    "    print(f\"Indexed {len(documents)} documents successfully!\")\n",
    "else:\n",
    "    print(\"Complete previous functions first to test this one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Function 4: Search Documents\n",
    "\n",
    "**Your Task:** Complete the `search_documents()` function below.\n",
    "\n",
    "**What this function does:**\n",
    "- Takes a search query (plain English text)\n",
    "- Converts query to an embedding\n",
    "- Finds the most similar document embeddings in the vector store\n",
    "- Returns the actual document text (not the embeddings)\n",
    "\n",
    "**Key Concept - Semantic Search:**\n",
    "Unlike keyword search (exact word matching), semantic search finds documents with similar **meaning**:\n",
    "- Query: \"machine learning tutorials\" ‚Üí Finds: \"AI and deep learning guides\"\n",
    "- Query: \"Italian food recipes\" ‚Üí Finds: \"Cooking pasta and pizza\"\n",
    "- Query: \"financial analysis\" ‚Üí Finds: \"Investment and stock market data\"\n",
    "\n",
    "**How it works:**\n",
    "1. Query \"What are AI agents?\" ‚Üí Embedding: `[0.65, 0.73, 0.32, ...]`\n",
    "2. Compare to all document embeddings using distance calculation\n",
    "3. Find closest matches:\n",
    "   - Document A: Distance = 0.08 (VERY SIMILAR) ‚úÖ\n",
    "   - Document B: Distance = 0.15 (SIMILAR) ‚úÖ\n",
    "   - Document C: Distance = 0.89 (NOT SIMILAR) ‚ùå\n",
    "4. Return top-k closest documents (e.g., top 3)\n",
    "\n",
    "**Parameters:**\n",
    "- `similarity_top_k`: How many results to return (e.g., 3 means \"return 3 most similar documents\")\n",
    "\n",
    "**TODO:** Complete the function by:\n",
    "1. Creating a retriever from the index with similarity_top_k parameter\n",
    "2. Using the retriever to search for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(index, query: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Search for relevant documents using the vector index.\n",
    "    \n",
    "    TODO: Complete this function to perform semantic search on the index.\n",
    "    HINT: Use index.as_retriever() with similarity_top_k parameter, then retrieve(query)\n",
    "    \n",
    "    Args:\n",
    "        index: Vector index to search\n",
    "        query (str): Search query\n",
    "        top_k (int): Number of top results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of retrieved document nodes\n",
    "    \"\"\"\n",
    "    # TODO: Your code here\n",
    "    # Create retriever from index with similarity_top_k\n",
    "    # Retrieve documents for the query\n",
    "    pass\n",
    "\n",
    "# Test the function after you complete it\n",
    "if 'index' in locals() and index is not None:\n",
    "    test_query = \"What are AI agents?\"\n",
    "    results = search_documents(index, test_query, top_k=2)\n",
    "    print(f\"Found {len(results)} results for query: '{test_query}'\")\n",
    "    print(\"\\nüîé Search Results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        text_preview = result.text[:100] if hasattr(result, 'text') else 'No text'\n",
    "        score = f\" (Similarity: {result.score:.4f})\" if hasattr(result, 'score') else \"\"\n",
    "        print(f\"  {i}. {text_preview}...{score}\")\n",
    "else:\n",
    "    print(\"Complete all previous functions first to test this one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üöÄ Final Test: Complete RAG Pipeline\n",
    "\n",
    "**What this cell does:**\n",
    "Once you've completed all 4 functions above, this cell will:\n",
    "1. Run the complete vector database pipeline from start to finish\n",
    "2. Test with multiple diverse search queries\n",
    "3. Show similarity scores for each result\n",
    "4. Verify that all components work together\n",
    "\n",
    "**Test Queries:**\n",
    "We'll test with 4 different topics to demonstrate semantic search:\n",
    "- AI and technology\n",
    "- Agent evaluation\n",
    "- Cooking and recipes\n",
    "- Financial analysis\n",
    "\n",
    "This proves your vector database can handle diverse topics and find relevant results!\n",
    "\n",
    "**What to look for:**\n",
    "- ‚úÖ All 4 functions complete successfully\n",
    "- ‚úÖ Documents load (should see ~39 documents)\n",
    "- ‚úÖ Vector store and index created\n",
    "- ‚úÖ Search returns relevant results with similarity scores\n",
    "- ‚úÖ Higher scores (closer to 1.0) = more similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test of the complete pipeline\n",
    "print(\"üöÄ Testing Complete Vector Database Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Re-run the complete pipeline to ensure everything works\n",
    "data_folder = \"data\"\n",
    "vector_db_path = \"./assignment_vectordb\"\n",
    "\n",
    "# Step 1: Load documents\n",
    "print(\"\\nüìÇ Step 1: Loading documents...\")\n",
    "documents = load_documents_from_folder(data_folder)\n",
    "print(f\"   Loaded {len(documents)} documents\")\n",
    "\n",
    "# Step 2: Create vector store\n",
    "print(\"\\nüóÑÔ∏è Step 2: Creating vector store...\")\n",
    "vector_store = create_vector_store(vector_db_path)\n",
    "print(\"   Vector store status:\", \"‚úÖ Created\" if vector_store else \"‚ùå Failed\")\n",
    "\n",
    "# Step 3: Create vector index\n",
    "print(\"\\nüîó Step 3: Creating vector index...\")\n",
    "print(\"   (This may take 30-60 seconds for ~39 documents...)\")\n",
    "if documents and vector_store:\n",
    "    index = create_vector_index(documents, vector_store)\n",
    "    print(\"   Index status:\", \"‚úÖ Created\" if index else \"‚ùå Failed\")\n",
    "else:\n",
    "    index = None\n",
    "    print(\"   ‚ùå Cannot create index - missing documents or vector store\")\n",
    "\n",
    "# Step 4: Test multiple search queries\n",
    "print(\"\\nüîç Step 4: Testing search functionality...\")\n",
    "if index:\n",
    "    search_queries = [\n",
    "        \"What are AI agents?\",\n",
    "        \"How to evaluate agent performance?\", \n",
    "        \"Italian recipes and cooking\",\n",
    "        \"Financial analysis and investment\"\n",
    "    ]\n",
    "    \n",
    "    for query in search_queries:\n",
    "        print(f\"\\n   üîé Query: '{query}'\")\n",
    "        results = search_documents(index, query, top_k=2)\n",
    "        \n",
    "        if results:\n",
    "            for i, result in enumerate(results, 1):\n",
    "                text_preview = result.text[:100] if hasattr(result, 'text') else \"No text available\"\n",
    "                score = f\" (Score: {result.score:.4f})\" if hasattr(result, 'score') else \"\"\n",
    "                print(f\"      {i}. {text_preview}...{score}\")\n",
    "        else:\n",
    "            print(\"      No results found\")\n",
    "else:\n",
    "    print(\"   ‚ùå Cannot test search - index not created\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéØ Assignment Status:\")\n",
    "print(f\"   Documents loaded: {'‚úÖ' if documents else '‚ùå'}\")\n",
    "print(f\"   Vector store created: {'‚úÖ' if vector_store else '‚ùå'}\")\n",
    "print(f\"   Index created: {'‚úÖ' if index else '‚ùå'}\")\n",
    "print(f\"   Search working: {'‚úÖ' if index else '‚ùå'}\")\n",
    "\n",
    "if documents and vector_store and index:\n",
    "    print(\"\\nüéâ Congratulations! You've successfully completed the assignment!\")\n",
    "    print(\"   You've built a complete vector database with semantic search functionality!\")\n",
    "    print(\"\\nüìö What you learned:\")\n",
    "    print(\"   ‚úÖ Document loading from folders\")\n",
    "    print(\"   ‚úÖ Vector store setup with LanceDB\")\n",
    "    print(\"   ‚úÖ Document embedding and indexing\")\n",
    "    print(\"   ‚úÖ Semantic search (meaning-based, not keyword-based)\")\n",
    "    print(\"\\nüöÄ You're ready for Assignment 2: Advanced RAG techniques!\")\n",
    "else:\n",
    "    print(\"\\nüìù Please complete the TODO functions above to finish the assignment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
