{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAfj0YTlm5fv"
      },
      "source": [
        "# Assignment 3a: Basic Gradio RAG Frontend\n",
        "## Day 6 Session 2 - Building Simple RAG Applications\n",
        "\n",
        "In this assignment, you'll build a simple Gradio frontend for your RAG system with just the essential features:\n",
        "- Button to initialize the vector database\n",
        "- Search query input and button\n",
        "- Display of AI responses\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Create basic Gradio interfaces\n",
        "- Connect RAG backend to frontend\n",
        "- Handle user interactions and database initialization\n",
        "- Build functional AI-powered web applications\n",
        "\n",
        "**Prerequisites:**\n",
        "- Completed Assignment 1 (Vector Database Basics)\n",
        "- Completed Assignment 2 (Advanced RAG)\n",
        "- Understanding of LlamaIndex fundamentals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB2U8-Sam5f5"
      },
      "source": [
        "## ğŸ“š Part 1: Setup and Imports\n",
        "\n",
        "Import all necessary libraries for building your Gradio RAG application.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HavAYY1OnATq",
        "outputId": "a0d5290f-6cc8-41c6-9b6e-a9d5878a3488"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r \"/content/requirements.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S6fYeE1snMv7",
        "outputId": "ad2d32db-6abb-4f90-9d46-662a722572b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNaaxZTwm5f7",
        "outputId": "ad78e79c-49f9-4657-b982-aff0de8e19be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import gradio as gr\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# securely input your key\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = getpass(\"Enter your OpenRouter key\")\n",
        "print(\"âœ“ OpenrRouter key set successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmMq8bq4nqEh",
        "outputId": "3764e5a6-5598-472c-da15-092ed6fc0c06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenRouter keyÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ“ OpenrRouter key set successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahE3_ICRm5f9"
      },
      "source": [
        "## ğŸ¤– Part 2: RAG Backend Class\n",
        "\n",
        "Create a simple RAG backend that can initialize the database and answer queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85NKJRakm5f-",
        "outputId": "99763526-db14-4781-fcb4-949a2fe8ff6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ RAG Backend initialized and ready!\n"
          ]
        }
      ],
      "source": [
        "class SimpleRAGBackend:\n",
        "    \"\"\"Simple RAG backend for Gradio frontend.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.index = None\n",
        "        self.setup_settings()\n",
        "\n",
        "    def setup_settings(self):\n",
        "        \"\"\"Configure LlamaIndex settings.\"\"\"\n",
        "        # Set up the LLM using OpenRouter\n",
        "        api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "        if api_key:\n",
        "            Settings.llm = OpenRouter(\n",
        "                api_key=api_key,\n",
        "                model=\"gpt-4o\",\n",
        "                temperature=0.1\n",
        "            )\n",
        "\n",
        "        # Set up the embedding model\n",
        "        Settings.embed_model = HuggingFaceEmbedding(\n",
        "            model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Set chunking parameters\n",
        "        Settings.chunk_size = 512\n",
        "        Settings.chunk_overlap = 50\n",
        "\n",
        "    def initialize_database(self, data_folder=\"/content/drive/MyDrive/Outskill/session_2/data\"):\n",
        "        \"\"\"Initialize the vector database with documents.\"\"\"\n",
        "        # Check if data folder exists\n",
        "        if not Path(data_folder).exists():\n",
        "            return f\"âŒ Data folder '{data_folder}' not found!\"\n",
        "\n",
        "        try:\n",
        "            # Create vector store\n",
        "            vector_store = LanceDBVectorStore(\n",
        "                uri=\"./basic_rag_vectordb\",\n",
        "                table_name=\"documents\"\n",
        "            )\n",
        "\n",
        "            # Load documents\n",
        "            reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "            documents = reader.load_data()\n",
        "\n",
        "            # Create storage context and index\n",
        "            storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "            self.index = VectorStoreIndex.from_documents(\n",
        "                documents,\n",
        "                storage_context=storage_context,\n",
        "                show_progress=True\n",
        "            )\n",
        "\n",
        "            return f\"âœ… Database initialized successfully with {len(documents)} documents!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error initializing database: {str(e)}\"\n",
        "\n",
        "    def query(self, question):\n",
        "        \"\"\"Query the RAG system and return response.\"\"\"\n",
        "        # Check if index exists\n",
        "        if self.index is None:\n",
        "            return \"âŒ Please initialize the database first!\"\n",
        "\n",
        "        # Check if question is empty\n",
        "        if not question or not question.strip():\n",
        "            return \"âš ï¸ Please enter a question first!\"\n",
        "\n",
        "        try:\n",
        "            # Create query engine and get response\n",
        "            query_engine = self.index.as_query_engine()\n",
        "            response = query_engine.query(question)\n",
        "            return str(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error processing query: {str(e)}\"\n",
        "\n",
        "# Initialize the backend\n",
        "rag_backend = SimpleRAGBackend()\n",
        "print(\"ğŸš€ RAG Backend initialized and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7VdUdh7m5gA"
      },
      "source": [
        "## ğŸ¨ Part 3: Gradio Interface\n",
        "\n",
        "Create a simple Gradio interface with:\n",
        "1. Button to initialize the database\n",
        "2. Text input for queries\n",
        "3. Button to submit queries\n",
        "4. Text output for responses\n",
        "5. Text output for status messages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGBmzaX6m5gC",
        "outputId": "7f27fcdd-1038-431e-8f4e-9ace18d99d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Basic RAG interface created successfully!\n"
          ]
        }
      ],
      "source": [
        "def create_basic_rag_interface():\n",
        "    \"\"\"Create basic RAG interface with essential features.\"\"\"\n",
        "\n",
        "    def initialize_db():\n",
        "        \"\"\"Handle database initialization.\"\"\"\n",
        "        return rag_backend.initialize_database()\n",
        "\n",
        "    def handle_query(question):\n",
        "        \"\"\"Handle user queries.\"\"\"\n",
        "        return rag_backend.query(question)\n",
        "\n",
        "    # TODO: Create Gradio interface using gr.Blocks()\n",
        "    # Hint: Look at the structure below and fill in the missing components\n",
        "\n",
        "    with gr.Blocks(title=\"Basic RAG Assistant\") as interface:\n",
        "        # TODO: Add title and description\n",
        "        # Hint: Use gr.Markdown() for formatted text\n",
        "        gr.Markdown(\"# Basic RAG Assistant\")\n",
        "        gr.Markdown(\"Ask questions about your research papers and get AI-powered answers.\")\n",
        "\n",
        "        # TODO: Add initialization section\n",
        "        # Hint: You need to use gr.Button to initialize the database\n",
        "        gr.Markdown(\"## Step 1: Initialize Database\")\n",
        "        init_btn = gr.Button(\"Initialize Database\", variant=\"primary\")\n",
        "\n",
        "        # TODO: Add status output\n",
        "        # Hint: You need to use gr.Textbox to display the status\n",
        "\n",
        "        # The connection between the button and the status output has already been implemented\n",
        "        # at the end of this function\n",
        "\n",
        "        status_output = gr.Textbox(\n",
        "            label=\"Status\",\n",
        "            placeholder=\"Click 'Initialize Database' to start...\",\n",
        "            interactive=False)\n",
        "\n",
        "        # TODO: Add query section\n",
        "        # Hint: You need a text input, submit button, and response output\n",
        "\n",
        "        gr.Markdown(\"## Step 2: Ask Questions\")\n",
        "\n",
        "\n",
        "        # Use gr.Textbox to create a text input\n",
        "        query_input = gr.Textbox(\n",
        "            label=\"Your Question\",\n",
        "            placeholder=\"Enter your question here...\",\n",
        "            lines=3\n",
        "        )\n",
        "\n",
        "        # Use gr.Button to create a submit button\n",
        "        submit_btn = gr.Button(\"Submit Query\", variant=\"primary\")\n",
        "\n",
        "        # Use gr.Textbox to create a response output\n",
        "        response_output = gr.Textbox(\n",
        "            label=\"Response\",\n",
        "            placeholder=\"Your answer will appear here...\",\n",
        "            lines=10,\n",
        "            interactive=False\n",
        "        )\n",
        "\n",
        "        # Connect buttons to functions\n",
        "        # Uncomment when above is implemented\n",
        "        init_btn.click(initialize_db, outputs=[status_output])\n",
        "        submit_btn.click(handle_query, inputs=[query_input], outputs=[response_output])\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create the interface\n",
        "basic_interface = create_basic_rag_interface()\n",
        "print(\"âœ… Basic RAG interface created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNjeb8eYm5gE"
      },
      "source": [
        "## ğŸš€ Part 4: Launch Your Application\n",
        "\n",
        "Launch your Gradio application and test it!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "id": "2ikmu18Lm5gG",
        "outputId": "3b960ef6-7df4-46f1-c617-b8822696681e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‰ Launching your Basic RAG Assistant...\n",
            "ğŸ”— Your application will open in a new browser tab!\n",
            "\n",
            "ğŸ“‹ Testing Instructions:\n",
            "1. Click 'Initialize Database' button first\n",
            "2. Wait for success message\n",
            "3. Enter a question in the query box\n",
            "4. Click 'Ask Question' to get AI response\n",
            "\n",
            "ğŸ’¡ Example questions to try:\n",
            "- What are the main topics in the documents?\n",
            "- Summarize the key findings\n",
            "- Explain the methodology used\n",
            "\n",
            "ğŸš€ Launch your app:\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5f0163487cdcd54a29.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f0163487cdcd54a29.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"ğŸ‰ Launching your Basic RAG Assistant...\")\n",
        "print(\"ğŸ”— Your application will open in a new browser tab!\")\n",
        "print(\"\")\n",
        "print(\"ğŸ“‹ Testing Instructions:\")\n",
        "print(\"1. Click 'Initialize Database' button first\")\n",
        "print(\"2. Wait for success message\")\n",
        "print(\"3. Enter a question in the query box\")\n",
        "print(\"4. Click 'Ask Question' to get AI response\")\n",
        "print(\"\")\n",
        "print(\"ğŸ’¡ Example questions to try:\")\n",
        "print(\"- What are the main topics in the documents?\")\n",
        "print(\"- Summarize the key findings\")\n",
        "print(\"- Explain the methodology used\")\n",
        "print(\"\")\n",
        "print(\"ğŸš€ Launch your app:\")\n",
        "\n",
        "# Your launch code here:\n",
        "# Uncomment when implemented\n",
        "basic_interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmiUSx0jm5gH"
      },
      "source": [
        "## âœ… Assignment Completion Checklist\n",
        "\n",
        "Before submitting, ensure you have:\n",
        "\n",
        "- [x] RAG backend is provided and working\n",
        "- [ ] Created Gradio interface with required components:\n",
        "  - [ ] Title and description using gr.Markdown()\n",
        "  - [ ] Initialize database button using gr.Button()\n",
        "  - [ ] Status output using gr.Textbox()\n",
        "  - [ ] Query input field using gr.Textbox()\n",
        "  - [ ] Submit query button using gr.Button()\n",
        "  - [ ] Response output area using gr.Textbox()\n",
        "- [ ] Connected buttons to backend functions using .click()\n",
        "- [ ] Successfully launched the application\n",
        "- [ ] Tested the full workflow (initialize â†’ query â†’ response)\n",
        "\n",
        "## ğŸŠ Congratulations!\n",
        "\n",
        "You've successfully built your first Gradio RAG application! You now have:\n",
        "\n",
        "- A functional web interface for your RAG system\n",
        "- Understanding of Gradio basics and component connections\n",
        "- A foundation for building more complex AI applications\n",
        "\n",
        "**Next Steps**: Complete Assignment 3b to add advanced configuration options to your RAG interface!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "accelerator",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}